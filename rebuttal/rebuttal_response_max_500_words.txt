We thank the reviewers for their comments. We summarize and respond to them in what follows.

[Reviewer 1] ICDAR Contest in 2011 related to that topic
Thanks for pointing this out. They are essentially using a full-cross evaluation of all methods to perform end-to-end evaluation, just like us. Also, they do not report NER evaluation, unlike us.
[TODO add ref to https://hal.archives-ouvertes.fr/inria-00608371 + small comment]  We updated the paper with these precisions.

[Reviewer 1] Qualitative analysis of influence of OCR quality on NER
[Reviewer 1] Metrics uses, potential biases

[Bertrand] Ajouter un paragraphe d'évaluation qualitative des résultats de l'ocr+ner comme on avait prévu initialement, et un commentaire la projection des labels dans les chaînes bruitée. 
[Joseph] say we used metrics as reported on previous work, and also that one of our goals is to assess whether NER could help correcting OCR errors?
Here OCR is either pretty good or very wrong, so alignments usually make sense or can be detected as degenerated cases. However, it is very true that some borderline cases may cause trouble. This requires more study and [TODO] we updated the paper to be more explicit about these limitations.




[Reviewer 2] comparing two runs of Pero OCR together, or two runs of Tesseract together
Very good point, but we could not compete with the large, private training datasets used to produce the models we used. We chose to report, as objectively as possible, the performance of actual, off-the-shelf systems.

[Reviewer 2] reason for not reporting Kraken performance on downstream NER
[Bertrand] Ajouter Kraken à l'évaluation NER ? 
(say we chose not to report this because would have reduced a lot the size of the test set? This would require to add one extra set of experiment; not possible because of space constraints)

[Reviewer 2] missing Figure 1 reference, inconsistent reference to figures, Tesseract spelling
Thanks for pointing these issues, [TODO] we fixed them.


[Reviewer 2] Experiment with artificial OCR noise in future work
This is planned, but it seems to be very hard to generate realistic noise.
We decided to first focus on real cases with no further assumptions.




[Reviewer 3] Section 2.3 should be a separate section about the pipeline
[RBertrand] Transformer la sous-section 2.3 "Pipeline summary" en section 3. 
[TODO attention espace supplémentaire] We extracted this content as a new section as suggested.

[Reviewer 3] What are "thumbnails" in page 7
We refer to "thumbnails" as image crops, have the same resolution as the original image.
We updated the text to clarify this.

[Reviewer 3] Description of NER QA is confusing
[TODO] we clarified the relevant section

[Reviewer 3] Figure 4 needs clarification
[Bertrand] Détailler la légende de la figure 4 ? 
[TODO] We improved the description of fig. 4.


