{"cells":[{"cell_type":"markdown","metadata":{"id":"9XuqX-_F9u7S","tags":[]},"source":["# 40 - Experiment #2"]},{"cell_type":"markdown","metadata":{"id":"J62JrWepL_yb","tags":[]},"source":["## Initialisation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"czKQM7SWKda4"},"outputs":[],"source":["\"\"\" RUN THIS BLOCK ONLY ON GOOGLE COLAB \"\"\"\n","\n","# `GDRIVE_PAPER_FOLDER` is the relative path in your GDrive to the folder\n","# contaning the code of the paper\n","# ADAPT TO YOUR SITUATION !\n","%env GDRIVE_PAPER_FOLDER=TEST\n","\n","# Mount Google Drive to your Colab environment. May require to log in to Google.\n","from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)\n","\n","# Copy the Python modules in `PATH_TO_SOURCES/src/ner/util` to GColab\n","# to enable import.\n","!cp -r /content/drive/MyDrive/$GDRIVE_PAPER_FOLDER/src/ner/util .\n","\n","# Install dependencies\n","!pip install -q datasets transformers[sentencepiece] sequeval"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"MVbu2jij-upN","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1653384587466,"user_tz":-120,"elapsed":25,"user":{"displayName":"Bertrand Dumenieu","userId":"12153120920884628135"}},"outputId":"c10f6d3e-7d30-43e3-f89f-4fe8634dd186"},"outputs":[{"output_type":"stream","name":"stderr","text":["24/05/2022 09:29:47 ; INFO ; ======= CONFIGURATION =======\n","24/05/2022 09:29:47 ; INFO ; BASEDIR: /content/drive/MyDrive/TEST\n","24/05/2022 09:29:47 ; INFO ; Input datasets will be loaded from DATASETDIR /content/drive/MyDrive/TEST/dataset\n","24/05/2022 09:29:47 ; INFO ; Training data and models will be saved to NERDIR /content/drive/MyDrive/TEST/src/ner\n","24/05/2022 09:29:47 ; INFO ; Debug mode is ON\n","24/05/2022 09:29:47 ; INFO ; Random seed: 42\n","24/05/2022 09:29:47 ; INFO ; Enable reproducibility checks: True\n","24/05/2022 09:29:47 ; INFO ; ============================\n"]},{"output_type":"stream","name":"stdout","text":["env: DEBUG=1\n","env: AS_IN_THE_PAPER=True\n"]}],"source":["\"\"\" Loads the configuration \"\"\"\n","\n","# Set to 1/true/ to set the logging level of nerlogger to DEBUG \n","# and save the the spacy datasets as TXT along with the .spacy file\n","#  for easier debug of the training set generation.\n","%env DEBUG=1\n","\n","# If True, activates a set of assertions in the notebooks to ensure\n","#Â that the scripts runs with the parameters used in the paper.\n","%env AS_IN_THE_PAPER = True\n","\n","import util.config as config\n","\n","config.show()"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cBI-Q1yCNMbZ","outputId":"e938f0f0-23dd-4d34-a06c-336351cea669","executionInfo":{"status":"ok","timestamp":1653384602099,"user_tz":-120,"elapsed":426,"user":{"displayName":"Bertrand Dumenieu","userId":"12153120920884628135"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(PosixPath('/content/drive/MyDrive/TEST/src/ner/02-experiment_2_prepared_datasets/huggingface_ref'),\n"," PosixPath('/content/drive/MyDrive/TEST/src/ner/02-experiment_2_prepared_datasets/huggingface_pero'))"]},"metadata":{},"execution_count":3}],"source":["# Same training configuration as in 20-experiment_1\n","TRAINING_CONFIG = {\n","    \"evaluation_strategy\": \"steps\",\n","    \"eval_steps\": 100,\n","    \"max_steps\": 5000,\n","    \"learning_rate\": 1e-4,\n","    \"per_device_train_batch_size\": 16,\n","    \"per_device_eval_batch_size\": 16,\n","    \"weight_decay\": 1e-5,\n","    \"load_best_model_at_end\": True,\n","    \"greater_is_better\":True,\n","    \"metric_for_best_model\": \"f1\",\n","    \"save_strategy\": \"steps\",\n","    \"save_steps\": 100, # Make Early callback bug ?\n","    \"save_total_limit\": 1,\n","}\n","\n","# Training set to fine-tune the NER layer\n","REF_GOLD_DATASET = config.NERDIR / \"02-experiment_2_prepared_datasets/huggingface_ref\"\n","PERO_GOLD_DATASET = config.NERDIR / \"02-experiment_2_prepared_datasets/huggingface_pero\"\n","assert REF_GOLD_DATASET.exists()\n","assert PERO_GOLD_DATASET.exists()\n","\n","REF_GOLD_DATASET, PERO_GOLD_DATASET"]},{"cell_type":"markdown","metadata":{"id":"tnkaloer8ko9","jp-MarkdownHeadingCollapsed":true,"tags":[]},"source":["## 41. Fine-tuning CamemBERT-pretrained for NER on the REFERENCE gold set (manually corrected entries)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ncys7ESN9P-L"},"outputs":[],"source":["from datasets import load_from_disk\n","from util.camembert_util import train_eval_loop, init_model\n","\n","# PATHS\n","MODEL_NAME = config.NERDIR / \"10-camembert_pretrained_model\"\n","\n","train_dev_test = load_from_disk(REF_GOLD_DATASET)\n","\n","local_config = TRAINING_CONFIG.copy()\n","local_config[\"output_dir\"] = config.NERDIR / \"41-camembert_pretrained_finetuned_ref\"\n","\n","# Get the model components\n","model, tokenizer, training_args = init_model(str(MODEL_NAME), local_config)\n","\n","# Run train eval\n","metrics = train_eval_loop(model,\n","                          training_args, \n","                          tokenizer,     \n","                          **train_dev_test, \n","                          patience=5)\n","metrics"]},{"cell_type":"markdown","metadata":{"id":"lTxdl8jYR9Is"},"source":["Run the following if you want to download the model from GColab. It might take a while."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iVweF9OCR5Az"},"outputs":[],"source":["\n","!zip -r \"/tmp/41-experiment_2_finetuned_camembert_pretrained.zip\" $FINETUNED_MODEL_OUTPUT_DIR\n","\n","from google.colab import files\n","files.download(\"/tmp/41-experiment_2_finetuned_camembert_pretrained.zip\")"]},{"cell_type":"markdown","metadata":{"id":"1B4PNjLmKHOn","jp-MarkdownHeadingCollapsed":true,"tags":[]},"source":["## 42 - Fine-tuning CamemBERT for NER on the REFERENCE gold set (manually corrected entries)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"B5jn_dxRkdl_"},"outputs":[],"source":["from datasets import load_from_disk\n","from util.camembert_util import train_eval_loop, init_model\n","\n","MODEL_NAME = \"Jean-Baptiste/camembert-ner\"\n","\n","local_config = TRAINING_CONFIG.copy()\n","local_config[\"output_dir\"] = config.NERDIR / \"42-camembert_finetuned_ref\" \n","\n","train_dev_test = load_from_disk(REF_GOLD_DATASET)\n","\n","# Get the model components\n","model, tokenizer, training_args = init_model(str(MODEL_NAME), local_config)\n","\n","# Run train eval\n","metrics = train_eval_loop(model,\n","                          training_args, \n","                          tokenizer,     \n","                          **train_dev_test,\n","                          patience=5)\n","metrics"]},{"cell_type":"markdown","metadata":{"id":"XhhmnbeA9b3E","jp-MarkdownHeadingCollapsed":true,"outputId":"41ea462a-93ec-4c38-a84d-e5036298970e","tags":[]},"source":["## 43 - Fine-tuning CamemBERT-pretrained for NER on the PERO-OCR gold set (noisy data)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sdO3FTpD9b3E"},"outputs":[],"source":["from datasets import load_from_disk\n","from util.camembert_util import train_eval_loop, init_model\n","\n","MODEL_NAME = \"HueyNemud/das22-10-camembert_pretrained\"\n","\n","local_config = TRAINING_CONFIG.copy()\n","local_config[\"output_dir\"] = config.NERDIR / \"43-camembert_pretrained_finetuned_pero\"\n","\n","train_dev_test = load_from_disk(PERO_GOLD_DATASET)\n","\n","# Get the model components\n","model, tokenizer, training_args = init_model(str(MODEL_NAME), local_config)\n","\n","# Run train eval\n","metrics = train_eval_loop(model,\n","                          training_args, \n","                          tokenizer,     \n","                          **train_dev_test,\n","                          patience=5)\n","metrics"]},{"cell_type":"markdown","metadata":{"id":"O-qIixc8wERT","jp-MarkdownHeadingCollapsed":true,"tags":[]},"source":["## 44 - Fine-tuning CamemBERT for NER on the PERO-OCR gold set (noisy data)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mGTfaqUE9b3G"},"outputs":[],"source":["from datasets import load_from_disk\n","from util.camembert_util import train_eval_loop, init_model\n","\n","MODEL_NAME = \"Jean-Baptiste/camembert-ner\"\n","\n","local_config = TRAINING_CONFIG.copy()\n","local_config[\"output_dir\"] = config.NERDIR / \"44-camembert_finetuned_pero\"\n","\n","train_dev_test = load_from_disk(PERO_GOLD_DATASET)\n","\n","# Get the model components\n","model, tokenizer, training_args = init_model(str(MODEL_NAME), local_config)\n","\n","# Run train eval\n","metrics = train_eval_loop(model,\n","                          training_args, \n","                          tokenizer,     \n","                          **train_dev_test,\n","                          patience=5)\n","metrics"]},{"cell_type":"markdown","metadata":{"id":"8fpUm_9Lg4BQ","tags":[]},"source":["## 45 - Evaluate CamemBERT-pretrained and camembert (simple) on the REF, PERO and TESS test datasets"]},{"cell_type":"markdown","metadata":{"id":"9Z3prFSHPu0q"},"source":["Load the model fine-tuned on the ref data from `BASE/41-experiment_2_finetuned_camembert_pretrained`.\n","\n","If you prefer to use the model shared on huggingface.co, replace `model_path` with `HueyNemud/HueyNemud/das2022-41-berties-pretrained-finetuned-ref`. \n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"12L5q59IFASm"},"outputs":[],"source":["REF_GOLD_DATASET = config.NERDIR / \"02-experiment_2_prepared_datasets/huggingface_ref\"\n","PERO_GOLD_DATASET = config.NERDIR / \"02-experiment_2_prepared_datasets/huggingface_pero\"\n","TESS_GOLD_DATASET = config.NERDIR / \"02-experiment_2_prepared_datasets/huggingface_tess\"\n","\n","REF_GOLD_DATASET, PERO_GOLD_DATASET, TESS_GOLD_DATASET "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8POYc7js9b3H"},"outputs":[],"source":["# Where to store the computed metrics\n","METRICS_OUTPUT = config.NERDIR / \"45-experiment_2_metrics\"\n","METRICS_OUTPUT.mkdir(exist_ok=True, parents=True)\n","METRICS_OUTPUT"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"MEwRhMmC9b3I","executionInfo":{"status":"ok","timestamp":1653384805182,"user_tz":-120,"elapsed":467,"user":{"displayName":"Bertrand Dumenieu","userId":"12153120920884628135"}}},"outputs":[],"source":["#Helper func to predict & save the computed metrics\n","import json\n","from datasets import load_from_disk\n","\n","def eval_save(dataset_path, name):\n","    train_dev_test = load_from_disk(dataset_path)\n","    predictions_ref = trainer.predict(train_dev_test[\"test\"])\n","\n","    with open( METRICS_OUTPUT / f\"camembert_{name}.json\" ,\"w\", encoding=\"utf-8\") as pf:\n","        js = json.dumps(predictions_ref.metrics)\n","        pf.write(js)\n","        js"]},{"cell_type":"markdown","metadata":{"id":"1T_ufD_hg4BU"},"source":["### Evaluate 41-camembert_pretrained_finetuned_ref"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nLg_7CapZTvc"},"outputs":[],"source":["# We won't train so keep it minimalistic\n","dummy_config = {\"output_dir\": \"/tmp\"}\n","\n","# Load the fine-tuned model\n","from transformers import AutoModelForTokenClassification, DataCollatorForTokenClassification, Trainer\n","from util.camembert_util import compute_metrics, init_model\n","\n","\n","model_path = config.NERDIR / \"41-camembert_pretrained_finetuned_ref\"\n","model, tokenizer, training_args = init_model(str(model_path), dummy_config)\n","\n","model.eval() # Switch to evaluation mode\n","\n","data_collator = DataCollatorForTokenClassification(tokenizer)\n","trainer = Trainer(\n","    model,\n","    training_args,\n","    data_collator=data_collator,\n","    tokenizer=tokenizer,\n","    compute_metrics=compute_metrics,\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vKQBu0rDED4r"},"outputs":[],"source":["eval_save(REF_GOLD_DATASET, \"pretrained_ref_test_ref\")\n","eval_save(PERO_GOLD_DATASET, \"pretrained_ref_test_pero\")\n","eval_save(TESS_GOLD_DATASET, \"pretrained_ref_test_tess\")"]},{"cell_type":"markdown","metadata":{"outputId":"d07b4f4d-a813-4bf7-c396-faeb54328aab","id":"tB7G7Dk7ZTvd"},"source":["### Evaluate 42-camembert_finetuned_ref"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cp-OMI9H9b3J"},"outputs":[],"source":["# Load the fine-tuned model\n","from transformers import AutoModelForTokenClassification, DataCollatorForTokenClassification, Trainer\n","from util.camembert_util import compute_metrics\n","\n","# We won't train so keep it minimalistic\n","dummy_config = {\"output_dir\": \"/tmp\"}\n","\n","model_path = config.NERDIR / \"42-camembert_finetuned_ref\"\n","model, tokenizer, training_args = init_model(str(model_path), dummy_config)\n","\n","model.eval() # Switch to evaluation mode\n","\n","data_collator = DataCollatorForTokenClassification(tokenizer)\n","trainer = Trainer(\n","    model,\n","    training_args,\n","    data_collator=data_collator,\n","    tokenizer=tokenizer,\n","    compute_metrics=compute_metrics,\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QPbt2BnLg4Ba"},"outputs":[],"source":["eval_save(REF_GOLD_DATASET, \"ref_test_ref\")\n","eval_save(PERO_GOLD_DATASET, \"ref_test_pero\")\n","eval_save(TESS_GOLD_DATASET, \"ref_test_tess\")"]},{"cell_type":"markdown","metadata":{"id":"2ddPhqn89b3K"},"source":["### Evaluate 43-camembert_pretrained_finetuned_pero"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JFugU6w7v9PM"},"outputs":[],"source":["from transformers import AutoModelForTokenClassification, DataCollatorForTokenClassification, Trainer\n","from util.camembert_util import compute_metrics\n","\n","# We won't train so keep it minimalistic\n","dummy_config = {\"output_dir\": \"/tmp\"}\n","\n","model_path = config.NERDIR / \"43-camembert_pretrained_finetuned_pero\"\n","model, tokenizer, training_args = init_model(str(model_path), dummy_config)\n","\n","model.eval() # Switch to evaluation mode\n","\n","data_collator = DataCollatorForTokenClassification(tokenizer)\n","trainer = Trainer(\n","    model,\n","    training_args,\n","    data_collator=data_collator,\n","    tokenizer=tokenizer,\n","    compute_metrics=compute_metrics,\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_fGGsad-ZTvf"},"outputs":[],"source":["eval_save(REF_GOLD_DATASET, \"pretrained_pero_test_ref\")\n","eval_save(PERO_GOLD_DATASET, \"pretrained_pero_test_pero\")\n","eval_save(TESS_GOLD_DATASET, \"pretrained_pero_test_tess\")"]},{"cell_type":"markdown","metadata":{"id":"J-7d8iwSZTvg"},"source":["### Evaluate 44-camembert_finetuned_pero"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZXf49dpmZTvg"},"outputs":[],"source":["# Load the fine-tuned model\n","from transformers import AutoModelForTokenClassification, DataCollatorForTokenClassification, Trainer\n","from util.camembert_util import compute_metrics\n","\n","# We won't train so keep it minimalistic\n","dummy_config = {\"output_dir\": \"/tmp\"}\n","\n","model_path = config.NERDIR / \"44-camembert_finetuned_pero\"\n","model, tokenizer, training_args = init_model(str(model_path), dummy_config)\n","\n","model.eval() # Switch to evaluation mode\n","\n","data_collator = DataCollatorForTokenClassification(tokenizer)\n","trainer = Trainer(\n","    model,\n","    training_args,\n","    data_collator=data_collator,\n","    tokenizer=tokenizer,\n","    compute_metrics=compute_metrics,\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MRF8c0vKZTvh"},"outputs":[],"source":["eval_save(REF_GOLD_DATASET, \"pero_test_ref\")\n","eval_save(PERO_GOLD_DATASET, \"pero_test_pero\")\n","eval_save(TESS_GOLD_DATASET, \"pero_test_tess\")"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"40_experiment_2.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"}},"nbformat":4,"nbformat_minor":0}