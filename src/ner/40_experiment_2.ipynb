{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9XuqX-_F9u7S",
    "tags": []
   },
   "source": [
    "# 40 - Experiment #2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J62JrWepL_yb",
    "tags": []
   },
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "czKQM7SWKda4",
    "outputId": "b5b7ec53-3769-4c76-9f84-24170e8a5538"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Is this notebook running on Google Colab ?\n",
    "ENV_IS_GOOGLE_COLAB = True if 'google.colab' in str(get_ipython()) else False\n",
    "os.environ[\"ENV_IS_GOOGLE_COLAB\"] = str(ENV_IS_GOOGLE_COLAB)\n",
    "ENV_IS_GOOGLE_COLAB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "69ALvor99p7N"
   },
   "outputs": [],
   "source": [
    "if ENV_IS_GOOGLE_COLAB:\n",
    "  !pip install transformers datasets spacy transformers[sentencepiece] seqeval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cBI-Q1yCNMbZ",
    "outputId": "9b222d80-0189-49f7-919b-9f5fbaa6aa00"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/bertrand/dev/paper-ner-bench-das22/src/ner')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys, os\n",
    "from pathlib import Path\n",
    "\n",
    "# If on GColab, workdir is expected to be in Google Drive\n",
    "# Adapt the value BASE according to your situation\n",
    "\n",
    "if ENV_IS_GOOGLE_COLAB:\n",
    "  from google.colab import drive\n",
    "  mountpoint = Path(\"/content/drive\")\n",
    "  BASE = mountpoint / \"/content/drive/MyDrive/SODUCO/article_das_2022\"\n",
    "  drive.mount(str(mountpoint)) # Mount gdrive immediately\n",
    "  sys.path.append(str(BASE)) # Add BASE to Python Path\n",
    "else:\n",
    "  # Expect all dependencies to be in the same directory as this notebook\n",
    "  BASE = Path(os.path.dirname(os.path.realpath(\"__file__\"))).resolve()\n",
    "\n",
    "BASE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tnkaloer8ko9",
    "tags": []
   },
   "source": [
    "## 41. Fine-tune CamemBERT-pretrained on the gold REFerence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "2UkatZ8v8fSM"
   },
   "outputs": [],
   "source": [
    "# PATHS\n",
    "FINETUNED_MODEL_OUTPUT_DIR = BASE / \"41-experiment_2_finetuned_camembert_pretrained\"\n",
    "\n",
    "REF_GOLD_DATASET = BASE / \"02-experiment_2_prepared_datasets/huggingface_ref\"\n",
    "\n",
    "MODEL_NAME = BASE / \"10-camembert_pretrained_model\"\n",
    "\n",
    "# Same training configuration as in 20-experiment_1\n",
    "TRAINING_CONFIG = {\n",
    "    \"evaluation_strategy\": \"steps\",\n",
    "    \"eval_steps\": 100,\n",
    "    \"max_steps\": 5000,\n",
    "    \"learning_rate\": 1e-4,\n",
    "    \"per_device_train_batch_size\": 16,\n",
    "    \"per_device_eval_batch_size\": 16,\n",
    "    \"weight_decay\": 1e-5,\n",
    "    \"load_best_model_at_end\": True,\n",
    "    \"greater_is_better\":True,\n",
    "    \"metric_for_best_model\": \"f1\",\n",
    "    \"save_strategy\": \"steps\",\n",
    "    \"save_steps\": 100, # Make Early callback bug ?\n",
    "    \"save_total_limit\": 1,\n",
    "    \"output_dir\": FINETUNED_MODEL_OUTPUT_DIR\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "ncys7ESN9P-L"
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "KeyboardInterrupt: ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_349864/2585142211.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_from_disk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcamembert_util\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_eval_loop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtrain_dev_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_from_disk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mREF_GOLD_DATASET\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/datasets/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m     )\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0marrow_dataset\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconcatenate_datasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0marrow_reader\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mArrowReader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mReadInstruction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0marrow_writer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mArrowWriter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpyarrow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpyarrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mhuggingface_hub\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mHfApi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mHfFolder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmultiprocess\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRLock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mrequests\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/huggingface_hub/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mwhoami\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m )\n\u001b[0;32m---> 59\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mhub_mixin\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModelHubMixin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPyTorchModelHubMixin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0minference_api\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInferenceApi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m from .keras_mixin import (\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/huggingface_hub/hub_mixin.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_torch_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mUSE_GLOBAL_DEPS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m         \u001b[0m_load_global_deps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m  \u001b[0;31m# noqa: F403\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[0;31m# Appease the type checker; ordinarily this binding is inserted by the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: KeyboardInterrupt: "
     ]
    }
   ],
   "source": [
    "from datasets import load_from_disk\n",
    "from camembert_util import train_eval_loop, init_model\n",
    "\n",
    "train_dev_test = load_from_disk(REF_GOLD_DATASET)\n",
    "\n",
    "# Get the model components\n",
    "model, tokenizer, training_args = init_model(str(MODEL_NAME), TRAINING_CONFIG)\n",
    "\n",
    "# Run train eval\n",
    "metrics = train_eval_loop(model,\n",
    "                          training_args, \n",
    "                          tokenizer,     \n",
    "                          **train_dev_test, \n",
    "                          patience=5)\n",
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lTxdl8jYR9Is"
   },
   "source": [
    "Run the following if you want to download the model from GColab. It might take a while."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iVweF9OCR5Az"
   },
   "outputs": [],
   "source": [
    "if ENV_IS_GOOGLE_COLAB:\n",
    "  !zip -r \"/tmp/41-experiment_2_finetuned_camembert_pretrained.zip\" $FINETUNED_MODEL_OUTPUT_DIR\n",
    "\n",
    "  from google.colab import files\n",
    "  files.download(\"/tmp/41-experiment_2_finetuned_camembert_pretrained.zip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1B4PNjLmKHOn",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 42 - Fine-tune Camembert on the gold REFerence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2dRsGWkJg4BP",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# PATHS\n",
    "\n",
    "REF_GOLD_DATASET = BASE / \"02-experiment_2_prepared_datasets/huggingface_ref\"\n",
    "\n",
    "MODEL_NAME = \"Jean-Baptiste/camembert-ner\"\n",
    "\n",
    "# Same training configuration as in 41...\n",
    "assert TRAINING_CONFIG\n",
    "# ... but change the output directory\n",
    "TRAINING_CONFIG[\"output_dir\"] = BASE / \"42-experiment_2_camembert\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "8daec121e8be4b5f9f1d49b5dce0b1f7",
      "de877a024065479094fd780f81091c66",
      "be8101d807a04038b794913be92cf559",
      "ea1dcba8b1f64af9975ad70d99143942",
      "b6359eb2a90e43418179d4bfa5697b78",
      "39446697106642b7982eab8cd72eab3c",
      "9d70757fe052453fb4ddbf15cb99d5fe",
      "6cdd5c85bb2842b1beee28e4575c2af3",
      "d6cc64ccc64644e0aad8c06773c9996a",
      "e28d07f797d1410e8257e0c974aa5cf5",
      "644146b7d40c49359d64d030bb5aaf22"
     ]
    },
    "id": "B5jn_dxRkdl_",
    "outputId": "41ea462a-93ec-4c38-a84d-e5036298970e"
   },
   "outputs": [],
   "source": [
    "from datasets import load_from_disk\n",
    "from camembert_util import train_eval_loop, init_model\n",
    "\n",
    "train_dev_test = load_from_disk(REF_GOLD_DATASET)\n",
    "\n",
    "# Get the model components\n",
    "model, tokenizer, training_args = init_model(str(MODEL_NAME), TRAINING_CONFIG)\n",
    "\n",
    "# Run train eval\n",
    "metrics = train_eval_loop(model,\n",
    "                          training_args, \n",
    "                          tokenizer,     \n",
    "                          **train_dev_test,\n",
    "                          patience=5)\n",
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8fpUm_9Lg4BQ",
    "tags": []
   },
   "source": [
    "## 43 - Evaluate CamemBERT-pretrained and camembert (simple) on the REF, PERO and TESS test datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9Z3prFSHPu0q"
   },
   "source": [
    "Load the model fine-tuned on the ref data from `BASE/41-experiment_2_finetuned_camembert_pretrained`.\n",
    "\n",
    "If you prefer to use the model shared on huggingface.co, replace `model_path` with `HueyNemud/HueyNemud/das2022-41-berties-pretrained-finetuned-ref`. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "12L5q59IFASm",
    "outputId": "db231b92-fa79-4666-eb04-c39ebbfb1916"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(PosixPath('/home/bertrand/dev/paper-ner-bench-das22/src/ner/02-experiment_2_prepared_datasets/huggingface_ref'),\n",
       " PosixPath('/home/bertrand/dev/paper-ner-bench-das22/src/ner/02-experiment_2_prepared_datasets/huggingface_pero'),\n",
       " PosixPath('/home/bertrand/dev/paper-ner-bench-das22/src/ner/02-experiment_2_prepared_datasets/huggingface_tess'))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "REF_GOLD_DATASET = BASE / \"02-experiment_2_prepared_datasets/huggingface_ref\"\n",
    "PERO_GOLD_DATASET = BASE / \"02-experiment_2_prepared_datasets/huggingface_pero\"\n",
    "TESS_GOLD_DATASET = BASE / \"02-experiment_2_prepared_datasets/huggingface_tess\"\n",
    "\n",
    "REF_GOLD_DATASET, PERO_GOLD_DATASET, TESS_GOLD_DATASET "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "12L5q59IFASm",
    "outputId": "db231b92-fa79-4666-eb04-c39ebbfb1916"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/bertrand/dev/paper-ner-bench-das22/src/ner/43-experiment_2_metrics')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Where to store the computed metrics\n",
    "METRICS_OUTPUT = BASE / \"43-experiment_2_metrics\"\n",
    "METRICS_OUTPUT.mkdir(exist_ok=True, parents=True)\n",
    "METRICS_OUTPUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "12L5q59IFASm",
    "outputId": "db231b92-fa79-4666-eb04-c39ebbfb1916"
   },
   "outputs": [],
   "source": [
    "#Helper func to predict & save the computed metrics\n",
    "import json\n",
    "from datasets import load_from_disk\n",
    "\n",
    "def eval_save(dataset_path, name):\n",
    "    train_dev_test = load_from_disk(dataset_path)\n",
    "    predictions_ref = trainer.predict(train_dev_test[\"test\"])\n",
    "\n",
    "    with open( METRICS_OUTPUT / f\"camembert_{name}.json\" ,\"w\", encoding=\"utf-8\") as pf:\n",
    "        js = json.dumps(predictions_ref.metrics)\n",
    "        pf.write(js)\n",
    "        js"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1T_ufD_hg4BU",
    "outputId": "ff83d6cc-7dab-4b00-aa75-1e251f11fa1a"
   },
   "outputs": [],
   "source": [
    "# We won't train so keep it minimalistic\n",
    "dummy_config = {\"output_dir\": \"/tmp\"}\n",
    "\n",
    "# Load the fine-tuned model\n",
    "from transformers import AutoModelForTokenClassification, DataCollatorForTokenClassification, Trainer\n",
    "from camembert_util import compute_metrics, init_model\n",
    "\n",
    "\n",
    "model_path = BASE / \"41-experiment_2_finetuned_camembert_pretrained\"\n",
    "model, tokenizer, training_args = init_model(str(model_path), dummy_config)\n",
    "\n",
    "model.eval() # Switch to evaluation mode\n",
    "\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer)\n",
    "trainer = Trainer(\n",
    "    model,\n",
    "    training_args,\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 252
    },
    "id": "vKQBu0rDED4r",
    "outputId": "d07b4f4d-a813-4bf7-c396-faeb54328aab"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set  don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: tokens, ner_tags.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1669\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='627' max='209' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [209/209 02:33]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bertrand/anaconda3/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "The following columns in the test set  don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: tokens, ner_tags.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1669\n",
      "  Batch size = 8\n",
      "The following columns in the test set  don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: tokens, ner_tags.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1669\n",
      "  Batch size = 8\n"
     ]
    }
   ],
   "source": [
    "eval_save(REF_GOLD_DATASET, \"pretrained_ref\")\n",
    "eval_save(PERO_GOLD_DATASET, \"pretrained_pero\")\n",
    "eval_save(TESS_GOLD_DATASET, \"pretrained_tess\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16/01/2022 11:29:13 ; INFO ; Model /home/bertrand/dev/paper-ner-bench-das22/src/ner/42-experiment_2_finetuned_camembert\n",
      "Didn't find file /home/bertrand/dev/paper-ner-bench-das22/src/ner/42-experiment_2_finetuned_camembert/added_tokens.json. We won't load it.\n",
      "loading file /home/bertrand/dev/paper-ner-bench-das22/src/ner/42-experiment_2_finetuned_camembert/sentencepiece.bpe.model\n",
      "loading file /home/bertrand/dev/paper-ner-bench-das22/src/ner/42-experiment_2_finetuned_camembert/tokenizer.json\n",
      "loading file None\n",
      "loading file /home/bertrand/dev/paper-ner-bench-das22/src/ner/42-experiment_2_finetuned_camembert/special_tokens_map.json\n",
      "loading file /home/bertrand/dev/paper-ner-bench-das22/src/ner/42-experiment_2_finetuned_camembert/tokenizer_config.json\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "loading configuration file /home/bertrand/dev/paper-ner-bench-das22/src/ner/42-experiment_2_finetuned_camembert/config.json\n",
      "Model config CamembertConfig {\n",
      "  \"_name_or_path\": \"/home/bertrand/dev/paper-ner-bench-das22/src/ner/42-experiment_2_finetuned_camembert\",\n",
      "  \"architectures\": [\n",
      "    \"CamembertForTokenClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 5,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 6,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"O\",\n",
      "    \"1\": \"I-LOC\",\n",
      "    \"2\": \"I-PER\",\n",
      "    \"3\": \"I-MISC\",\n",
      "    \"4\": \"I-ORG\",\n",
      "    \"5\": \"I-CARDINAL\",\n",
      "    \"6\": \"I-ACT\",\n",
      "    \"7\": \"I-TITRE\",\n",
      "    \"8\": \"I-FT\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"I-ACT\": 6,\n",
      "    \"I-CARDINAL\": 5,\n",
      "    \"I-FT\": 8,\n",
      "    \"I-LOC\": 1,\n",
      "    \"I-MISC\": 3,\n",
      "    \"I-ORG\": 4,\n",
      "    \"I-PER\": 2,\n",
      "    \"I-TITRE\": 7,\n",
      "    \"O\": 0\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"camembert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.15.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32005\n",
      "}\n",
      "\n",
      "loading weights file /home/bertrand/dev/paper-ner-bench-das22/src/ner/42-experiment_2_finetuned_camembert/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing CamembertForTokenClassification.\n",
      "\n",
      "All the weights of CamembertForTokenClassification were initialized from the model checkpoint at /home/bertrand/dev/paper-ner-bench-das22/src/ner/42-experiment_2_finetuned_camembert.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use CamembertForTokenClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "# Load the fine-tuned model\n",
    "from transformers import AutoModelForTokenClassification, DataCollatorForTokenClassification, Trainer\n",
    "from camembert_util import compute_metrics\n",
    "\n",
    "# We won't train so keep it minimalistic\n",
    "dummy_config = {\"output_dir\": \"/tmp\"}\n",
    "\n",
    "model_path = BASE / \"42-experiment_2_finetuned_camembert\"\n",
    "model, tokenizer, training_args = init_model(str(model_path), dummy_config)\n",
    "\n",
    "model.eval() # Switch to evaluation mode\n",
    "\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer)\n",
    "trainer = Trainer(\n",
    "    model,\n",
    "    training_args,\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "QPbt2BnLg4Ba"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set  don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: tokens, ner_tags.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1669\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='627' max='209' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [209/209 02:31]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set  don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: tokens, ner_tags.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1669\n",
      "  Batch size = 8\n",
      "The following columns in the test set  don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: tokens, ner_tags.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1669\n",
      "  Batch size = 8\n"
     ]
    }
   ],
   "source": [
    "eval_save(REF_GOLD_DATASET, \"simple_ref\")\n",
    "eval_save(PERO_GOLD_DATASET, \"simple_pero\")\n",
    "eval_save(TESS_GOLD_DATASET, \"simple_tess\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "40_experiment_2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "39446697106642b7982eab8cd72eab3c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "644146b7d40c49359d64d030bb5aaf22": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6cdd5c85bb2842b1beee28e4575c2af3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "8daec121e8be4b5f9f1d49b5dce0b1f7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_be8101d807a04038b794913be92cf559",
       "IPY_MODEL_ea1dcba8b1f64af9975ad70d99143942",
       "IPY_MODEL_b6359eb2a90e43418179d4bfa5697b78"
      ],
      "layout": "IPY_MODEL_de877a024065479094fd780f81091c66"
     }
    },
    "9d70757fe052453fb4ddbf15cb99d5fe": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b6359eb2a90e43418179d4bfa5697b78": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_644146b7d40c49359d64d030bb5aaf22",
      "placeholder": "​",
      "style": "IPY_MODEL_e28d07f797d1410e8257e0c974aa5cf5",
      "value": " 420M/420M [00:14&lt;00:00, 36.2MB/s]"
     }
    },
    "be8101d807a04038b794913be92cf559": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9d70757fe052453fb4ddbf15cb99d5fe",
      "placeholder": "​",
      "style": "IPY_MODEL_39446697106642b7982eab8cd72eab3c",
      "value": "Downloading: 100%"
     }
    },
    "d6cc64ccc64644e0aad8c06773c9996a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "de877a024065479094fd780f81091c66": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e28d07f797d1410e8257e0c974aa5cf5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ea1dcba8b1f64af9975ad70d99143942": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d6cc64ccc64644e0aad8c06773c9996a",
      "max": 440227047,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_6cdd5c85bb2842b1beee28e4575c2af3",
      "value": 440227047
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
