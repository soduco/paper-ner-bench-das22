{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2552858d-7386-4e9a-8b0e-c338b920f783",
   "metadata": {},
   "source": [
    "# 20 - Experiment #1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ddcc84-3134-41bb-8c3c-f9e902a8cfb9",
   "metadata": {},
   "source": [
    "**Requirements** \n",
    "\n",
    "Do not forget to install the SpaCy pipeline `fr_core_news_lg` before running Experiment 1:\n",
    "```bash\n",
    "python -m spacy download fr_core_news_lg\n",
    "```\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06332f9f-37d5-4a0c-9af6-1f2bda236789",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# CONSTANTS\n",
    "N_RUNS = 1 # Run the trainings only once per trainset size \n",
    "\n",
    "# Expected datasets indexed by number of examples in the trainset\n",
    "#INTPUT_DATASETS_SIZES = [49,99,199,398,769,1593,3186,6373]\n",
    "INPUT_DATASETS_SIZES = [398]\n",
    "\n",
    "WORK_DIR = Path(os.path.dirname(os.path.realpath(\"__file__\"))) / \"20-experiment_1\"\n",
    "\n",
    "\n",
    "# SPACY\n",
    "SPACY_NER_METRICS_DIR = WORK_DIR / \"21-spacy_ner_metrics\"\n",
    "SPACY_NER_METRICS_DIR.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "SPACY_USE_GPU = -1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3113af67-7896-4a87-a904-26130e5cb47d",
   "metadata": {},
   "source": [
    "## 21. SpaCy NER pipeline - train & eval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12227aaa-8696-4e34-af69-186a3043dd2d",
   "metadata": {},
   "source": [
    "Train the SpaCy pipeline on the NER task for each trainset created in step 00.\n",
    "\n",
    "Chage N_RUNS to do multiple runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28c86974-f989-406c-b4da-1e881457e333",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16/01/2022 01:31:51 ; INFO ; SpaCy run #1, will save in /home/bertrand/dev/paper-ner-bench-das22/src/ner/20-experiment_1/21-spacy_ner_metrics/run_1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;4mℹ Saving to output directory:\n",
      "/home/bertrand/dev/paper-ner-bench-das22/src/ner/20-experiment_1/21-spacy_ner_metrics/run_1\u001b[0m\n",
      "\u001b[38;5;4mℹ Using CPU\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== Initializing pipeline ===========================\u001b[0m\n",
      "\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n",
      "\u001b[1m\n",
      "============================= Training pipeline =============================\u001b[0m\n",
      "\u001b[38;5;4mℹ Pipeline: ['tok2vec', 'ner']\u001b[0m\n",
      "\u001b[38;5;4mℹ Initial learn rate: 0.001\u001b[0m\n",
      "E    #       LOSS TOK2VEC  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
      "---  ------  ------------  --------  ------  ------  ------  ------\n",
      "\u001b[38;5;3m⚠ Aborting and saving the final best model. Encountered exception:\n",
      "FileNotFoundError(2, 'No such file or directory')\u001b[0m\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/bertrand/dev/paper-ner-bench-das22/src/ner/20-experiment_1/spacy_train_398.spacy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_276530/4267775958.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;31m# Train now !\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         train.train(\"cnn_config.cfg\",       # The pipeline configuration file\n\u001b[0m\u001b[1;32m     25\u001b[0m                     \u001b[0mRUN_OUTPUT_DIR\u001b[0m\u001b[0;34m,\u001b[0m         \u001b[0;31m# save model_best and model_last here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m                     \u001b[0muse_gpu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSPACY_USE_GPU\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Use GPU if asked\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/spacy/cli/train.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(config_path, output_path, use_gpu, overrides)\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0mmsg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgood\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Initialized pipeline\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0mmsg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdivider\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training pipeline\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m     \u001b[0mtrain_nlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnlp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_gpu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_gpu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstdout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/spacy/training/loop.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(nlp, output_path, use_gpu, stdout, stderr)\u001b[0m\n\u001b[1;32m    120\u001b[0m                 \u001b[0;34m+\u001b[0m \u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             )\n\u001b[0;32m--> 122\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0mfinalize_logger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/spacy/training/loop.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(nlp, output_path, use_gpu, stdout, stderr)\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0mlog_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinalize_logger\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_logger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnlp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_best_checkpoint\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtraining_step_iterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_best_checkpoint\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect_pipes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdisable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfrozen_components\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/spacy/training/loop.py\u001b[0m in \u001b[0;36mtrain_while_improving\u001b[0;34m(nlp, optimizer, train_data, evaluate, dropout, eval_frequency, accumulate_gradient, patience, max_steps, exclude, annotating_components)\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0mwords_seen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m         \u001b[0mdropout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdropouts\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0msubbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msubdivide_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccumulate_gradient\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/spacy/training/loop.py\u001b[0m in \u001b[0;36mcreate_train_batches\u001b[0;34m(nlp, corpus, batcher, max_epochs)\u001b[0m\n\u001b[1;32m    311\u001b[0m     \u001b[0mepoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmax_epochs\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 313\u001b[0;31m         \u001b[0mexamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnlp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: Iterable[Example]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    314\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mexamples\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m             \u001b[0;31m# Raise error if no data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/spacy/training/corpus.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, nlp)\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m             \u001b[0mexamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_examples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnlp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref_docs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mreal_eg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mexamples\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0maugmented_eg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maugmenter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnlp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreal_eg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# type: ignore[operator]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0maugmented_eg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/spacy/training/corpus.py\u001b[0m in \u001b[0;36mmake_examples\u001b[0;34m(self, nlp, reference_docs)\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"Language\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreference_docs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIterable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mDoc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m     ) -> Iterator[Example]:\n\u001b[0;32m--> 164\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mreference\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreference_docs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreference\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/spacy/training/corpus.py\u001b[0m in \u001b[0;36mread_docbin\u001b[0;34m(self, vocab, locs)\u001b[0m\n\u001b[1;32m    195\u001b[0m             \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFILE_TYPE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# type: ignore[union-attr]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m                 \u001b[0mdoc_bin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDocBin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_disk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m                 \u001b[0mdocs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdoc_bin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_docs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdocs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/spacy/tokens/_serialize.py\u001b[0m in \u001b[0;36mfrom_disk\u001b[0;34m(self, path)\u001b[0m\n\u001b[1;32m    269\u001b[0m         \"\"\"\n\u001b[1;32m    270\u001b[0m         \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile_\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    272\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/pathlib.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, mode, buffering, encoding, errors, newline)\u001b[0m\n\u001b[1;32m   1250\u001b[0m         \u001b[0mthe\u001b[0m \u001b[0mbuilt\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;32min\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0mfunction\u001b[0m \u001b[0mdoes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1251\u001b[0m         \"\"\"\n\u001b[0;32m-> 1252\u001b[0;31m         return io.open(self, mode, buffering, encoding, errors, newline,\n\u001b[0m\u001b[1;32m   1253\u001b[0m                        opener=self._opener)\n\u001b[1;32m   1254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/pathlib.py\u001b[0m in \u001b[0;36m_opener\u001b[0;34m(self, name, flags, mode)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_opener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0o666\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m         \u001b[0;31m# A stub for the opener argument to built-in open()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1120\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accessor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_raw_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0o777\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/bertrand/dev/paper-ner-bench-das22/src/ner/20-experiment_1/spacy_train_398.spacy'"
     ]
    }
   ],
   "source": [
    "from spacy.cli import train, evaluate\n",
    "from config import logger\n",
    "\n",
    "# Train & evaluate loop\n",
    "for run in range(1, N_RUNS + 1):\n",
    "    RUN_OUTPUT_DIR = SPACY_NER_METRICS_DIR / f\"run_{run}\"\n",
    "    RUN_OUTPUT_DIR.mkdir(exist_ok=True)\n",
    "    \n",
    "    logger.info(f\"SpaCy run #{run}, will save in {RUN_OUTPUT_DIR}\")\n",
    "    \n",
    "    for trainset_size in INPUT_DATASETS_SIZES:\n",
    "        # paths to datasets\n",
    "        trainset = WORK_DIR / f\"spacy_train_{trainset_size}.spacy\"\n",
    "        devset = WORK_DIR / f\"spacy_dev_{trainset_size}.spacy\"\n",
    "        testset = WORK_DIR / f\"spacy_test_{trainset_size}.spacy\"\n",
    "\n",
    "        # Pass train & dev paths as SpaCy config items\n",
    "        spacy_opts = {\n",
    "            \"paths.train\": str(trainset),\n",
    "            \"paths.dev\": str(devset),\n",
    "        }\n",
    "        \n",
    "        # Train now !\n",
    "        train.train(\"cnn_config.cfg\",       # The pipeline configuration file\n",
    "                    RUN_OUTPUT_DIR,         # save model_best and model_last here\n",
    "                    use_gpu=SPACY_USE_GPU,  # Use GPU if asked\n",
    "                    overrides=spacy_opts)   # Pass training options\n",
    "\n",
    "        model_best = RUN_OUTPUT_DIR / \"model_best\"\n",
    "        \n",
    "        # Compute metrics on the test set\n",
    "        metrics_file = RUN_OUTPUT_DIR / f\"test_{trainsets}.json\"\n",
    "        evaluate(model_best,                      # Where is the trained model\n",
    "                 testset,                         # Test dataset\n",
    "                 metrics_file,                    # Save metrics here\n",
    "                 use_gpu=SPACY_USE_GPU,           # Use GPU if asked\n",
    "                 displacy_path=RUN_OUTPUT_DIR,    # Save a few tagged results to be shown with displacy\n",
    "                 displacy_limit=100)              # How much is \"a few\"\n",
    "        \n",
    "        # Compute metrics on the dev set\n",
    "        metrics_file = RUN_OUTPUT_DIR / f\"dev_{trainsets}.json\"\n",
    "        evaluate(model_best,                      # Where is the trained model\n",
    "                 devset,                          # Dev dataset\n",
    "                 metrics_file,                    # Save metrics here\n",
    "                 use_gpu=SPACY_USE_GPU,           # Use GPU if asked\n",
    "                 displacy_path=RUN_OUTPUT_DIR,    # Save a few tagged results to be shown with displacy\n",
    "                 displacy_limit=100)              # How much is \"a few\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b18a5bc-1abb-450d-90d3-6a7e56f773ed",
   "metadata": {},
   "source": [
    "## 22. CamemBERT - Common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91140aa5-b377-47c1-bd44-844cd9365ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMMON CONSTANTS\n",
    "\n",
    "TRAINING_CONFIG = {\n",
    "    \"evaluation_strategy\": \"steps\",\n",
    "    \"eval_steps\": 100,\n",
    "    \"max_steps\": 5000,\n",
    "    \"learning_rate\": 1e-4,\n",
    "    \"per_device_train_batch_size\": 16,\n",
    "    \"per_device_eval_batch_size\": 16,\n",
    "    \"weight_decay\": 1e-5,\n",
    "    \"load_best_model_at_end\": True,\n",
    "    \"greater_is_better\":True,\n",
    "    \"metric_for_best_model\": \"f1\",\n",
    "    \"save_strategy\": \"steps\",\n",
    "    \"save_steps\": 100, # Make Early callback bug ?\n",
    "    \"save_total_limit\": 1,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e821087-3623-4c14-a8fb-63dcc98dc1d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import logger\n",
    "from datasets import load_from_disk\n",
    "from camembert_util import train_eval_loop\n",
    "\n",
    "def train_bert():\n",
    "    # Train & evaluate loop\n",
    "    for run in range(1, N_RUNS + 1):\n",
    "        RUN_OUTPUT_DIR = CAMEMBERT_METRICS_DIR / f\"run_{run}\"\n",
    "        RUN_OUTPUT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "        logger.info(f\"{model} #{run}, will save in {RUN_OUTPUT_DIR}\")\n",
    "\n",
    "        for trainset_size in INPUT_DATASETS_SIZES:\n",
    "            datasetdir = WORK_DIR / f\"huggingface_{trainset_size}\"\n",
    "\n",
    "            logger.info(f\"Running on datasets in {datasetdir}\")\n",
    "            logger.info(f\"Metrics will be saved in {RUN_OUTPUT_DIR}\")\n",
    "\n",
    "            # Train now !\n",
    "            train_dev_test = load_from_disk(datasetdir)\n",
    "            metrics = train_eval_loop(model, # Implicit\n",
    "                                      training_args, # Implicit\n",
    "                                      tokenizer, # Implicit\n",
    "                                      **train_dev_test)\n",
    "\n",
    "            # Save the metrics\n",
    "            metrics_file = RUN_OUTPUT_DIR / f\"test_{trainsets}.json\"\n",
    "            with open(f\"{metrics_file}_test.json\", \"w\", encoding=\"utf-8\") as o:\n",
    "                json.dump(metrics[0], o)\n",
    "\n",
    "            metrics_file = RUN_OUTPUT_DIR / f\"dev_{trainsets}.json\"\n",
    "            with open(f\"{metrics_file}_dev.json\", \"w\", encoding=\"utf-8\") as o:\n",
    "                json.dump(metrics[1], o)\n",
    "\n",
    "\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09de0446-e62f-46d5-ae73-34112f3c420d",
   "metadata": {},
   "source": [
    "## 23 - CamemBERT - train & eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c808f0e4-1b8a-43d7-9b16-256e60faf339",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CAMEMBERT\n",
    "CAMEMBERT_METRICS_DIR = WORK_DIR / \"22-camembert_metrics\"\n",
    "CAMEMBERT_METRICS_DIR.mkdir(exist_ok=True, parents=True)\n",
    "CAMEMBERT_MODEL = \"Jean-Baptiste/camembert-ner\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05387e39-dd69-491e-9517-57490356e5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from camembert_util import init_model\n",
    "\n",
    "# Get the model components\n",
    "model, tokenizer, training_args = init_model(CAMEMBERT_MODEL, TRAINING_CONFIG)\n",
    "\n",
    "# Run the main loop\n",
    "train_bert()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17cd632b-99a9-4c85-aafc-72b7b0615d60",
   "metadata": {},
   "source": [
    "## 23 - CamemBERT pretrained - train & eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af0b70e9-fc3e-47da-b231-002d329a2932",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CAMEMBERT-PRETRAINED\n",
    "CAMEMBERT_PRETRAINED_METRICS_DIR = WORK_DIR / \"23-camembert_pretrained_metrics\"\n",
    "CAMEMBERT_PRETRAINED_METRICS_DIR.mkdir(exist_ok=True, parents=True)\n",
    "CAMEMBERT_PRETRAINED_MODEL = \"HueyNemud/berties-pretrained-das22\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3459be-8661-40f4-a9dc-e4bc03f9cb53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from camembert import init_model\n",
    "\n",
    "# Get the model components\n",
    "model, tokenizer, training_args = init_model(CAMEMBERT_MODEL, TRAINING_CONFIG)\n",
    "\n",
    "# Run the main loop\n",
    "train_bert()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
