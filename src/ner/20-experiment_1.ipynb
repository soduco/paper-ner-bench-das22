{"cells":[{"cell_type":"markdown","metadata":{"id":"294705ff-9e89-499f-a41f-9494362be5f9"},"source":["# 20 - Experiment #1\n","\n","This notebook contains the code to perform the experiment #1 explained in the section #5 of the paper."]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":309,"status":"ok","timestamp":1653321989161,"user":{"displayName":"Bertrand Dumenieu","userId":"12153120920884628135"},"user_tz":-120},"id":"41a270f9-5f9e-449e-bbff-69136b383507"},"outputs":[],"source":["\"\"\" MAIN CONTROLS \"\"\"\n","\n","# CONTROLS\n","RUN_SPACY = True                  # Set to false to skip training SpaCy NER\n","RUN_CAMEMBERT = True             # Set to false to skip training Camembert\n","RUN_CAMEMBERT_PRETRAINED = True  # Set to false to skip training Camembert pretrained\n","\n","# Number of times a model will be trained \u0026 evaluated on each of the 8 trainsets.\n","N_RUNS = 1"]},{"cell_type":"markdown","metadata":{"id":"cZvwNIzqBwDs"},"source":["## Initialisation\n","\n","The initialisation step:\n","- set up the environment on Google Colab (optional).\n","- sets the random seed SPLIT_SEED to use in all training set generation to ensure repeatable results\n","- creates logger named nerlogger\n","- defines the paths to the directories used by the NER notebooks\n","- imports all the modules used in this notebook\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6MrDdXgLqtZb"},"outputs":[],"source":["\"\"\" RUN THIS BLOCK ONLY ON GOOGLE COLAB \"\"\"\n","\n","# `GDRIVE_PAPER_FOLDER` is the relative path in your GDrive to the folder\n","# contaning the code of the paper\n","# ADAPT TO YOUR SITUATION !\n","%env GDRIVE_PAPER_FOLDER=TEST\n","\n","# Mount Google Drive to your Colab environment. May require to log in to Google.\n","from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)\n","\n","# Copy the Python modules in `PATH_TO_SOURCES/src/ner/util` to GColab\n","# to enable import.\n","!cp -r /content/drive/MyDrive/$GDRIVE_PAPER_FOLDER/src/ner/util .\n","\n","# Copy the spacy configuration\n","!cp -r /content/drive/MyDrive/$GDRIVE_PAPER_FOLDER/src/ner/cnn_config.cfg .\n","\n","# Install dependencies\n","!pip install -q datasets transformers[sentencepiece]\n","# Force update SpaCy to v3 and NLTK\n","!pip install -qU spacy"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21,"status":"ok","timestamp":1653322069493,"user":{"displayName":"Bertrand Dumenieu","userId":"12153120920884628135"},"user_tz":-120},"id":"LWJVak2mB6bI","outputId":"732adf89-2c25-4c8a-f0b6-a7a4d9b2fb46"},"outputs":[{"name":"stderr","output_type":"stream","text":["23/05/2022 04:07:50 ; INFO ; ======= CONFIGURATION =======\n","23/05/2022 04:07:50 ; INFO ; BASEDIR: /content/drive/MyDrive/TEST\n","23/05/2022 04:07:50 ; INFO ; Input datasets will be loaded from DATASETDIR /content/drive/MyDrive/TEST/dataset\n","23/05/2022 04:07:50 ; INFO ; Training data and models will be saved to NERDIR /content/drive/MyDrive/TEST/src/ner\n","23/05/2022 04:07:50 ; INFO ; Debug mode is ON\n","23/05/2022 04:07:50 ; INFO ; Random seed: 42\n","23/05/2022 04:07:50 ; INFO ; Enable reproducibility checks: True\n","23/05/2022 04:07:50 ; INFO ; ============================\n"]},{"name":"stdout","output_type":"stream","text":["env: DEBUG=1\n","env: AS_IN_THE_PAPER=True\n"]}],"source":["\"\"\" Loads the configuration \"\"\"\n","\n","# Set to 1/true/ to set the logging level of nerlogger to DEBUG \n","# and save the the spacy datasets as TXT along with the .spacy file\n","#  for easier debug of the training set generation.\n","%env DEBUG=1\n","\n","# If True, activates a set of assertions in the notebooks to ensure\n","# that the scripts runs with the parameters used in the paper.\n","%env AS_IN_THE_PAPER = True\n","\n","import util.config as config\n","\n","config.show()\n"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1295,"status":"ok","timestamp":1653322086986,"user":{"displayName":"Bertrand Dumenieu","userId":"12153120920884628135"},"user_tz":-120},"id":"82081821","outputId":"124a8ab6-0458-4113-d1f9-1e54a34df69c"},"outputs":[{"data":{"text/plain":["(PosixPath('/content/drive/MyDrive/TEST/src/ner/01-experiment_1_prepared_datasets'),\n"," PosixPath('/content/drive/MyDrive/TEST/src/ner/20-experiment_1_metrics'))"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["\"\"\" Import all modules at once \"\"\"\n","\n","# General imports\n","import os\n","import pathlib\n","import nltk\n","import tempfile\n","import json\n","\n","# NER imports\n","from util.as_in_the_paper import assert_expected\n","\n","# Expected datasets indexed by number of examples in the trainset\n","TRAINSETS_SIZES = [49,99,199,398,796,1593,3186,6373]\n","\n","# INPUT / OUTPUT DIRS\n","INPUT_DIR = config.NERDIR / \"01-experiment_1_prepared_datasets\"\n","METRICS_OUTPUT_DIR = config.NERDIR / \"20-experiment_1_metrics\"\n","INPUT_DIR, METRICS_OUTPUT_DIR"]},{"cell_type":"markdown","metadata":{"id":"3113af67-7896-4a87-a904-26130e5cb47d"},"source":["## 21. SpaCy NER pipeline - train \u0026 eval"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":246,"status":"ok","timestamp":1653322101638,"user":{"displayName":"Bertrand Dumenieu","userId":"12153120920884628135"},"user_tz":-120},"id":"34cc9601-6e2b-4e71-90b7-6889104dcfb1"},"outputs":[],"source":["# SPACY CONSTS\n","SPACY_NER_METRICS_DIR = METRICS_OUTPUT_DIR / \"21-spacy_ner\"\n","SPACY_NER_METRICS_DIR.mkdir(exist_ok=True, parents=True)\n","\n","# Spacy's model be overwritten by each run \u0026 for each trainset size.\n","# The last model will be trained on the largest trainset.\n","SPACY_OUTPUT_MODEL_PATH = pathlib.Path(tempfile.gettempdir())\n","SPACY_USE_GPU = -1"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":45793,"status":"ok","timestamp":1653322305510,"user":{"displayName":"Bertrand Dumenieu","userId":"12153120920884628135"},"user_tz":-120},"id":"4UDQj_j3PdV9","outputId":"97f32ce8-255e-47a2-a75a-44c2c349e1ce"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting fr-core-news-lg==3.3.0\n","  Downloading https://github.com/explosion/spacy-models/releases/download/fr_core_news_lg-3.3.0/fr_core_news_lg-3.3.0-py3-none-any.whl (571.8 MB)\n","\u001b[K     |████████████████████████████████| 571.8 MB 12 kB/s \n","\u001b[?25hRequirement already satisfied: spacy\u003c3.4.0,\u003e=3.3.0.dev0 in /usr/local/lib/python3.7/dist-packages (from fr-core-news-lg==3.3.0) (3.3.0)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,\u003c1.9.0,\u003e=1.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy\u003c3.4.0,\u003e=3.3.0.dev0-\u003efr-core-news-lg==3.3.0) (1.8.2)\n","Requirement already satisfied: numpy\u003e=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy\u003c3.4.0,\u003e=3.3.0.dev0-\u003efr-core-news-lg==3.3.0) (1.21.6)\n","Requirement already satisfied: spacy-loggers\u003c2.0.0,\u003e=1.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy\u003c3.4.0,\u003e=3.3.0.dev0-\u003efr-core-news-lg==3.3.0) (1.0.2)\n","Requirement already satisfied: pathy\u003e=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy\u003c3.4.0,\u003e=3.3.0.dev0-\u003efr-core-news-lg==3.3.0) (0.6.1)\n","Requirement already satisfied: blis\u003c0.8.0,\u003e=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy\u003c3.4.0,\u003e=3.3.0.dev0-\u003efr-core-news-lg==3.3.0) (0.4.1)\n","Requirement already satisfied: catalogue\u003c2.1.0,\u003e=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy\u003c3.4.0,\u003e=3.3.0.dev0-\u003efr-core-news-lg==3.3.0) (2.0.7)\n","Requirement already satisfied: spacy-legacy\u003c3.1.0,\u003e=3.0.9 in /usr/local/lib/python3.7/dist-packages (from spacy\u003c3.4.0,\u003e=3.3.0.dev0-\u003efr-core-news-lg==3.3.0) (3.0.9)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy\u003c3.4.0,\u003e=3.3.0.dev0-\u003efr-core-news-lg==3.3.0) (57.4.0)\n","Requirement already satisfied: packaging\u003e=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy\u003c3.4.0,\u003e=3.3.0.dev0-\u003efr-core-news-lg==3.3.0) (21.3)\n","Requirement already satisfied: langcodes\u003c4.0.0,\u003e=3.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy\u003c3.4.0,\u003e=3.3.0.dev0-\u003efr-core-news-lg==3.3.0) (3.3.0)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy\u003c3.4.0,\u003e=3.3.0.dev0-\u003efr-core-news-lg==3.3.0) (2.11.3)\n","Requirement already satisfied: tqdm\u003c5.0.0,\u003e=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy\u003c3.4.0,\u003e=3.3.0.dev0-\u003efr-core-news-lg==3.3.0) (4.64.0)\n","Requirement already satisfied: cymem\u003c2.1.0,\u003e=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy\u003c3.4.0,\u003e=3.3.0.dev0-\u003efr-core-news-lg==3.3.0) (2.0.6)\n","Requirement already satisfied: requests\u003c3.0.0,\u003e=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy\u003c3.4.0,\u003e=3.3.0.dev0-\u003efr-core-news-lg==3.3.0) (2.23.0)\n","Requirement already satisfied: srsly\u003c3.0.0,\u003e=2.4.3 in /usr/local/lib/python3.7/dist-packages (from spacy\u003c3.4.0,\u003e=3.3.0.dev0-\u003efr-core-news-lg==3.3.0) (2.4.3)\n","Requirement already satisfied: typing-extensions\u003c4.0.0.0,\u003e=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy\u003c3.4.0,\u003e=3.3.0.dev0-\u003efr-core-news-lg==3.3.0) (3.10.0.2)\n","Requirement already satisfied: typer\u003c0.5.0,\u003e=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy\u003c3.4.0,\u003e=3.3.0.dev0-\u003efr-core-news-lg==3.3.0) (0.4.1)\n","Requirement already satisfied: wasabi\u003c1.1.0,\u003e=0.9.1 in /usr/local/lib/python3.7/dist-packages (from spacy\u003c3.4.0,\u003e=3.3.0.dev0-\u003efr-core-news-lg==3.3.0) (0.9.1)\n","Requirement already satisfied: preshed\u003c3.1.0,\u003e=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy\u003c3.4.0,\u003e=3.3.0.dev0-\u003efr-core-news-lg==3.3.0) (3.0.6)\n","Requirement already satisfied: thinc\u003c8.1.0,\u003e=8.0.14 in /usr/local/lib/python3.7/dist-packages (from spacy\u003c3.4.0,\u003e=3.3.0.dev0-\u003efr-core-news-lg==3.3.0) (8.0.16)\n","Requirement already satisfied: murmurhash\u003c1.1.0,\u003e=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy\u003c3.4.0,\u003e=3.3.0.dev0-\u003efr-core-news-lg==3.3.0) (1.0.7)\n","Requirement already satisfied: zipp\u003e=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue\u003c2.1.0,\u003e=2.0.6-\u003espacy\u003c3.4.0,\u003e=3.3.0.dev0-\u003efr-core-news-lg==3.3.0) (3.8.0)\n","Requirement already satisfied: pyparsing!=3.0.5,\u003e=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging\u003e=20.0-\u003espacy\u003c3.4.0,\u003e=3.3.0.dev0-\u003efr-core-news-lg==3.3.0) (3.0.9)\n","Requirement already satisfied: smart-open\u003c6.0.0,\u003e=5.0.0 in /usr/local/lib/python3.7/dist-packages (from pathy\u003e=0.3.5-\u003espacy\u003c3.4.0,\u003e=3.3.0.dev0-\u003efr-core-news-lg==3.3.0) (5.2.1)\n","Requirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests\u003c3.0.0,\u003e=2.13.0-\u003espacy\u003c3.4.0,\u003e=3.3.0.dev0-\u003efr-core-news-lg==3.3.0) (2021.10.8)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,\u003c1.26,\u003e=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests\u003c3.0.0,\u003e=2.13.0-\u003espacy\u003c3.4.0,\u003e=3.3.0.dev0-\u003efr-core-news-lg==3.3.0) (1.25.11)\n","Requirement already satisfied: idna\u003c3,\u003e=2.5 in /usr/local/lib/python3.7/dist-packages (from requests\u003c3.0.0,\u003e=2.13.0-\u003espacy\u003c3.4.0,\u003e=3.3.0.dev0-\u003efr-core-news-lg==3.3.0) (2.10)\n","Requirement already satisfied: chardet\u003c4,\u003e=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests\u003c3.0.0,\u003e=2.13.0-\u003espacy\u003c3.4.0,\u003e=3.3.0.dev0-\u003efr-core-news-lg==3.3.0) (3.0.4)\n","Requirement already satisfied: click\u003c9.0.0,\u003e=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer\u003c0.5.0,\u003e=0.3.0-\u003espacy\u003c3.4.0,\u003e=3.3.0.dev0-\u003efr-core-news-lg==3.3.0) (7.1.2)\n","Requirement already satisfied: MarkupSafe\u003e=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2-\u003espacy\u003c3.4.0,\u003e=3.3.0.dev0-\u003efr-core-news-lg==3.3.0) (2.0.1)\n","\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n","You can now load the package via spacy.load('fr_core_news_lg')\n"]}],"source":["\"\"\" SpaCy preparation \"\"\"\n","if RUN_SPACY:\n","  # Download SpaCy pipeline\n","  !python -m spacy download fr_core_news_lg\n","  \n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"28c86974-f989-406c-b4da-1e881457e333"},"outputs":[{"name":"stderr","output_type":"stream","text":["23/05/2022 04:11:52 ; INFO ; SpaCy run #1, will save in /content/drive/MyDrive/TEST/src/ner/20-experiment_1_metrics/21-spacy_ner/run_1\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[38;5;4mℹ Saving to output directory: /tmp\u001b[0m\n","\u001b[38;5;4mℹ Using CPU\u001b[0m\n","\u001b[1m\n","=========================== Initializing pipeline ===========================\u001b[0m\n","\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n","\u001b[1m\n","============================= Training pipeline =============================\u001b[0m\n","\u001b[38;5;4mℹ Pipeline: ['tok2vec', 'ner']\u001b[0m\n","\u001b[38;5;4mℹ Initial learn rate: 0.001\u001b[0m\n","E    #       LOSS TOK2VEC  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n","---  ------  ------------  --------  ------  ------  ------  ------\n","  0       0          0.00     58.05   25.66   33.72   20.71    0.26\n"," 36     200          0.00   1323.91   82.20   80.51   83.96    0.82\n"," 80     400          0.00      0.00   82.63   81.37   83.93    0.83\n","131     600          0.00      0.01   82.49   81.40   83.61    0.82\n","197     800          0.00      0.00   81.98   80.79   83.21    0.82\n","273    1000          0.00      0.00   81.90   80.25   83.61    0.82\n","373    1200          0.00      0.00   82.18   80.60   83.82    0.82\n","473    1400          0.00      0.00   81.91   80.28   83.61    0.82\n","601    1600          0.00      0.00   82.59   81.10   84.14    0.83\n","801    1800          0.00      0.00   82.08   80.09   84.18    0.82\n","1001    2000          0.00      0.34   81.60   80.39   82.86    0.82\n","\u001b[38;5;2m✔ Saved pipeline to output directory\u001b[0m\n","/tmp/model-last\n","\u001b[38;5;4mℹ Saving to output directory: /tmp\u001b[0m\n","\u001b[38;5;4mℹ Using CPU\u001b[0m\n","\u001b[1m\n","=========================== Initializing pipeline ===========================\u001b[0m\n","\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n","\u001b[1m\n","============================= Training pipeline =============================\u001b[0m\n","\u001b[38;5;4mℹ Pipeline: ['tok2vec', 'ner']\u001b[0m\n","\u001b[38;5;4mℹ Initial learn rate: 0.001\u001b[0m\n","E    #       LOSS TOK2VEC  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n","---  ------  ------------  --------  ------  ------  ------  ------\n","  0       0          0.00     54.95   25.42   33.35   20.54    0.25\n"," 17     200          0.00   1877.61   85.22   84.18   86.29    0.85\n"," 38     400          0.00    154.83   85.04   83.83   86.29    0.85\n"," 65     600          0.00      3.46   83.85   82.63   85.11    0.84\n"," 97     800          0.00      0.95   85.44   84.65   86.25    0.85\n","136    1000          0.00      2.73   85.06   83.54   86.64    0.85\n","183    1200          0.00     12.42   83.96   82.64   85.32    0.84\n","241    1400          0.00     14.72   85.69   84.36   87.07    0.86\n","308    1600          0.00      1.86   84.84   83.38   86.36    0.85\n","395    1800          0.00     39.91   84.99   83.37   86.68    0.85\n","495    2000          0.00     11.87   85.59   84.56   86.64    0.86\n","595    2200          0.00      3.68   86.70   85.77   87.64    0.87\n","758    2400          0.00     12.20   86.33   84.96   87.75    0.86\n","958    2600          0.00      7.40   87.02   85.85   88.21    0.87\n","1158    2800          0.00      0.20   85.68   84.51   86.89    0.86\n","1358    3000          0.00     12.64   86.44   84.63   88.32    0.86\n","1558    3200          0.00      2.61   86.83   85.75   87.93    0.87\n","1758    3400          0.00      0.02   86.09   85.10   87.11    0.86\n","1958    3600          0.00      2.20   86.63   85.57   87.71    0.87\n","2158    3800          0.00      9.73   86.39   84.87   87.96    0.86\n","2358    4000          0.00     12.66   86.00   84.72   87.32    0.86\n","2558    4200          0.00      1.45   86.27   85.61   86.93    0.86\n","\u001b[38;5;2m✔ Saved pipeline to output directory\u001b[0m\n","/tmp/model-last\n","\u001b[38;5;4mℹ Saving to output directory: /tmp\u001b[0m\n","\u001b[38;5;4mℹ Using CPU\u001b[0m\n","\u001b[1m\n","=========================== Initializing pipeline ===========================\u001b[0m\n","\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n","\u001b[1m\n","============================= Training pipeline =============================\u001b[0m\n","\u001b[38;5;4mℹ Pipeline: ['tok2vec', 'ner']\u001b[0m\n","\u001b[38;5;4mℹ Initial learn rate: 0.001\u001b[0m\n","E    #       LOSS TOK2VEC  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n","---  ------  ------------  --------  ------  ------  ------  ------\n","  0       0          0.00     33.34   26.08   34.22   21.07    0.26\n","  8     200          0.00   2137.88   86.72   86.36   87.07    0.87\n"," 18     400          0.00    272.04   88.01   87.39   88.64    0.88\n"," 31     600          0.00    166.08   88.36   87.55   89.18    0.88\n"," 47     800          0.00      3.34   88.24   87.36   89.14    0.88\n"," 66    1000          0.00      8.98   88.77   88.33   89.21    0.89\n"," 89    1200          0.00      6.00   88.59   87.77   89.43    0.89\n","118    1400          0.00     30.13   88.51   87.61   89.43    0.89\n","152    1600          0.00     27.17   88.52   87.70   89.36    0.89\n","195    1800          0.00     13.42   88.49   87.21   89.82    0.88\n","245    2000          0.00     24.80   89.46   88.92   90.00    0.89\n","309    2200          0.00      0.30   88.30   87.65   88.96    0.88\n","375    2400          0.00     25.17   88.89   88.08   89.71    0.89\n","442    2600          0.00      1.34   88.97   87.93   90.04    0.89\n","509    2800          0.00      0.00   89.48   88.76   90.21    0.89\n","575    3000          0.00      0.00   89.78   89.24   90.32    0.90\n","642    3200          0.00      9.56   88.50   88.33   88.68    0.89\n","709    3400          0.00     41.67   89.60   89.49   89.71    0.90\n","775    3600          0.00     26.86   88.72   87.47   90.00    0.89\n","842    3800          0.00     39.06   89.52   88.46   90.61    0.90\n","909    4000          0.00    175.33   90.29   90.43   90.14    0.90\n","975    4200          0.00     29.16   89.64   88.87   90.43    0.90\n","1042    4400          0.00      5.03   89.72   89.69   89.75    0.90\n","1109    4600          0.00      4.66   89.64   89.18   90.11    0.90\n","1175    4800          0.00     11.80   89.56   88.72   90.43    0.90\n","1242    5000          0.00     11.55   88.98   89.00   88.96    0.89\n","1309    5200          0.00      3.65   89.86   89.51   90.21    0.90\n","1375    5400          0.00      0.00   89.94   89.81   90.07    0.90\n","1442    5600          0.00      4.40   89.83   88.52   91.18    0.90\n","\u001b[38;5;2m✔ Saved pipeline to output directory\u001b[0m\n","/tmp/model-last\n","\u001b[38;5;4mℹ Saving to output directory: /tmp\u001b[0m\n","\u001b[38;5;4mℹ Using CPU\u001b[0m\n","\u001b[1m\n","=========================== Initializing pipeline ===========================\u001b[0m\n","\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n","\u001b[1m\n","============================= Training pipeline =============================\u001b[0m\n","\u001b[38;5;4mℹ Pipeline: ['tok2vec', 'ner']\u001b[0m\n","\u001b[38;5;4mℹ Initial learn rate: 0.001\u001b[0m\n","E    #       LOSS TOK2VEC  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n","---  ------  ------------  --------  ------  ------  ------  ------\n","  0       0          0.00     39.56   26.31   33.99   21.46    0.26\n","  4     200          0.00   2497.27   90.34   90.47   90.21    0.90\n","  9     400          0.00    443.68   91.00   90.79   91.21    0.91\n"," 16     600          0.00    491.41   90.68   90.12   91.25    0.91\n"," 24     800          0.00     90.90   90.25   89.96   90.54    0.90\n"," 34    1000          0.00     42.56   90.79   90.20   91.39    0.91\n"," 46    1200          0.00     15.63   91.00   90.62   91.39    0.91\n"," 61    1400          0.00     11.00   91.11   90.72   91.50    0.91\n"," 79    1600          0.00     38.64   91.04   90.86   91.21    0.91\n","102    1800          0.00     24.43   91.11   90.58   91.64    0.91\n","129    2000          0.00     26.96   91.24   90.98   91.50    0.91\n","161    2200          0.00     21.35   90.96   90.49   91.43    0.91\n","201    2400          0.00     28.37   91.11   90.69   91.54    0.91\n","241    2600          0.00     13.06   91.56   91.12   92.00    0.92\n","281    2800          0.00     23.28   91.58   91.10   92.07    0.92\n","321    3000          0.00     20.32   91.31   91.02   91.61    0.91\n","361    3200          0.00     19.81   91.52   90.94   92.11    0.92\n","401    3400          0.00     10.35   91.00   90.32   91.68    0.91\n","441    3600          0.00     31.43   91.08   91.01   91.14    0.91\n","481    3800          0.00     49.11   90.90   90.45   91.36    0.91\n","521    4000          0.00     23.29   91.05   90.71   91.39    0.91\n","561    4200          0.00     28.03   91.04   90.45   91.64    0.91\n","601    4400          0.00     22.82   91.85   91.55   92.14    0.92\n","641    4600          0.00     16.94   91.25   90.66   91.86    0.91\n"]}],"source":["if RUN_SPACY:\n","  from spacy.cli import train, evaluate\n","\n","  # Train \u0026 evaluate loop\n","  for run in range(1, N_RUNS + 1):\n","      output_dir = SPACY_NER_METRICS_DIR / f\"run_{run}\"\n","      output_dir.mkdir(exist_ok=True)\n","      \n","      config.logger.info(f\"SpaCy run #{run}, will save in {output_dir}\")\n","      \n","      for trainset_size in TRAINSETS_SIZES:\n","          # paths to datasets\n","          trainset = INPUT_DIR / f\"spacy_train_{trainset_size}.spacy\"\n","          devset = INPUT_DIR / f\"spacy_dev_{trainset_size}.spacy\"\n","          testset = INPUT_DIR / f\"spacy_test_{trainset_size}.spacy\"\n","\n","          # Pass train \u0026 dev paths as SpaCy config items\n","          spacy_opts = {\n","              \"paths.train\": str(trainset),\n","              \"paths.dev\": str(devset),\n","          }\n","          \n","          # Train now !\n","          train.train(\"cnn_config.cfg\",       # The pipeline configuration file\n","                      SPACY_OUTPUT_MODEL_PATH,# save model-best and model-last here\n","                      use_gpu=SPACY_USE_GPU,  # Use GPU if asked\n","                      overrides=spacy_opts)   # Pass training options\n","\n","          model_best = SPACY_OUTPUT_MODEL_PATH / \"model-best\"\n","          \n","          # Compute metrics on the test set\n","          metrics_file = output_dir / f\"test_{trainset_size}.json\"\n","          evaluate(model_best,                     # Where is the trained model\n","                  testset,                         # Test dataset\n","                  metrics_file,                    # Save metrics here\n","                  use_gpu=SPACY_USE_GPU,           # Use GPU if asked\n","                  displacy_path=output_dir,        # Save a few tagged results to be shown with displacy\n","                  displacy_limit=100)              # How much is \"a few\"\n","          \n","          # Compute metrics on the dev set\n","          metrics_file = output_dir / f\"dev_{trainset_size}.json\"\n","          evaluate(model_best,                      # Where is the trained model\n","                  devset,                          # Dev dataset\n","                  metrics_file,                    # Save metrics here\n","                  use_gpu=SPACY_USE_GPU,           # Use GPU if asked\n","                  displacy_path=output_dir,        # Save a few tagged results to be shown with displacy\n","                  displacy_limit=100)              # How much is \"a few\"\n","else:\n","  config.logger.info(\"Skipped finetuning SpaCy NER\")"]},{"cell_type":"markdown","metadata":{"id":"6b18a5bc-1abb-450d-90d3-6a7e56f773ed"},"source":["## 22. CamemBERT - Common"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"91140aa5-b377-47c1-bd44-844cd9365ec3"},"outputs":[],"source":["# SHARED CONSTANTS\n","\n","TRAINING_CONFIG = {\n","    \"evaluation_strategy\": \"steps\",\n","    \"eval_steps\": 100,\n","    \"max_steps\": 5000,\n","    \"learning_rate\": 1e-4,\n","    \"per_device_train_batch_size\": 16,\n","    \"per_device_eval_batch_size\": 16,\n","    \"weight_decay\": 1e-5,\n","    \"load_best_model_at_end\": True,\n","    \"greater_is_better\":True,\n","    \"metric_for_best_model\": \"f1\",\n","    \"save_strategy\": \"steps\",\n","    \"save_steps\": 100, # Make Early callback bug ?\n","    \"save_total_limit\": 1,\n","}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2e821087-3623-4c14-a8fb-63dcc98dc1d4","outputId":"13a5a534-558c-40b5-933b-609f42ae9d52"},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package punkt to /home/bertrand/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"]}],"source":["\n","def train_bert(metrics_output_directory):\n","    # Train \u0026 evaluate loop\n","    for run in range(1, N_RUNS + 1):\n","        output_dir = metrics_output_directory / f\"run_{run}\"\n","        output_dir.mkdir(exist_ok=True)\n","\n","        logger.info(f\"{model} #{run}, will save in {output_dir}\")\n","\n","        for trainset_size in TRAINSETS_SIZES:\n","            datasetdir = INPUT_DIR / f\"huggingface_{trainset_size}\"\n","\n","            logger.info(f\"Running on datasets in {datasetdir}\")\n","            logger.info(f\"Metrics will be saved in {output_dir}\")\n","\n","            # Train now !\n","            train_dev_test = load_from_disk(datasetdir)\n","            metrics = train_eval_loop(model,         # Implicit. Must be setbefore calling train_bert()\n","                                      training_args, # Idem\n","                                      tokenizer,     # idem\n","                                      **train_dev_test)\n","\n","            # Save the metrics\n","            metrics_file = output_dir / f\"test_{trainset_size}.json\"\n","            with open(metrics_file, \"w\", encoding=\"utf-8\") as o:\n","                json.dump(metrics[0], o)\n","\n","            metrics_file = output_dir / f\"dev_{trainset_size}.json\"\n","            with open(metrics_file, \"w\", encoding=\"utf-8\") as o:\n","                json.dump(metrics[1], o)\n","\n","\n","                "]},{"cell_type":"markdown","metadata":{"id":"09de0446-e62f-46d5-ae73-34112f3c420d"},"source":["## 23 - CamemBERT - train \u0026 eval"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c808f0e4-1b8a-43d7-9b16-256e60faf339","outputId":"a9c1ed05-885f-45a9-8084-e0777eba00fe"},"outputs":[{"data":{"text/plain":["(PosixPath('/home/bertrand/dev/paper-ner-bench-das22/src/ner/20-experiment_1_metrics/22-camembert'),\n"," '/tmp/22-camembert')"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["# CAMEMBERT CONSTS\n","CAMEMBERT_METRICS_DIR = METRICS_OUTPUT_DIR / \"22-camembert\"\n","CAMEMBERT_METRICS_DIR.mkdir(exist_ok=True, parents=True)\n","CAMEMBERT_MODEL = \"Jean-Baptiste/camembert-ner\"\n","CAMEMBERT_OUTPUT_MODEL_PATH = \"/tmp/22-camembert\"\n","CAMEMBERT_METRICS_DIR, CAMEMBERT_OUTPUT_MODEL_PATH"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"05387e39-dd69-491e-9517-57490356e5e9","outputId":"a894e899-0646-4260-f12f-7468adfbb5b2"},"outputs":[{"name":"stderr","output_type":"stream","text":["17/01/2022 02:41:50 ; INFO ; Skipped finetuning Camembert\n"]}],"source":["if RUN_CAMEMBERT:\n","  from camembert_util import init_model\n","\n","  # Set config output dir\n","  local_config = TRAINING_CONFIG.copy() \n","  local_config[\"output_dir\"]=CAMEMBERT_OUTPUT_MODEL_PATH\n","\n","  # Get the model components\n","  model, tokenizer, training_args = init_model(CAMEMBERT_MODEL, local_config)\n","\n","  # Run the main loop\n","  train_bert(CAMEMBERT_METRICS_DIR)\n","else:\n","  logger.info(\"Skipped finetuning Camembert\")"]},{"cell_type":"markdown","metadata":{"id":"17cd632b-99a9-4c85-aafc-72b7b0615d60"},"source":["## 23 - CamemBERT pretrained - train \u0026 eval"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"af0b70e9-fc3e-47da-b231-002d329a2932"},"outputs":[],"source":["# CAMEMBERT PRETRAINED CONSTS\n","CAMEMBERT_PRETRAINED_METRICS_DIR = METRICS_OUTPUT_DIR / \"23-camembert_pretrained\"\n","CAMEMBERT_PRETRAINED_METRICS_DIR.mkdir(exist_ok=True, parents=True)\n","CAMEMBERT_PRETRAINED_MODEL = \"HueyNemud/das22-10-camembert_pretrained\"\n","CAMEMBERT_PRETRAINED_OUTPUT_MODEL_PATH = \"/tmp/22-camembert_pretrained\""]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"de3459be-8661-40f4-a9dc-e4bc03f9cb53","outputId":"077e0a27-cd2b-41e4-a080-80292418d483"},"outputs":[{"name":"stderr","output_type":"stream","text":["17/01/2022 02:41:56 ; INFO ; Model HueyNemud/das22-10-camembert_pretrained\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"949602a1518347b7987c7fb57f447e8f","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/671 [00:00\u003c?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"69b2f53014f44588b5a5ebeb04c5cc79","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/792k [00:00\u003c?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"247cf255760e41f2a463a6d72de2b57d","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/1.33M [00:00\u003c?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5e826e8674f44375991a489a2a710c1d","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/210 [00:00\u003c?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d9c3fbf46b914b3c86b817b32f1c4eba","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/958 [00:00\u003c?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a2629abc30fc42f1b0b96ac3b4dd21e5","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/422M [00:00\u003c?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at HueyNemud/das22-10-camembert_pretrained were not used when initializing CamembertForTokenClassification: ['lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.bias']\n","- This IS expected if you are initializing CamembertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing CamembertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of CamembertForTokenClassification were not initialized from the model checkpoint at HueyNemud/das22-10-camembert_pretrained and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","17/01/2022 02:42:50 ; INFO ; CamembertForTokenClassification(\n","  (roberta): RobertaModel(\n","    (embeddings): RobertaEmbeddings(\n","      (word_embeddings): Embedding(32005, 768, padding_idx=1)\n","      (position_embeddings): Embedding(514, 768, padding_idx=1)\n","      (token_type_embeddings): Embedding(1, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): RobertaEncoder(\n","      (layer): ModuleList(\n","        (0): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","  )\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (classifier): Linear(in_features=768, out_features=9, bias=True)\n",") #1, will save in /home/bertrand/dev/paper-ner-bench-das22/src/ner/20-experiment_1_metrics/23-camembert_pretrained/run_1\n","17/01/2022 02:42:50 ; INFO ; Running on datasets in /home/bertrand/dev/paper-ner-bench-das22/src/ner/01-experiment_1_prepared_datasets/huggingface_49\n","17/01/2022 02:42:50 ; INFO ; Metrics will be saved in /home/bertrand/dev/paper-ner-bench-das22/src/ner/20-experiment_1_metrics/23-camembert_pretrained/run_1\n","max_steps is given, it will override any value given in num_train_epochs\n","The following columns in the training set  don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: ner_tags, tokens.\n","***** Running training *****\n","  Num examples = 49\n","  Num Epochs = 1250\n","  Instantaneous batch size per device = 16\n","  Total train batch size (w. parallel, distributed \u0026 accumulation) = 16\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 5000\n"]},{"data":{"text/html":["\n","    \u003cdiv\u003e\n","      \n","      \u003cprogress value='5' max='5000' style='width:300px; height:20px; vertical-align: middle;'\u003e\u003c/progress\u003e\n","      [   5/5000 00:05 \u003c 2:37:01, 0.53 it/s, Epoch 1/1250]\n","    \u003c/div\u003e\n","    \u003ctable border=\"1\" class=\"dataframe\"\u003e\n","  \u003cthead\u003e\n","    \u003ctr style=\"text-align: left;\"\u003e\n","      \u003cth\u003eStep\u003c/th\u003e\n","      \u003cth\u003eTraining Loss\u003c/th\u003e\n","      \u003cth\u003eValidation Loss\u003c/th\u003e\n","    \u003c/tr\u003e\n","  \u003c/thead\u003e\n","  \u003ctbody\u003e\n","  \u003c/tbody\u003e\n","\u003c/table\u003e\u003cp\u003e"],"text/plain":["\u003cIPython.core.display.HTML object\u003e"]},"metadata":{},"output_type":"display_data"},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_315739/874093072.py\u001b[0m in \u001b[0;36m\u003cmodule\u003e\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m   \u001b[0;31m# Run the main loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---\u003e 12\u001b[0;31m   \u001b[0mtrain_bert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCAMEMBERT_PRETRAINED_METRICS_DIR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m   \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Skipped finetuning Camembert-pretraining\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_315739/2268760230.py\u001b[0m in \u001b[0;36mtrain_bert\u001b[0;34m(metrics_output_directory)\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0;31m# Train now !\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0mtrain_dev_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_from_disk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatasetdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---\u003e 21\u001b[0;31m             metrics = train_eval_loop(model,         # Implicit. Must be setbefore calling train_bert()\n\u001b[0m\u001b[1;32m     22\u001b[0m                                       \u001b[0mtraining_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# Idem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m                                       \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m     \u001b[0;31m# idem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/dev/paper-ner-bench-das22/src/ner/camembert_util.py\u001b[0m in \u001b[0;36mtrain_eval_loop\u001b[0;34m(model, training_args, tokenizer, train, dev, test, patience)\u001b[0m\n\u001b[1;32m     61\u001b[0m         ],\n\u001b[1;32m     62\u001b[0m     )\n\u001b[0;32m---\u003e 63\u001b[0;31m     \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1330\u001b[0m                         \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1331\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-\u003e 1332\u001b[0;31m                     \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1334\u001b[0m                 if (\n","\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   1889\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1890\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautocast_smart_context_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-\u003e 1891\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1893\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_gpu\u001b[0m \u001b[0;34m\u003e\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mcompute_loss\u001b[0;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[1;32m   1921\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1922\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-\u003e 1923\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1924\u001b[0m         \u001b[0;31m# Save past state if it exists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1925\u001b[0m         \u001b[0;31m# TODO: this needs to be fixed and made cleaner later.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-\u003e 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1393\u001b[0m         \u001b[0mreturn_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_return_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-\u003e 1395\u001b[0;31m         outputs = self.roberta(\n\u001b[0m\u001b[1;32m   1396\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1397\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-\u003e 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    849\u001b[0m             \u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m         )\n\u001b[0;32m--\u003e 851\u001b[0;31m         encoder_outputs = self.encoder(\n\u001b[0m\u001b[1;32m    852\u001b[0m             \u001b[0membedding_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-\u003e 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    524\u001b[0m                 )\n\u001b[1;32m    525\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 526\u001b[0;31m                 layer_outputs = layer_module(\n\u001b[0m\u001b[1;32m    527\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-\u003e 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    451\u001b[0m             \u001b[0mpresent_key_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpresent_key_value\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcross_attn_present_key_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 453\u001b[0;31m         layer_output = apply_chunking_to_forward(\n\u001b[0m\u001b[1;32m    454\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed_forward_chunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk_size_feed_forward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseq_len_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m         )\n","\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mapply_chunking_to_forward\u001b[0;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[1;32m   2368\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_chunks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunk_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-\u003e 2370\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mforward_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mfeed_forward_chunk\u001b[0;34m(self, attention_output)\u001b[0m\n\u001b[1;32m    464\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfeed_forward_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m         \u001b[0mintermediate_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 466\u001b[0;31m         \u001b[0mlayer_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintermediate_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    467\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlayer_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-\u003e 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, input_tensor)\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 378\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    379\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLayerNorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-\u003e 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u003e\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 103\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u003e\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1846\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1847\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-\u003e 1848\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["if RUN_CAMEMBERT_PRETRAINED:\n","  from camembert_util import init_model\n","\n","  # Set config output dir\n","  local_config = TRAINING_CONFIG.copy() \n","  local_config[\"output_dir\"]=CAMEMBERT_PRETRAINED_OUTPUT_MODEL_PATH\n","\n","  # Get the model components\n","  model, tokenizer, training_args = init_model(CAMEMBERT_PRETRAINED_MODEL, local_config)\n","\n","  # Run the main loop\n","  train_bert(CAMEMBERT_PRETRAINED_METRICS_DIR)\n","else:\n","  logger.info(\"Skipped finetuning Camembert-pretraining\")"]}],"metadata":{"colab":{"collapsed_sections":[],"name":"20-experiment_1.ipynb","version":""},"kernelspec":{"display_name":"Python 3.10.4 ('ner')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.4"},"vscode":{"interpreter":{"hash":"c57d6dc83202ed16477ed01fbeb8d45268fb6711c5da666dad291c245339c394"}}},"nbformat":4,"nbformat_minor":5}