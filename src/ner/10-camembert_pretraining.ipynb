{"cells":[{"cell_type":"markdown","id":"b4d13fee-3305-4991-8a1f-f9ef149e5b2f","metadata":{"id":"b4d13fee-3305-4991-8a1f-f9ef149e5b2f"},"source":["# 10 - Pretraining CamemBERT\n","\n","Pretrain the Huggingface `Jean-Baptiste/cammbert-ner` model on a large set of trade directory entries extracted with OCR.\n","The resulting model is saved on the disk in the folder `10-camembert_pretrained_model`."]},{"cell_type":"code","source":["\"\"\" RUN THIS BLOCK ONLY ON GOOGLE COLAB \"\"\"\n","\n","# `GDRIVE_PAPER_FOLDER` is the relative path in your GDrive to the folder\n","# contaning the code of the paper\n","# ADAPT TO YOUR SITUATION !\n","%env GDRIVE_PAPER_FOLDER=TEST\n","\n","# Mount Google Drive to your Colab environment. May require to log in to Google.\n","from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)\n","\n","# Copy the Python modules in `PATH_TO_SOURCES/src/ner/util` to GColab\n","# to enable import.\n","!cp -r /content/drive/MyDrive/$GDRIVE_PAPER_FOLDER/src/ner/util .\n","\n","# Install dependencies\n","!pip install -q datasets transformers[sentencepiece]\n","# Force update SpaCy to v3 and NLTK\n","!pip install -qU spacy\n","!pip install -qU nltk"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KP-7W61IkF9w","executionInfo":{"status":"ok","timestamp":1653321025925,"user_tz":-120,"elapsed":24134,"user":{"displayName":"Bertrand Dumenieu","userId":"12153120920884628135"}},"outputId":"ac4b619f-aeea-4942-bbef-67e625230708"},"id":"KP-7W61IkF9w","execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["env: GDRIVE_PAPER_FOLDER=TEST\n","Mounted at /content/drive\n","\u001b[K     |████████████████████████████████| 1.5 MB 14.9 MB/s \n","\u001b[K     |████████████████████████████████| 749 kB 68.2 MB/s \n","\u001b[?25h"]}]},{"cell_type":"code","execution_count":2,"id":"ddc01488-30ac-4929-b2ad-e097786e65f0","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ddc01488-30ac-4929-b2ad-e097786e65f0","executionInfo":{"status":"ok","timestamp":1653321060980,"user_tz":-120,"elapsed":23,"user":{"displayName":"Bertrand Dumenieu","userId":"12153120920884628135"}},"outputId":"2468c317-cb10-4bcd-8131-2dc7ff9f9b23"},"outputs":[{"output_type":"stream","name":"stderr","text":["23/05/2022 03:51:01 ; INFO ; ======= CONFIGURATION =======\n","23/05/2022 03:51:01 ; INFO ; BASEDIR: /content/drive/MyDrive/TEST\n","23/05/2022 03:51:01 ; INFO ; Input datasets will be loaded from DATASETDIR /content/drive/MyDrive/TEST/dataset\n","23/05/2022 03:51:01 ; INFO ; Training data and models will be saved to NERDIR /content/drive/MyDrive/TEST/src/ner\n","23/05/2022 03:51:01 ; INFO ; Debug mode is ON\n","23/05/2022 03:51:01 ; INFO ; Random seed: 42\n","23/05/2022 03:51:01 ; INFO ; Enable reproducibility checks: True\n","23/05/2022 03:51:01 ; INFO ; ============================\n"]},{"output_type":"stream","name":"stdout","text":["env: DEBUG=1\n","env: AS_IN_THE_PAPER=True\n"]}],"source":["\"\"\" Loads the configuration \"\"\"\n","\n","# Set to 1/true/ to set the logging level of nerlogger to DEBUG \n","# and save the the spacy datasets as TXT along with the .spacy file\n","#  for easier debug of the training set generation.\n","%env DEBUG=1\n","\n","# If True, activates a set of assertions in the notebooks to ensure\n","# that the scripts runs with the parameters used in the paper.\n","%env AS_IN_THE_PAPER = True\n","\n","import util.config as config\n","\n","config.show()"]},{"cell_type":"code","execution_count":3,"id":"966a20fd","metadata":{"id":"966a20fd","executionInfo":{"status":"ok","timestamp":1653321065535,"user_tz":-120,"elapsed":833,"user":{"displayName":"Bertrand Dumenieu","userId":"12153120920884628135"}}},"outputs":[],"source":["\"\"\" Import all modules at once \"\"\"\n","\n","# General imports\n","import nltk\n","import gzip\n","import tempfile \n","import pathlib\n","\n","# NER imports\n","from util.as_in_the_paper import assert_expected\n"]},{"cell_type":"markdown","id":"1b7a3e31-243a-4fa7-a6c4-b39bf9ad42ca","metadata":{"tags":[],"id":"1b7a3e31-243a-4fa7-a6c4-b39bf9ad42ca"},"source":["## 11 - Preparation of the pre-training data\n","\n","Starting from a set of raw entries in `dataset/unsupervised_pretraining/10-normalized/all.txt.gz`, this block extracts a subset of entries that contain a minimum number of words as fixed by the threshold `MIN_WORDS_PER_ENTRY`.\n","\n","The resulting set is outputed to the text file `pretraining_data.txt` in the temporary folder of your file system."]},{"cell_type":"code","execution_count":4,"id":"98f8aa0c-91ff-48e9-9be0-f9bb4cf5779f","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"98f8aa0c-91ff-48e9-9be0-f9bb4cf5779f","executionInfo":{"status":"ok","timestamp":1653321171195,"user_tz":-120,"elapsed":97369,"user":{"displayName":"Bertrand Dumenieu","userId":"12153120920884628135"}},"outputId":"88ff74f3-62ac-4b1f-ec70-93336d7e7264"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","23/05/2022 03:52:51 ; DEBUG ; Stored the pretraining data in /tmp\n","23/05/2022 03:52:51 ; INFO ; Valid entries:845014, 0.808105.2 percent of the total\n"]}],"source":["\"\"\" Prepare the pre-training dataset \"\"\"\n","\n","pretraining_set_path = config.DATASETDIR / \"unsupervised_pretraining/10-normalized\"\n","\n","# Filter the normalized pre-training \n","# Keep only entries containing at least MIN_WORDS_PER_ENTRY words\n","MIN_WORDS_PER_ENTRY = 7 # Keep simples entries like \"Morel abbé ,Tournon, 14.\"\n","\n","assert_expected(actual=MIN_WORDS_PER_ENTRY, expected=7)\n","\n","nltk.download(\"punkt\")\n","number_of_entries = 0\n","valid_entries = []\n","\n","with gzip.open(pretraining_set_path / \"all.txt.gz\", \"rt\") as all_txt:\n","    for entry in all_txt:\n","        entry = entry.strip() # Sanitize\n","        words = nltk.word_tokenize(entry, language=\"fr\", preserve_line=True)\n","        if len(words) >= MIN_WORDS_PER_ENTRY:\n","            valid_entries.append(entry)\n","        number_of_entries += 1\n","        \n","\n","\n","# Get the name of the temp folder and save the file to that folder.\n","temp_dir = pathlib.Path(tempfile.gettempdir())\n","with open(temp_dir / \"pretraining_data.txt\", \"w\") as fp:\n","    fp.write(\"\\n\".join(valid_entries))\n","    config.logger.debug(f\"Stored the pretraining data in {temp_dir}\")\n","\n","\n","config.logger.info(\"Valid entries:%d, %f.2 percent of the total\" % (len(valid_entries),len(valid_entries) / number_of_entries))\n","assert_expected(actual=845014, expected=len(valid_entries))\n","assert_expected(actual=1045674, expected=number_of_entries)"]},{"cell_type":"markdown","id":"5a5e9321-957b-4dbe-867c-437cadcc8c2e","metadata":{"id":"5a5e9321-957b-4dbe-867c-437cadcc8c2e"},"source":["## 12 - Pretraining process\n","\n","Pretrain the base model \"Jean-Baptiste/camembert-ner\" on the 845k raw entries in pretraining_data.txt\n","Th"]},{"cell_type":"code","execution_count":10,"id":"1be1e366-78cc-4a3d-b62d-28c07dd63732","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1be1e366-78cc-4a3d-b62d-28c07dd63732","executionInfo":{"status":"ok","timestamp":1653321499715,"user_tz":-120,"elapsed":108657,"user":{"displayName":"Bertrand Dumenieu","userId":"12153120920884628135"}},"outputId":"b6665a97-f93b-459f-f986-d515935aac50"},"outputs":[{"output_type":"stream","name":"stdout","text":["05/23/2022 15:56:36 - WARNING - __main__ - Process rank: -1, device: cpu, n_gpu: 0distributed training: False, 16-bits training: False\n","05/23/2022 15:56:36 - INFO - __main__ - Training/evaluation parameters TrainingArguments(\n","_n_gpu=0,\n","adafactor=False,\n","adam_beta1=0.9,\n","adam_beta2=0.999,\n","adam_epsilon=1e-08,\n","auto_find_batch_size=False,\n","bf16=False,\n","bf16_full_eval=False,\n","data_seed=None,\n","dataloader_drop_last=False,\n","dataloader_num_workers=0,\n","dataloader_pin_memory=True,\n","ddp_bucket_cap_mb=None,\n","ddp_find_unused_parameters=None,\n","debug=[],\n","deepspeed=None,\n","disable_tqdm=False,\n","do_eval=True,\n","do_predict=False,\n","do_train=True,\n","eval_accumulation_steps=None,\n","eval_delay=0,\n","eval_steps=500,\n","evaluation_strategy=IntervalStrategy.STEPS,\n","fp16=False,\n","fp16_backend=auto,\n","fp16_full_eval=False,\n","fp16_opt_level=O1,\n","fsdp=[],\n","fsdp_min_num_params=0,\n","full_determinism=False,\n","gradient_accumulation_steps=1,\n","gradient_checkpointing=False,\n","greater_is_better=False,\n","group_by_length=False,\n","half_precision_backend=auto,\n","hub_model_id=None,\n","hub_private_repo=False,\n","hub_strategy=HubStrategy.EVERY_SAVE,\n","hub_token=<HUB_TOKEN>,\n","ignore_data_skip=False,\n","include_inputs_for_metrics=False,\n","label_names=None,\n","label_smoothing_factor=0.0,\n","learning_rate=5e-05,\n","length_column_name=length,\n","load_best_model_at_end=True,\n","local_rank=-1,\n","log_level=-1,\n","log_level_replica=-1,\n","log_on_each_node=True,\n","logging_dir=$/content/drive/MyDrive/TEST/10-camembert_pretrained_model/runs/May23_15-56-36_8fa1e4d853e7,\n","logging_first_step=False,\n","logging_nan_inf_filter=True,\n","logging_steps=500,\n","logging_strategy=IntervalStrategy.STEPS,\n","lr_scheduler_type=SchedulerType.LINEAR,\n","max_grad_norm=1.0,\n","max_steps=-1,\n","metric_for_best_model=loss,\n","mp_parameters=,\n","no_cuda=False,\n","num_train_epochs=3.0,\n","optim=OptimizerNames.ADAMW_HF,\n","output_dir=$/content/drive/MyDrive/TEST/10-camembert_pretrained_model,\n","overwrite_output_dir=False,\n","past_index=-1,\n","per_device_eval_batch_size=8,\n","per_device_train_batch_size=8,\n","prediction_loss_only=False,\n","push_to_hub=False,\n","push_to_hub_model_id=None,\n","push_to_hub_organization=None,\n","push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n","remove_unused_columns=True,\n","report_to=['tensorboard'],\n","resume_from_checkpoint=None,\n","run_name=$/content/drive/MyDrive/TEST/10-camembert_pretrained_model,\n","save_on_each_node=False,\n","save_steps=500,\n","save_strategy=IntervalStrategy.STEPS,\n","save_total_limit=1,\n","seed=42,\n","sharded_ddp=[],\n","skip_memory_metrics=True,\n","tf32=None,\n","tpu_metrics_debug=False,\n","tpu_num_cores=None,\n","use_legacy_prediction_loop=False,\n","warmup_ratio=0.0,\n","warmup_steps=0,\n","weight_decay=0.0,\n","xpu_backend=None,\n",")\n","05/23/2022 15:56:36 - WARNING - datasets.builder - Using custom data configuration default-e3977a958449e6ba\n","05/23/2022 15:56:36 - INFO - datasets.builder - Generating dataset text (/root/.cache/huggingface/datasets/text/default-e3977a958449e6ba/0.0.0/4b86d314f7236db91f0a0f5cda32d4375445e64c5eda2692655dd99c2dac68e8)\n","Downloading and preparing dataset text/default to /root/.cache/huggingface/datasets/text/default-e3977a958449e6ba/0.0.0/4b86d314f7236db91f0a0f5cda32d4375445e64c5eda2692655dd99c2dac68e8...\n","Downloading data files: 100% 1/1 [00:00<00:00, 5729.92it/s]\n","05/23/2022 15:56:36 - INFO - datasets.utils.download_manager - Downloading took 0.0 min\n","05/23/2022 15:56:36 - INFO - datasets.utils.download_manager - Checksum Computation took 0.0 min\n","Extracting data files: 100% 1/1 [00:00<00:00, 651.69it/s]\n","05/23/2022 15:56:36 - INFO - datasets.utils.info_utils - Unable to verify checksums.\n","05/23/2022 15:56:36 - INFO - datasets.builder - Generating train split\n","05/23/2022 15:56:38 - INFO - datasets.utils.info_utils - Unable to verify splits sizes.\n","Dataset text downloaded and prepared to /root/.cache/huggingface/datasets/text/default-e3977a958449e6ba/0.0.0/4b86d314f7236db91f0a0f5cda32d4375445e64c5eda2692655dd99c2dac68e8. Subsequent calls will reuse this data.\n","100% 1/1 [00:00<00:00, 81.69it/s]\n","05/23/2022 15:56:38 - WARNING - datasets.builder - Using custom data configuration default-e3977a958449e6ba\n","05/23/2022 15:56:38 - INFO - datasets.builder - Overwrite dataset info from restored data version.\n","05/23/2022 15:56:38 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/text/default-e3977a958449e6ba/0.0.0/4b86d314f7236db91f0a0f5cda32d4375445e64c5eda2692655dd99c2dac68e8\n","05/23/2022 15:56:38 - WARNING - datasets.builder - Reusing dataset text (/root/.cache/huggingface/datasets/text/default-e3977a958449e6ba/0.0.0/4b86d314f7236db91f0a0f5cda32d4375445e64c5eda2692655dd99c2dac68e8)\n","05/23/2022 15:56:38 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/text/default-e3977a958449e6ba/0.0.0/4b86d314f7236db91f0a0f5cda32d4375445e64c5eda2692655dd99c2dac68e8\n","05/23/2022 15:56:38 - WARNING - datasets.builder - Using custom data configuration default-e3977a958449e6ba\n","05/23/2022 15:56:38 - INFO - datasets.builder - Overwrite dataset info from restored data version.\n","05/23/2022 15:56:38 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/text/default-e3977a958449e6ba/0.0.0/4b86d314f7236db91f0a0f5cda32d4375445e64c5eda2692655dd99c2dac68e8\n","05/23/2022 15:56:38 - WARNING - datasets.builder - Reusing dataset text (/root/.cache/huggingface/datasets/text/default-e3977a958449e6ba/0.0.0/4b86d314f7236db91f0a0f5cda32d4375445e64c5eda2692655dd99c2dac68e8)\n","05/23/2022 15:56:38 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/text/default-e3977a958449e6ba/0.0.0/4b86d314f7236db91f0a0f5cda32d4375445e64c5eda2692655dd99c2dac68e8\n","[INFO|hub.py:583] 2022-05-23 15:56:39,362 >> https://huggingface.co/Jean-Baptiste/camembert-ner/resolve/main/config.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmp4825edye\n","Downloading: 100% 892/892 [00:00<00:00, 503kB/s]\n","[INFO|hub.py:587] 2022-05-23 15:56:39,737 >> storing https://huggingface.co/Jean-Baptiste/camembert-ner/resolve/main/config.json in cache at /root/.cache/huggingface/transformers/0ca0fa98897ddf36d30f9a4f597bc247f48b49acee6ada696ef37f71ad0c7183.72890737d36e24d44eee8889cd355932b6b45361a99f9a231076186f3562e80b\n","[INFO|hub.py:595] 2022-05-23 15:56:39,737 >> creating metadata file for /root/.cache/huggingface/transformers/0ca0fa98897ddf36d30f9a4f597bc247f48b49acee6ada696ef37f71ad0c7183.72890737d36e24d44eee8889cd355932b6b45361a99f9a231076186f3562e80b\n","[INFO|configuration_utils.py:659] 2022-05-23 15:56:39,738 >> loading configuration file https://huggingface.co/Jean-Baptiste/camembert-ner/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/0ca0fa98897ddf36d30f9a4f597bc247f48b49acee6ada696ef37f71ad0c7183.72890737d36e24d44eee8889cd355932b6b45361a99f9a231076186f3562e80b\n","[INFO|configuration_utils.py:708] 2022-05-23 15:56:39,739 >> Model config CamembertConfig {\n","  \"_name_or_path\": \"Jean-Baptiste/camembert-ner\",\n","  \"architectures\": [\n","    \"CamembertForTokenClassification\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 5,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 6,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"O\",\n","    \"1\": \"I-LOC\",\n","    \"2\": \"I-PER\",\n","    \"3\": \"I-MISC\",\n","    \"4\": \"I-ORG\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"label2id\": {\n","    \"I-LOC\": 1,\n","    \"I-MISC\": 3,\n","    \"I-ORG\": 4,\n","    \"I-PER\": 2,\n","    \"O\": 0\n","  },\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"camembert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.19.2\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 32005\n","}\n","\n","[INFO|hub.py:583] 2022-05-23 15:56:40,110 >> https://huggingface.co/Jean-Baptiste/camembert-ner/resolve/main/tokenizer_config.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpmn087ohm\n","Downloading: 100% 269/269 [00:00<00:00, 209kB/s]\n","[INFO|hub.py:587] 2022-05-23 15:56:40,479 >> storing https://huggingface.co/Jean-Baptiste/camembert-ner/resolve/main/tokenizer_config.json in cache at /root/.cache/huggingface/transformers/698cd84321395889697c8edd4faa9b4a65ddf410a9825c8a4b046cb94c2c220d.1f67f456146012f1824eb9498c5438252647f9c4a05d37e8cb1de960505fbff9\n","[INFO|hub.py:595] 2022-05-23 15:56:40,479 >> creating metadata file for /root/.cache/huggingface/transformers/698cd84321395889697c8edd4faa9b4a65ddf410a9825c8a4b046cb94c2c220d.1f67f456146012f1824eb9498c5438252647f9c4a05d37e8cb1de960505fbff9\n","[INFO|configuration_utils.py:659] 2022-05-23 15:56:40,845 >> loading configuration file https://huggingface.co/Jean-Baptiste/camembert-ner/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/0ca0fa98897ddf36d30f9a4f597bc247f48b49acee6ada696ef37f71ad0c7183.72890737d36e24d44eee8889cd355932b6b45361a99f9a231076186f3562e80b\n","[INFO|configuration_utils.py:708] 2022-05-23 15:56:40,846 >> Model config CamembertConfig {\n","  \"_name_or_path\": \"Jean-Baptiste/camembert-ner\",\n","  \"architectures\": [\n","    \"CamembertForTokenClassification\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 5,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 6,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"O\",\n","    \"1\": \"I-LOC\",\n","    \"2\": \"I-PER\",\n","    \"3\": \"I-MISC\",\n","    \"4\": \"I-ORG\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"label2id\": {\n","    \"I-LOC\": 1,\n","    \"I-MISC\": 3,\n","    \"I-ORG\": 4,\n","    \"I-PER\": 2,\n","    \"O\": 0\n","  },\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"camembert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.19.2\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 32005\n","}\n","\n","[INFO|hub.py:583] 2022-05-23 15:56:41,585 >> https://huggingface.co/Jean-Baptiste/camembert-ner/resolve/main/sentencepiece.bpe.model not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpgx97_a9b\n","Downloading: 100% 792k/792k [00:00<00:00, 14.4MB/s]\n","[INFO|hub.py:587] 2022-05-23 15:56:41,738 >> storing https://huggingface.co/Jean-Baptiste/camembert-ner/resolve/main/sentencepiece.bpe.model in cache at /root/.cache/huggingface/transformers/22d115f43e0f0f7c76775875f4882c6edf818acd82eec9c24f88c68364b61594.1092b49637a91e74723b3bca56ef1baa3b70e86dd2e54222c53f6e1e5a310676\n","[INFO|hub.py:595] 2022-05-23 15:56:41,738 >> creating metadata file for /root/.cache/huggingface/transformers/22d115f43e0f0f7c76775875f4882c6edf818acd82eec9c24f88c68364b61594.1092b49637a91e74723b3bca56ef1baa3b70e86dd2e54222c53f6e1e5a310676\n","[INFO|hub.py:583] 2022-05-23 15:56:42,841 >> https://huggingface.co/Jean-Baptiste/camembert-ner/resolve/main/special_tokens_map.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpvk10fl2v\n","Downloading: 100% 210/210 [00:00<00:00, 174kB/s]\n","[INFO|hub.py:587] 2022-05-23 15:56:43,210 >> storing https://huggingface.co/Jean-Baptiste/camembert-ner/resolve/main/special_tokens_map.json in cache at /root/.cache/huggingface/transformers/fe0e213c44079a9ee091098f81fff2941484006e9ba3001a9bf1ee9f87537599.cb3ec3a6c1200d181228d8825ae9767572abca54efa1bbb37fd83d721b2ef323\n","[INFO|hub.py:595] 2022-05-23 15:56:43,210 >> creating metadata file for /root/.cache/huggingface/transformers/fe0e213c44079a9ee091098f81fff2941484006e9ba3001a9bf1ee9f87537599.cb3ec3a6c1200d181228d8825ae9767572abca54efa1bbb37fd83d721b2ef323\n","[INFO|tokenization_utils_base.py:1782] 2022-05-23 15:56:43,585 >> loading file https://huggingface.co/Jean-Baptiste/camembert-ner/resolve/main/sentencepiece.bpe.model from cache at /root/.cache/huggingface/transformers/22d115f43e0f0f7c76775875f4882c6edf818acd82eec9c24f88c68364b61594.1092b49637a91e74723b3bca56ef1baa3b70e86dd2e54222c53f6e1e5a310676\n","[INFO|tokenization_utils_base.py:1782] 2022-05-23 15:56:43,585 >> loading file https://huggingface.co/Jean-Baptiste/camembert-ner/resolve/main/tokenizer.json from cache at None\n","[INFO|tokenization_utils_base.py:1782] 2022-05-23 15:56:43,585 >> loading file https://huggingface.co/Jean-Baptiste/camembert-ner/resolve/main/added_tokens.json from cache at None\n","[INFO|tokenization_utils_base.py:1782] 2022-05-23 15:56:43,585 >> loading file https://huggingface.co/Jean-Baptiste/camembert-ner/resolve/main/special_tokens_map.json from cache at /root/.cache/huggingface/transformers/fe0e213c44079a9ee091098f81fff2941484006e9ba3001a9bf1ee9f87537599.cb3ec3a6c1200d181228d8825ae9767572abca54efa1bbb37fd83d721b2ef323\n","[INFO|tokenization_utils_base.py:1782] 2022-05-23 15:56:43,586 >> loading file https://huggingface.co/Jean-Baptiste/camembert-ner/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/698cd84321395889697c8edd4faa9b4a65ddf410a9825c8a4b046cb94c2c220d.1f67f456146012f1824eb9498c5438252647f9c4a05d37e8cb1de960505fbff9\n","[INFO|configuration_utils.py:659] 2022-05-23 15:56:43,957 >> loading configuration file https://huggingface.co/Jean-Baptiste/camembert-ner/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/0ca0fa98897ddf36d30f9a4f597bc247f48b49acee6ada696ef37f71ad0c7183.72890737d36e24d44eee8889cd355932b6b45361a99f9a231076186f3562e80b\n","[INFO|configuration_utils.py:708] 2022-05-23 15:56:43,958 >> Model config CamembertConfig {\n","  \"_name_or_path\": \"Jean-Baptiste/camembert-ner\",\n","  \"architectures\": [\n","    \"CamembertForTokenClassification\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 5,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 6,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"O\",\n","    \"1\": \"I-LOC\",\n","    \"2\": \"I-PER\",\n","    \"3\": \"I-MISC\",\n","    \"4\": \"I-ORG\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"label2id\": {\n","    \"I-LOC\": 1,\n","    \"I-MISC\": 3,\n","    \"I-ORG\": 4,\n","    \"I-PER\": 2,\n","    \"O\": 0\n","  },\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"camembert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.19.2\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 32005\n","}\n","\n","[INFO|configuration_utils.py:659] 2022-05-23 15:56:44,399 >> loading configuration file https://huggingface.co/Jean-Baptiste/camembert-ner/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/0ca0fa98897ddf36d30f9a4f597bc247f48b49acee6ada696ef37f71ad0c7183.72890737d36e24d44eee8889cd355932b6b45361a99f9a231076186f3562e80b\n","[INFO|configuration_utils.py:708] 2022-05-23 15:56:44,401 >> Model config CamembertConfig {\n","  \"_name_or_path\": \"Jean-Baptiste/camembert-ner\",\n","  \"architectures\": [\n","    \"CamembertForTokenClassification\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 5,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 6,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"O\",\n","    \"1\": \"I-LOC\",\n","    \"2\": \"I-PER\",\n","    \"3\": \"I-MISC\",\n","    \"4\": \"I-ORG\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"label2id\": {\n","    \"I-LOC\": 1,\n","    \"I-MISC\": 3,\n","    \"I-ORG\": 4,\n","    \"I-PER\": 2,\n","    \"O\": 0\n","  },\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"camembert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.19.2\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 32005\n","}\n","\n","[INFO|hub.py:583] 2022-05-23 15:56:44,931 >> https://huggingface.co/Jean-Baptiste/camembert-ner/resolve/main/pytorch_model.bin not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmp87h211di\n","Downloading: 100% 420M/420M [00:08<00:00, 53.3MB/s]\n","[INFO|hub.py:587] 2022-05-23 15:56:53,259 >> storing https://huggingface.co/Jean-Baptiste/camembert-ner/resolve/main/pytorch_model.bin in cache at /root/.cache/huggingface/transformers/a0f287c684a81b3f5603d8c73a8303a2a554446a51e28b08e5715f301f4012e1.9ea323d73321b5d2aea778b0154b8beb9d4d48ac674ec068ec5dbb931efcd859\n","[INFO|hub.py:595] 2022-05-23 15:56:53,259 >> creating metadata file for /root/.cache/huggingface/transformers/a0f287c684a81b3f5603d8c73a8303a2a554446a51e28b08e5715f301f4012e1.9ea323d73321b5d2aea778b0154b8beb9d4d48ac674ec068ec5dbb931efcd859\n","[INFO|modeling_utils.py:1953] 2022-05-23 15:56:53,260 >> loading weights file https://huggingface.co/Jean-Baptiste/camembert-ner/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/a0f287c684a81b3f5603d8c73a8303a2a554446a51e28b08e5715f301f4012e1.9ea323d73321b5d2aea778b0154b8beb9d4d48ac674ec068ec5dbb931efcd859\n","[WARNING|modeling_utils.py:2255] 2022-05-23 15:56:54,975 >> Some weights of the model checkpoint at Jean-Baptiste/camembert-ner were not used when initializing CamembertForMaskedLM: ['classifier.bias', 'classifier.weight']\n","- This IS expected if you are initializing CamembertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing CamembertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","[WARNING|modeling_utils.py:2266] 2022-05-23 15:56:54,975 >> Some weights of CamembertForMaskedLM were not initialized from the model checkpoint at Jean-Baptiste/camembert-ner and are newly initialized: ['lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Running tokenizer on dataset line_by_line:   0% 0/803 [00:00<?, ?ba/s]05/23/2022 15:56:55 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/text/default-e3977a958449e6ba/0.0.0/4b86d314f7236db91f0a0f5cda32d4375445e64c5eda2692655dd99c2dac68e8/cache-5b3062ecfd8d22c8.arrow\n","Running tokenizer on dataset line_by_line: 100% 803/803 [00:53<00:00, 14.90ba/s]\n","Running tokenizer on dataset line_by_line:   0% 0/43 [00:00<?, ?ba/s]05/23/2022 15:57:49 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/text/default-e3977a958449e6ba/0.0.0/4b86d314f7236db91f0a0f5cda32d4375445e64c5eda2692655dd99c2dac68e8/cache-e3b01d0b94805508.arrow\n","Running tokenizer on dataset line_by_line: 100% 43/43 [00:02<00:00, 14.52ba/s]\n","[INFO|trainer.py:623] 2022-05-23 15:57:51,938 >> The following columns in the training set don't have a corresponding argument in `CamembertForMaskedLM.forward` and have been ignored: special_tokens_mask. If special_tokens_mask are not expected by `CamembertForMaskedLM.forward`,  you can safely ignore this message.\n","/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","[INFO|trainer.py:1419] 2022-05-23 15:57:51,948 >> ***** Running training *****\n","[INFO|trainer.py:1420] 2022-05-23 15:57:51,948 >>   Num examples = 802763\n","[INFO|trainer.py:1421] 2022-05-23 15:57:51,948 >>   Num Epochs = 3\n","[INFO|trainer.py:1422] 2022-05-23 15:57:51,948 >>   Instantaneous batch size per device = 8\n","[INFO|trainer.py:1423] 2022-05-23 15:57:51,948 >>   Total train batch size (w. parallel, distributed & accumulation) = 8\n","[INFO|trainer.py:1424] 2022-05-23 15:57:51,948 >>   Gradient Accumulation steps = 1\n","[INFO|trainer.py:1425] 2022-05-23 15:57:51,948 >>   Total optimization steps = 301038\n","  0% 4/301038 [00:23<518:21:11,  6.20s/it]Traceback (most recent call last):\n","  File \"util/pretrain_camembert.py\", line 557, in <module>\n","    main()\n","  File \"util/pretrain_camembert.py\", line 506, in main\n","    train_result = trainer.train(resume_from_checkpoint=checkpoint)\n","  File \"/usr/local/lib/python3.7/dist-packages/transformers/trainer.py\", line 1321, in train\n","    ignore_keys_for_eval=ignore_keys_for_eval,\n","  File \"/usr/local/lib/python3.7/dist-packages/transformers/trainer.py\", line 1619, in _inner_training_loop\n","    self.optimizer.step()\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py\", line 65, in wrapper\n","    return wrapped(*args, **kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n","    return func(*args, **kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/transformers/optimization.py\", line 369, in step\n","    p.data.addcdiv_(exp_avg, denom, value=-step_size)\n","KeyboardInterrupt\n","  0% 4/301038 [00:27<564:58:17,  6.76s/it]\n"]}],"source":["\"\"\" Actually runs the pretraining.\n","On GColab you'd certainly want to activate GPU acceleration before training !\n","\"\"\"\n","\n","# Get the name of the temp folder and save the file to that folder.\n","temp_dir = tempfile.gettempdir()\n","!python util/pretrain_camembert.py --model_name_or_path \"Jean-Baptiste/camembert-ner\" --train_file \"{temp_dir}/pretraining_data.txt\" --do_train --do_eval --line_by_line --output_dir \"${config.BASEDIR}/10-camembert_pretrained_model\" --save_total_limit 1 --load_best_model_at_end True --evaluation_strategy \"steps\" --save_strategy \"steps\""]}],"metadata":{"kernelspec":{"display_name":"Python 3.10.4 ('ner')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.4"},"vscode":{"interpreter":{"hash":"c57d6dc83202ed16477ed01fbeb8d45268fb6711c5da666dad291c245339c394"}},"colab":{"name":"10-camembert_pretraining.ipynb","provenance":[],"collapsed_sections":[]}},"nbformat":4,"nbformat_minor":5}