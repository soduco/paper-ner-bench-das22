{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4d13fee-3305-4991-8a1f-f9ef149e5b2f",
   "metadata": {},
   "source": [
    "# 10 - Pretraining CamemBERT\n",
    "\n",
    "Run the script below with :\n",
    "- train_file: the local absolute path to paper-ner-bench-das22/dataset/unsupervised_pretraining/10-normalized/all.txt\n",
    "- output_dir: where to save the pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ddc01488-30ac-4929-b2ad-e097786e65f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: DEBUG=1\n",
      "env: AS_IN_THE_PAPER=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18/05/2022 03:32:38 ; INFO ; ======= CONFIGURATION =======\n",
      "18/05/2022 03:32:38 ; INFO ; BASEDIR: /home/bertrand/paper-ner-bench-das22\n",
      "18/05/2022 03:32:38 ; INFO ; Input datasets will be loaded from DATASETDIR /home/bertrand/paper-ner-bench-das22/dataset\n",
      "18/05/2022 03:32:38 ; INFO ; Training data and models will be saved to NERDIR /home/bertrand/paper-ner-bench-das22/src/ner\n",
      "18/05/2022 03:32:38 ; INFO ; Debug mode is ON\n",
      "18/05/2022 03:32:38 ; INFO ; Random seed: 42\n",
      "18/05/2022 03:32:38 ; INFO ; Enable reproducibility checks: True\n",
      "18/05/2022 03:32:38 ; INFO ; ============================\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Loads the configuration \"\"\"\n",
    "\n",
    "# Set to 1/true/ to set the logging level of nerlogger to DEBUG \n",
    "# and save the the spacy datasets as TXT along with the .spacy file\n",
    "#  for easier debug of the training set generation.\n",
    "%env DEBUG=1\n",
    "\n",
    "# If True, activates a set of assertions in the notebooks to ensure\n",
    "# that the scripts runs with the parameters used in the paper.\n",
    "%env AS_IN_THE_PAPER = True\n",
    "\n",
    "import util.config as config\n",
    "\n",
    "config.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "966a20fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Import all modules at once \"\"\"\n",
    "\n",
    "# General imports\n",
    "import nltk\n",
    "import gzip\n",
    "\n",
    "# NER imports\n",
    "from util.as_in_the_paper import assert_expected\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b7a3e31-243a-4fa7-a6c4-b39bf9ad42ca",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 11 - Creation of the pre-training set from raw entries extracted with OCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "98f8aa0c-91ff-48e9-9be0-f9bb4cf5779f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/bertrand/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid entries:845014, 0.808105.2 percent of the total\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "pretraining_set_path = config.DATASETDIR / \"unsupervised_pretraining/10-normalized\"\n",
    "\n",
    "# Filter the normalized pre-training \n",
    "# Keep only entries containing at least MIN_WORDS_PER_ENTRY words\n",
    "MIN_WORDS_PER_ENTRY = 7 # Keep simples entries like \"Morel abbé ,Tournon, 14.\"\n",
    "\n",
    "assert_expected(actual=MIN_WORDS_PER_ENTRY, expected=7)\n",
    "\n",
    "nltk.download(\"punkt\")\n",
    "number_of_entries = 0\n",
    "valid_entries = []\n",
    "\n",
    "with gzip.open(pretraining_set_path / \"all.txt.gz\", \"rt\") as all_txt:\n",
    "    for entry in all_txt:\n",
    "        entry = entry.strip() # Sanitize\n",
    "        words = nltk.word_tokenize(entry, language=\"fr\", preserve_line=True)\n",
    "        if len(words) >= MIN_WORDS_PER_ENTRY:\n",
    "            valid_entries.append(entry)\n",
    "        number_of_entries += 1\n",
    "        \n",
    "with open(pretraining_set_path / \"all_filtered.txt\", \"w\") as wfp:\n",
    "    wfp.write(\"\\n\".join(valid_entries))\n",
    "\n",
    "print(\"Valid entries:%d, %f.2 percent of the total\" % (len(valid_entries),len(valid_entries) / number_of_entries))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5e9321-957b-4dbe-867c-437cadcc8c2e",
   "metadata": {},
   "source": [
    "## 12 - Pretraining CamemBERT on domain texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be1e366-78cc-4a3d-b62d-28c07dd63732",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python pretrain_camembert.py --model_name_or_path \"Jean-Baptiste/camembert-ner\" --train_file \"${PRETRAINING_SET_PATH}/unsupervised_pretraining/10-normalized/all_filtered.txt\" --do_train --do_eval --line_by_line --output_dir \"${BASE}/10-camembert_pretrained_model\" --save_total_limit 1 --load_best_model_at_end True --evaluation_strategy \"steps\" --save_strategy \"steps\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('ner')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "c57d6dc83202ed16477ed01fbeb8d45268fb6711c5da666dad291c245339c394"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
