{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd8b9c98-bde1-468c-a4ef-66fae2ac9fce",
   "metadata": {},
   "source": [
    "# 10 - Pretraining CamemBERT\n",
    "\n",
    "Run the script below with :\n",
    "- train_file: the local absolute path to paper-ner-bench-das22/dataset/unsupervised_pretraining/10-normalized/all.txt\n",
    "- output_dir: where to save the pretrained model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b7a3e31-243a-4fa7-a6c4-b39bf9ad42ca",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Create the filtered pre-training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "98f8aa0c-91ff-48e9-9be0-f9bb4cf5779f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/bertrand/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid entries:845014, 0.808105.2 percent of the total\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "# Filter the normalized pre-training \n",
    "# Keep only entries containing at least MIN_WORDS_PER_ENTRY words\n",
    "PRETRAINING_SET_PATH = Path(\"/home/bertrand/dev/paper-ner-bench-das22/dataset/unsupervised_pretraining/10-normalized/all.txt\")\n",
    "MIN_WORDS_PER_ENTRY = 7 # Keep simples entries like \"Morel abbé ,Tournon, 14.\"\n",
    "\n",
    "nltk.download(\"punkt\")\n",
    "nlines = 0\n",
    "valid_entries = []\n",
    "\n",
    "with open(PRETRAINING_SET_PATH, \"r\", encoding=\"utf-8\") as fp:\n",
    "    for l in fp:\n",
    "        l = l.strip() # Sanitize\n",
    "        words = nltk.word_tokenize(l, language=\"fr\", preserve_line=True)\n",
    "        if len(words) >= MIN_WORDS_PER_ENTRY:\n",
    "            valid_entries.append(l)\n",
    "        nlines += 1\n",
    "        \n",
    "with open(PRETRAINING_SET_PATH.parent / \"all_filtered.txt\", \"w\") as wfp:\n",
    "    wfp.write(\"\\n\".join(valid_entries))\n",
    "\n",
    "print(\"Valid entries:%d, %f.2 percent of the total\" % (len(valid_entries),len(valid_entries)/nlines))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5e9321-957b-4dbe-867c-437cadcc8c2e",
   "metadata": {},
   "source": [
    "## Pretrain CamemBERT !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1be1e366-78cc-4a3d-b62d-28c07dd63732",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01/16/2022 00:43:49 - WARNING - __main__ - Process rank: -1, device: cpu, n_gpu: 0distributed training: False, 16-bits training: False\n",
      "01/16/2022 00:43:49 - INFO - __main__ - Training/evaluation parameters TrainingArguments(\n",
      "_n_gpu=0,\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "bf16=False,\n",
      "bf16_full_eval=False,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=0,\n",
      "dataloader_pin_memory=True,\n",
      "ddp_bucket_cap_mb=None,\n",
      "ddp_find_unused_parameters=None,\n",
      "debug=[],\n",
      "deepspeed=None,\n",
      "disable_tqdm=False,\n",
      "do_eval=True,\n",
      "do_predict=False,\n",
      "do_train=True,\n",
      "eval_accumulation_steps=None,\n",
      "eval_steps=500,\n",
      "evaluation_strategy=IntervalStrategy.STEPS,\n",
      "fp16=False,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "gradient_accumulation_steps=1,\n",
      "gradient_checkpointing=False,\n",
      "greater_is_better=False,\n",
      "group_by_length=False,\n",
      "half_precision_backend=auto,\n",
      "hub_model_id=None,\n",
      "hub_strategy=HubStrategy.EVERY_SAVE,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=5e-05,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=True,\n",
      "local_rank=-1,\n",
      "log_level=-1,\n",
      "log_level_replica=-1,\n",
      "log_on_each_node=True,\n",
      "logging_dir=./10-camembert_pretraining/model/runs/Jan16_00-43-49_Marvin,\n",
      "logging_first_step=False,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=500,\n",
      "logging_strategy=IntervalStrategy.STEPS,\n",
      "lr_scheduler_type=SchedulerType.LINEAR,\n",
      "max_grad_norm=1.0,\n",
      "max_steps=-1,\n",
      "metric_for_best_model=loss,\n",
      "mp_parameters=,\n",
      "no_cuda=False,\n",
      "num_train_epochs=3.0,\n",
      "output_dir=./10-camembert_pretraining/model,\n",
      "overwrite_output_dir=False,\n",
      "past_index=-1,\n",
      "per_device_eval_batch_size=8,\n",
      "per_device_train_batch_size=8,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "remove_unused_columns=True,\n",
      "report_to=[],\n",
      "resume_from_checkpoint=None,\n",
      "run_name=./10-camembert_pretraining/model,\n",
      "save_on_each_node=False,\n",
      "save_steps=500,\n",
      "save_strategy=IntervalStrategy.STEPS,\n",
      "save_total_limit=1,\n",
      "seed=42,\n",
      "sharded_ddp=[],\n",
      "skip_memory_metrics=True,\n",
      "tf32=None,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_legacy_prediction_loop=False,\n",
      "warmup_ratio=0.0,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.0,\n",
      "xpu_backend=None,\n",
      ")\n",
      "01/16/2022 00:43:49 - WARNING - datasets.builder - Using custom data configuration default-43d401314dafcc5a\n",
      "01/16/2022 00:43:49 - INFO - datasets.builder - Overwrite dataset info from restored data version.\n",
      "01/16/2022 00:43:49 - INFO - datasets.info - Loading Dataset info from /home/bertrand/.cache/huggingface/datasets/text/default-43d401314dafcc5a/0.0.0/d86c40dad297bdddf277b406c6a59f0250b5318c400bf23d420a31aff88c84c4\n",
      "01/16/2022 00:43:49 - WARNING - datasets.builder - Reusing dataset text (/home/bertrand/.cache/huggingface/datasets/text/default-43d401314dafcc5a/0.0.0/d86c40dad297bdddf277b406c6a59f0250b5318c400bf23d420a31aff88c84c4)\n",
      "01/16/2022 00:43:49 - INFO - datasets.info - Loading Dataset info from /home/bertrand/.cache/huggingface/datasets/text/default-43d401314dafcc5a/0.0.0/d86c40dad297bdddf277b406c6a59f0250b5318c400bf23d420a31aff88c84c4\n",
      "100%|████████████████████████████████████████████| 1/1 [00:00<00:00, 146.43it/s]\n",
      "01/16/2022 00:43:50 - WARNING - datasets.builder - Using custom data configuration default-43d401314dafcc5a\n",
      "01/16/2022 00:43:50 - INFO - datasets.builder - Overwrite dataset info from restored data version.\n",
      "01/16/2022 00:43:50 - INFO - datasets.info - Loading Dataset info from /home/bertrand/.cache/huggingface/datasets/text/default-43d401314dafcc5a/0.0.0/d86c40dad297bdddf277b406c6a59f0250b5318c400bf23d420a31aff88c84c4\n",
      "01/16/2022 00:43:50 - WARNING - datasets.builder - Reusing dataset text (/home/bertrand/.cache/huggingface/datasets/text/default-43d401314dafcc5a/0.0.0/d86c40dad297bdddf277b406c6a59f0250b5318c400bf23d420a31aff88c84c4)\n",
      "01/16/2022 00:43:50 - INFO - datasets.info - Loading Dataset info from /home/bertrand/.cache/huggingface/datasets/text/default-43d401314dafcc5a/0.0.0/d86c40dad297bdddf277b406c6a59f0250b5318c400bf23d420a31aff88c84c4\n",
      "01/16/2022 00:43:50 - WARNING - datasets.builder - Using custom data configuration default-43d401314dafcc5a\n",
      "01/16/2022 00:43:50 - INFO - datasets.builder - Overwrite dataset info from restored data version.\n",
      "01/16/2022 00:43:50 - INFO - datasets.info - Loading Dataset info from /home/bertrand/.cache/huggingface/datasets/text/default-43d401314dafcc5a/0.0.0/d86c40dad297bdddf277b406c6a59f0250b5318c400bf23d420a31aff88c84c4\n",
      "01/16/2022 00:43:50 - WARNING - datasets.builder - Reusing dataset text (/home/bertrand/.cache/huggingface/datasets/text/default-43d401314dafcc5a/0.0.0/d86c40dad297bdddf277b406c6a59f0250b5318c400bf23d420a31aff88c84c4)\n",
      "01/16/2022 00:43:50 - INFO - datasets.info - Loading Dataset info from /home/bertrand/.cache/huggingface/datasets/text/default-43d401314dafcc5a/0.0.0/d86c40dad297bdddf277b406c6a59f0250b5318c400bf23d420a31aff88c84c4\n",
      "[INFO|configuration_utils.py:606] 2022-01-16 00:43:51,636 >> loading configuration file https://huggingface.co/Jean-Baptiste/camembert-ner/resolve/main/config.json from cache at /home/bertrand/.cache/huggingface/transformers/0ca0fa98897ddf36d30f9a4f597bc247f48b49acee6ada696ef37f71ad0c7183.72890737d36e24d44eee8889cd355932b6b45361a99f9a231076186f3562e80b\n",
      "[INFO|configuration_utils.py:643] 2022-01-16 00:43:51,639 >> Model config CamembertConfig {\n",
      "  \"_name_or_path\": \"Jean-Baptiste/camembert-ner\",\n",
      "  \"architectures\": [\n",
      "    \"CamembertForTokenClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 5,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 6,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"O\",\n",
      "    \"1\": \"I-LOC\",\n",
      "    \"2\": \"I-PER\",\n",
      "    \"3\": \"I-MISC\",\n",
      "    \"4\": \"I-ORG\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"I-LOC\": 1,\n",
      "    \"I-MISC\": 3,\n",
      "    \"I-ORG\": 4,\n",
      "    \"I-PER\": 2,\n",
      "    \"O\": 0\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"camembert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.15.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32005\n",
      "}\n",
      "\n",
      "[INFO|configuration_utils.py:606] 2022-01-16 00:43:53,397 >> loading configuration file https://huggingface.co/Jean-Baptiste/camembert-ner/resolve/main/config.json from cache at /home/bertrand/.cache/huggingface/transformers/0ca0fa98897ddf36d30f9a4f597bc247f48b49acee6ada696ef37f71ad0c7183.72890737d36e24d44eee8889cd355932b6b45361a99f9a231076186f3562e80b\n",
      "[INFO|configuration_utils.py:643] 2022-01-16 00:43:53,400 >> Model config CamembertConfig {\n",
      "  \"_name_or_path\": \"Jean-Baptiste/camembert-ner\",\n",
      "  \"architectures\": [\n",
      "    \"CamembertForTokenClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 5,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 6,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"O\",\n",
      "    \"1\": \"I-LOC\",\n",
      "    \"2\": \"I-PER\",\n",
      "    \"3\": \"I-MISC\",\n",
      "    \"4\": \"I-ORG\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"I-LOC\": 1,\n",
      "    \"I-MISC\": 3,\n",
      "    \"I-ORG\": 4,\n",
      "    \"I-PER\": 2,\n",
      "    \"O\": 0\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"camembert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.15.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32005\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:1745] 2022-01-16 00:43:56,968 >> loading file https://huggingface.co/Jean-Baptiste/camembert-ner/resolve/main/sentencepiece.bpe.model from cache at /home/bertrand/.cache/huggingface/transformers/22d115f43e0f0f7c76775875f4882c6edf818acd82eec9c24f88c68364b61594.1092b49637a91e74723b3bca56ef1baa3b70e86dd2e54222c53f6e1e5a310676\n",
      "[INFO|tokenization_utils_base.py:1745] 2022-01-16 00:43:56,969 >> loading file https://huggingface.co/Jean-Baptiste/camembert-ner/resolve/main/tokenizer.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:1745] 2022-01-16 00:43:56,969 >> loading file https://huggingface.co/Jean-Baptiste/camembert-ner/resolve/main/added_tokens.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:1745] 2022-01-16 00:43:56,969 >> loading file https://huggingface.co/Jean-Baptiste/camembert-ner/resolve/main/special_tokens_map.json from cache at /home/bertrand/.cache/huggingface/transformers/fe0e213c44079a9ee091098f81fff2941484006e9ba3001a9bf1ee9f87537599.cb3ec3a6c1200d181228d8825ae9767572abca54efa1bbb37fd83d721b2ef323\n",
      "[INFO|tokenization_utils_base.py:1745] 2022-01-16 00:43:56,969 >> loading file https://huggingface.co/Jean-Baptiste/camembert-ner/resolve/main/tokenizer_config.json from cache at /home/bertrand/.cache/huggingface/transformers/698cd84321395889697c8edd4faa9b4a65ddf410a9825c8a4b046cb94c2c220d.1f67f456146012f1824eb9498c5438252647f9c4a05d37e8cb1de960505fbff9\n",
      "[INFO|configuration_utils.py:606] 2022-01-16 00:43:58,317 >> loading configuration file https://huggingface.co/Jean-Baptiste/camembert-ner/resolve/main/config.json from cache at /home/bertrand/.cache/huggingface/transformers/0ca0fa98897ddf36d30f9a4f597bc247f48b49acee6ada696ef37f71ad0c7183.72890737d36e24d44eee8889cd355932b6b45361a99f9a231076186f3562e80b\n",
      "[INFO|configuration_utils.py:643] 2022-01-16 00:43:58,319 >> Model config CamembertConfig {\n",
      "  \"_name_or_path\": \"Jean-Baptiste/camembert-ner\",\n",
      "  \"architectures\": [\n",
      "    \"CamembertForTokenClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 5,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 6,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"O\",\n",
      "    \"1\": \"I-LOC\",\n",
      "    \"2\": \"I-PER\",\n",
      "    \"3\": \"I-MISC\",\n",
      "    \"4\": \"I-ORG\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"I-LOC\": 1,\n",
      "    \"I-MISC\": 3,\n",
      "    \"I-ORG\": 4,\n",
      "    \"I-PER\": 2,\n",
      "    \"O\": 0\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"camembert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.15.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32005\n",
      "}\n",
      "\n",
      "[INFO|configuration_utils.py:606] 2022-01-16 00:43:59,539 >> loading configuration file https://huggingface.co/Jean-Baptiste/camembert-ner/resolve/main/config.json from cache at /home/bertrand/.cache/huggingface/transformers/0ca0fa98897ddf36d30f9a4f597bc247f48b49acee6ada696ef37f71ad0c7183.72890737d36e24d44eee8889cd355932b6b45361a99f9a231076186f3562e80b\n",
      "[INFO|configuration_utils.py:643] 2022-01-16 00:43:59,540 >> Model config CamembertConfig {\n",
      "  \"_name_or_path\": \"Jean-Baptiste/camembert-ner\",\n",
      "  \"architectures\": [\n",
      "    \"CamembertForTokenClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 5,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 6,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"O\",\n",
      "    \"1\": \"I-LOC\",\n",
      "    \"2\": \"I-PER\",\n",
      "    \"3\": \"I-MISC\",\n",
      "    \"4\": \"I-ORG\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"I-LOC\": 1,\n",
      "    \"I-MISC\": 3,\n",
      "    \"I-ORG\": 4,\n",
      "    \"I-PER\": 2,\n",
      "    \"O\": 0\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"camembert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.15.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32005\n",
      "}\n",
      "\n",
      "[INFO|modeling_utils.py:1356] 2022-01-16 00:44:00,364 >> loading weights file https://huggingface.co/Jean-Baptiste/camembert-ner/resolve/main/pytorch_model.bin from cache at /home/bertrand/.cache/huggingface/transformers/a0f287c684a81b3f5603d8c73a8303a2a554446a51e28b08e5715f301f4012e1.9ea323d73321b5d2aea778b0154b8beb9d4d48ac674ec068ec5dbb931efcd859\n",
      "[WARNING|modeling_utils.py:1614] 2022-01-16 00:44:01,773 >> Some weights of the model checkpoint at Jean-Baptiste/camembert-ner were not used when initializing CamembertForMaskedLM: ['classifier.weight', 'classifier.bias']\n",
      "- This IS expected if you are initializing CamembertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing CamembertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "[WARNING|modeling_utils.py:1625] 2022-01-16 00:44:01,773 >> Some weights of CamembertForMaskedLM were not initialized from the model checkpoint at Jean-Baptiste/camembert-ner and are newly initialized: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Running tokenizer on dataset line_by_line:   0%|        | 0/909 [00:00<?, ?ba/s]01/16/2022 00:44:01 - INFO - datasets.arrow_dataset - Caching processed dataset at /home/bertrand/.cache/huggingface/datasets/text/default-43d401314dafcc5a/0.0.0/d86c40dad297bdddf277b406c6a59f0250b5318c400bf23d420a31aff88c84c4/cache-399bc41df8aa8672.arrow\n",
      "Running tokenizer on dataset line_by_line:  18%|▏| 167/909 [00:04<00:20, 36.42ba^C\n",
      "Running tokenizer on dataset line_by_line:  18%|▏| 167/909 [00:04<00:22, 33.71ba\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/bertrand/dev/paper-ner-bench-das22/src/ner/pretrain_camembert.py\", line 557, in <module>\n",
      "    main()\n",
      "  File \"/home/bertrand/dev/paper-ner-bench-das22/src/ner/pretrain_camembert.py\", line 408, in main\n",
      "    tokenized_datasets = raw_datasets.map(\n",
      "  File \"/home/bertrand/anaconda3/lib/python3.9/site-packages/datasets/dataset_dict.py\", line 494, in map\n",
      "    {\n",
      "  File \"/home/bertrand/anaconda3/lib/python3.9/site-packages/datasets/dataset_dict.py\", line 495, in <dictcomp>\n",
      "    k: dataset.map(\n",
      "  File \"/home/bertrand/anaconda3/lib/python3.9/site-packages/datasets/arrow_dataset.py\", line 2092, in map\n",
      "    return self._map_single(\n",
      "  File \"/home/bertrand/anaconda3/lib/python3.9/site-packages/datasets/arrow_dataset.py\", line 518, in wrapper\n",
      "    out: Union[\"Dataset\", \"DatasetDict\"] = func(self, *args, **kwargs)\n",
      "  File \"/home/bertrand/anaconda3/lib/python3.9/site-packages/datasets/arrow_dataset.py\", line 485, in wrapper\n",
      "    out: Union[\"Dataset\", \"DatasetDict\"] = func(self, *args, **kwargs)\n",
      "  File \"/home/bertrand/anaconda3/lib/python3.9/site-packages/datasets/fingerprint.py\", line 411, in wrapper\n",
      "    out = func(self, *args, **kwargs)\n",
      "  File \"/home/bertrand/anaconda3/lib/python3.9/site-packages/datasets/arrow_dataset.py\", line 2469, in _map_single\n",
      "    batch = apply_function_on_filtered_inputs(\n",
      "  File \"/home/bertrand/anaconda3/lib/python3.9/site-packages/datasets/arrow_dataset.py\", line 2357, in apply_function_on_filtered_inputs\n",
      "    processed_inputs = function(*fn_args, *additional_args, **fn_kwargs)\n",
      "  File \"/home/bertrand/anaconda3/lib/python3.9/site-packages/datasets/arrow_dataset.py\", line 2052, in decorated\n",
      "    result = f(decorated_item, *args, **kwargs)\n",
      "  File \"/home/bertrand/dev/paper-ner-bench-das22/src/ner/pretrain_camembert.py\", line 397, in tokenize_function\n",
      "    return tokenizer(\n",
      "  File \"/home/bertrand/anaconda3/lib/python3.9/site-packages/transformers/tokenization_utils_base.py\", line 2418, in __call__\n",
      "    return self.batch_encode_plus(\n",
      "  File \"/home/bertrand/anaconda3/lib/python3.9/site-packages/transformers/tokenization_utils_base.py\", line 2609, in batch_encode_plus\n",
      "    return self._batch_encode_plus(\n",
      "  File \"/home/bertrand/anaconda3/lib/python3.9/site-packages/transformers/tokenization_utils_fast.py\", line 409, in _batch_encode_plus\n",
      "    encodings = self._tokenizer.encode_batch(\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!python pretrain_camembert.py --model_name_or_path \"Jean-Baptiste/camembert-ner\" --train_file \"/home/bertrand/dev/paper-ner-bench-das22/dataset/unsupervised_pretraining/10-normalized/all_filtered.txt\" --do_train --do_eval --line_by_line --output_dir \"./10-camembert_pretraining/model\" --save_total_limit 1 --load_best_model_at_end True --evaluation_strategy \"steps\" --save_strategy \"steps\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c09bec2-a73b-40c5-a418-16ce314eb08e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
