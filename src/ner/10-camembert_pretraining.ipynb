{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4d13fee-3305-4991-8a1f-f9ef149e5b2f",
   "metadata": {},
   "source": [
    "# 10 - Pretraining CamemBERT\n",
    "\n",
    "Run the script below with :\n",
    "- train_file: the local absolute path to paper-ner-bench-das22/dataset/unsupervised_pretraining/10-normalized/all.txt\n",
    "- output_dir: where to save the pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ddc01488-30ac-4929-b2ad-e097786e65f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: DEBUG=1\n",
      "env: AS_IN_THE_PAPER=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18/05/2022 03:32:38 ; INFO ; ======= CONFIGURATION =======\n",
      "18/05/2022 03:32:38 ; INFO ; BASEDIR: /home/bertrand/paper-ner-bench-das22\n",
      "18/05/2022 03:32:38 ; INFO ; Input datasets will be loaded from DATASETDIR /home/bertrand/paper-ner-bench-das22/dataset\n",
      "18/05/2022 03:32:38 ; INFO ; Training data and models will be saved to NERDIR /home/bertrand/paper-ner-bench-das22/src/ner\n",
      "18/05/2022 03:32:38 ; INFO ; Debug mode is ON\n",
      "18/05/2022 03:32:38 ; INFO ; Random seed: 42\n",
      "18/05/2022 03:32:38 ; INFO ; Enable reproducibility checks: True\n",
      "18/05/2022 03:32:38 ; INFO ; ============================\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Loads the configuration \"\"\"\n",
    "\n",
    "# Set to 1/true/ to set the logging level of nerlogger to DEBUG \n",
    "# and save the the spacy datasets as TXT along with the .spacy file\n",
    "#  for easier debug of the training set generation.\n",
    "%env DEBUG=1\n",
    "\n",
    "# If True, activates a set of assertions in the notebooks to ensure\n",
    "# that the scripts runs with the parameters used in the paper.\n",
    "%env AS_IN_THE_PAPER = True\n",
    "\n",
    "import util.config as config\n",
    "\n",
    "config.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "966a20fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Import all modules at once \"\"\"\n",
    "\n",
    "# General imports\n",
    "import nltk\n",
    "import gzip\n",
    "\n",
    "# NER imports\n",
    "from util.as_in_the_paper import assert_expected\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b7a3e31-243a-4fa7-a6c4-b39bf9ad42ca",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 11 - Creation of the pre-training set from raw entries extracted with OCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "98f8aa0c-91ff-48e9-9be0-f9bb4cf5779f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/bertrand/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "845014\n",
      "Valid entries:845014, 0.808105.2 percent of the total\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "pretraining_set_path = config.DATASETDIR / \"unsupervised_pretraining/10-normalized\"\n",
    "\n",
    "# Filter the normalized pre-training \n",
    "# Keep only entries containing at least MIN_WORDS_PER_ENTRY words\n",
    "MIN_WORDS_PER_ENTRY = 7 # Keep simples entries like \"Morel abbé ,Tournon, 14.\"\n",
    "\n",
    "assert_expected(actual=MIN_WORDS_PER_ENTRY, expected=7)\n",
    "\n",
    "nltk.download(\"punkt\")\n",
    "number_of_entries = 0\n",
    "valid_entries = []\n",
    "\n",
    "with gzip.open(pretraining_set_path / \"all.txt.gz\", \"rt\") as all_txt:\n",
    "    for entry in all_txt:\n",
    "        entry = entry.strip() # Sanitize\n",
    "        words = nltk.word_tokenize(entry, language=\"fr\", preserve_line=True)\n",
    "        if len(words) >= MIN_WORDS_PER_ENTRY:\n",
    "            valid_entries.append(entry)\n",
    "        number_of_entries += 1\n",
    "        \n",
    "with open(\"/tmp/pretraining_data.txt\", \"w\") as wfp:\n",
    "    wfp.write(\"\\n\".join(valid_entries))\n",
    "\n",
    "print(len(valid_entries))\n",
    "print(\"Valid entries:%d, %f.2 percent of the total\" % (len(valid_entries),len(valid_entries) / number_of_entries))\n",
    "assert_expected(actual=845014, expected=len(valid_entries))\n",
    "assert_expected(actual=1045674, expected=number_of_entries)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5e9321-957b-4dbe-867c-437cadcc8c2e",
   "metadata": {},
   "source": [
    "## 12 - Pretraining CamemBERT on pretraining_data.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1be1e366-78cc-4a3d-b62d-28c07dd63732",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "05/18/2022 16:05:46 - WARNING - __main__ - Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\n",
      "05/18/2022 16:05:46 - INFO - __main__ - Training/evaluation parameters TrainingArguments(\n",
      "_n_gpu=1,\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "auto_find_batch_size=False,\n",
      "bf16=False,\n",
      "bf16_full_eval=False,\n",
      "data_seed=None,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=0,\n",
      "dataloader_pin_memory=True,\n",
      "ddp_bucket_cap_mb=None,\n",
      "ddp_find_unused_parameters=None,\n",
      "debug=[],\n",
      "deepspeed=None,\n",
      "disable_tqdm=False,\n",
      "do_eval=True,\n",
      "do_predict=False,\n",
      "do_train=True,\n",
      "eval_accumulation_steps=None,\n",
      "eval_delay=0,\n",
      "eval_steps=500,\n",
      "evaluation_strategy=IntervalStrategy.STEPS,\n",
      "fp16=False,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "fsdp=[],\n",
      "fsdp_min_num_params=0,\n",
      "full_determinism=False,\n",
      "gradient_accumulation_steps=1,\n",
      "gradient_checkpointing=False,\n",
      "greater_is_better=False,\n",
      "group_by_length=False,\n",
      "half_precision_backend=auto,\n",
      "hub_model_id=None,\n",
      "hub_private_repo=False,\n",
      "hub_strategy=HubStrategy.EVERY_SAVE,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "include_inputs_for_metrics=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=5e-05,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=True,\n",
      "local_rank=-1,\n",
      "log_level=-1,\n",
      "log_level_replica=-1,\n",
      "log_on_each_node=True,\n",
      "logging_dir=$/home/bertrand/paper-ner-bench-das22/10-camembert_pretrained_model/runs/May18_16-05-46_anubis,\n",
      "logging_first_step=False,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=500,\n",
      "logging_strategy=IntervalStrategy.STEPS,\n",
      "lr_scheduler_type=SchedulerType.LINEAR,\n",
      "max_grad_norm=1.0,\n",
      "max_steps=-1,\n",
      "metric_for_best_model=loss,\n",
      "mp_parameters=,\n",
      "no_cuda=False,\n",
      "num_train_epochs=3.0,\n",
      "optim=OptimizerNames.ADAMW_HF,\n",
      "output_dir=$/home/bertrand/paper-ner-bench-das22/10-camembert_pretrained_model,\n",
      "overwrite_output_dir=False,\n",
      "past_index=-1,\n",
      "per_device_eval_batch_size=8,\n",
      "per_device_train_batch_size=8,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "remove_unused_columns=True,\n",
      "report_to=[],\n",
      "resume_from_checkpoint=None,\n",
      "run_name=$/home/bertrand/paper-ner-bench-das22/10-camembert_pretrained_model,\n",
      "save_on_each_node=False,\n",
      "save_steps=500,\n",
      "save_strategy=IntervalStrategy.STEPS,\n",
      "save_total_limit=1,\n",
      "seed=42,\n",
      "sharded_ddp=[],\n",
      "skip_memory_metrics=True,\n",
      "tf32=None,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_legacy_prediction_loop=False,\n",
      "warmup_ratio=0.0,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.0,\n",
      "xpu_backend=None,\n",
      ")\n",
      "05/18/2022 16:05:47 - WARNING - datasets.builder - Using custom data configuration default-df1722206e26b064\n",
      "05/18/2022 16:05:48 - INFO - datasets.builder - Generating dataset text (/home/bertrand/.cache/huggingface/datasets/text/default-df1722206e26b064/0.0.0/4b86d314f7236db91f0a0f5cda32d4375445e64c5eda2692655dd99c2dac68e8)\n",
      "Downloading and preparing dataset text/default to /home/bertrand/.cache/huggingface/datasets/text/default-df1722206e26b064/0.0.0/4b86d314f7236db91f0a0f5cda32d4375445e64c5eda2692655dd99c2dac68e8...\n",
      "Downloading data files: 100%|███████████████████| 1/1 [00:00<00:00, 2235.77it/s]\n",
      "05/18/2022 16:05:48 - INFO - datasets.utils.download_manager - Downloading took 0.0 min\n",
      "05/18/2022 16:05:48 - INFO - datasets.utils.download_manager - Checksum Computation took 0.0 min\n",
      "Extracting data files: 100%|████████████████████| 1/1 [00:00<00:00, 2103.46it/s]\n",
      "05/18/2022 16:05:48 - INFO - datasets.utils.info_utils - Unable to verify checksums.\n",
      "05/18/2022 16:05:48 - INFO - datasets.builder - Generating train split\n",
      "05/18/2022 16:05:49 - INFO - datasets.utils.info_utils - Unable to verify splits sizes.\n",
      "Dataset text downloaded and prepared to /home/bertrand/.cache/huggingface/datasets/text/default-df1722206e26b064/0.0.0/4b86d314f7236db91f0a0f5cda32d4375445e64c5eda2692655dd99c2dac68e8. Subsequent calls will reuse this data.\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 48.05it/s]\n",
      "05/18/2022 16:05:49 - WARNING - datasets.builder - Using custom data configuration default-df1722206e26b064\n",
      "05/18/2022 16:05:49 - INFO - datasets.builder - Overwrite dataset info from restored data version.\n",
      "05/18/2022 16:05:49 - INFO - datasets.info - Loading Dataset info from /home/bertrand/.cache/huggingface/datasets/text/default-df1722206e26b064/0.0.0/4b86d314f7236db91f0a0f5cda32d4375445e64c5eda2692655dd99c2dac68e8\n",
      "05/18/2022 16:05:49 - WARNING - datasets.builder - Reusing dataset text (/home/bertrand/.cache/huggingface/datasets/text/default-df1722206e26b064/0.0.0/4b86d314f7236db91f0a0f5cda32d4375445e64c5eda2692655dd99c2dac68e8)\n",
      "05/18/2022 16:05:49 - INFO - datasets.info - Loading Dataset info from /home/bertrand/.cache/huggingface/datasets/text/default-df1722206e26b064/0.0.0/4b86d314f7236db91f0a0f5cda32d4375445e64c5eda2692655dd99c2dac68e8\n",
      "05/18/2022 16:05:50 - WARNING - datasets.builder - Using custom data configuration default-df1722206e26b064\n",
      "05/18/2022 16:05:50 - INFO - datasets.builder - Overwrite dataset info from restored data version.\n",
      "05/18/2022 16:05:50 - INFO - datasets.info - Loading Dataset info from /home/bertrand/.cache/huggingface/datasets/text/default-df1722206e26b064/0.0.0/4b86d314f7236db91f0a0f5cda32d4375445e64c5eda2692655dd99c2dac68e8\n",
      "05/18/2022 16:05:50 - WARNING - datasets.builder - Reusing dataset text (/home/bertrand/.cache/huggingface/datasets/text/default-df1722206e26b064/0.0.0/4b86d314f7236db91f0a0f5cda32d4375445e64c5eda2692655dd99c2dac68e8)\n",
      "05/18/2022 16:05:50 - INFO - datasets.info - Loading Dataset info from /home/bertrand/.cache/huggingface/datasets/text/default-df1722206e26b064/0.0.0/4b86d314f7236db91f0a0f5cda32d4375445e64c5eda2692655dd99c2dac68e8\n",
      "[INFO|configuration_utils.py:659] 2022-05-18 16:05:50,534 >> loading configuration file https://huggingface.co/Jean-Baptiste/camembert-ner/resolve/main/config.json from cache at /home/bertrand/.cache/huggingface/transformers/0ca0fa98897ddf36d30f9a4f597bc247f48b49acee6ada696ef37f71ad0c7183.72890737d36e24d44eee8889cd355932b6b45361a99f9a231076186f3562e80b\n",
      "[INFO|configuration_utils.py:708] 2022-05-18 16:05:50,536 >> Model config CamembertConfig {\n",
      "  \"_name_or_path\": \"Jean-Baptiste/camembert-ner\",\n",
      "  \"architectures\": [\n",
      "    \"CamembertForTokenClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 5,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 6,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"O\",\n",
      "    \"1\": \"I-LOC\",\n",
      "    \"2\": \"I-PER\",\n",
      "    \"3\": \"I-MISC\",\n",
      "    \"4\": \"I-ORG\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"I-LOC\": 1,\n",
      "    \"I-MISC\": 3,\n",
      "    \"I-ORG\": 4,\n",
      "    \"I-PER\": 2,\n",
      "    \"O\": 0\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"camembert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.19.2\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32005\n",
      "}\n",
      "\n",
      "[INFO|configuration_utils.py:659] 2022-05-18 16:05:51,257 >> loading configuration file https://huggingface.co/Jean-Baptiste/camembert-ner/resolve/main/config.json from cache at /home/bertrand/.cache/huggingface/transformers/0ca0fa98897ddf36d30f9a4f597bc247f48b49acee6ada696ef37f71ad0c7183.72890737d36e24d44eee8889cd355932b6b45361a99f9a231076186f3562e80b\n",
      "[INFO|configuration_utils.py:708] 2022-05-18 16:05:51,259 >> Model config CamembertConfig {\n",
      "  \"_name_or_path\": \"Jean-Baptiste/camembert-ner\",\n",
      "  \"architectures\": [\n",
      "    \"CamembertForTokenClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 5,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 6,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"O\",\n",
      "    \"1\": \"I-LOC\",\n",
      "    \"2\": \"I-PER\",\n",
      "    \"3\": \"I-MISC\",\n",
      "    \"4\": \"I-ORG\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"I-LOC\": 1,\n",
      "    \"I-MISC\": 3,\n",
      "    \"I-ORG\": 4,\n",
      "    \"I-PER\": 2,\n",
      "    \"O\": 0\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"camembert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.19.2\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32005\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:1782] 2022-05-18 16:05:54,086 >> loading file https://huggingface.co/Jean-Baptiste/camembert-ner/resolve/main/sentencepiece.bpe.model from cache at /home/bertrand/.cache/huggingface/transformers/22d115f43e0f0f7c76775875f4882c6edf818acd82eec9c24f88c68364b61594.1092b49637a91e74723b3bca56ef1baa3b70e86dd2e54222c53f6e1e5a310676\n",
      "[INFO|tokenization_utils_base.py:1782] 2022-05-18 16:05:54,087 >> loading file https://huggingface.co/Jean-Baptiste/camembert-ner/resolve/main/tokenizer.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:1782] 2022-05-18 16:05:54,087 >> loading file https://huggingface.co/Jean-Baptiste/camembert-ner/resolve/main/added_tokens.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:1782] 2022-05-18 16:05:54,087 >> loading file https://huggingface.co/Jean-Baptiste/camembert-ner/resolve/main/special_tokens_map.json from cache at /home/bertrand/.cache/huggingface/transformers/fe0e213c44079a9ee091098f81fff2941484006e9ba3001a9bf1ee9f87537599.cb3ec3a6c1200d181228d8825ae9767572abca54efa1bbb37fd83d721b2ef323\n",
      "[INFO|tokenization_utils_base.py:1782] 2022-05-18 16:05:54,087 >> loading file https://huggingface.co/Jean-Baptiste/camembert-ner/resolve/main/tokenizer_config.json from cache at /home/bertrand/.cache/huggingface/transformers/698cd84321395889697c8edd4faa9b4a65ddf410a9825c8a4b046cb94c2c220d.1f67f456146012f1824eb9498c5438252647f9c4a05d37e8cb1de960505fbff9\n",
      "[INFO|configuration_utils.py:659] 2022-05-18 16:05:54,426 >> loading configuration file https://huggingface.co/Jean-Baptiste/camembert-ner/resolve/main/config.json from cache at /home/bertrand/.cache/huggingface/transformers/0ca0fa98897ddf36d30f9a4f597bc247f48b49acee6ada696ef37f71ad0c7183.72890737d36e24d44eee8889cd355932b6b45361a99f9a231076186f3562e80b\n",
      "[INFO|configuration_utils.py:708] 2022-05-18 16:05:54,429 >> Model config CamembertConfig {\n",
      "  \"_name_or_path\": \"Jean-Baptiste/camembert-ner\",\n",
      "  \"architectures\": [\n",
      "    \"CamembertForTokenClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 5,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 6,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"O\",\n",
      "    \"1\": \"I-LOC\",\n",
      "    \"2\": \"I-PER\",\n",
      "    \"3\": \"I-MISC\",\n",
      "    \"4\": \"I-ORG\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"I-LOC\": 1,\n",
      "    \"I-MISC\": 3,\n",
      "    \"I-ORG\": 4,\n",
      "    \"I-PER\": 2,\n",
      "    \"O\": 0\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"camembert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.19.2\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32005\n",
      "}\n",
      "\n",
      "[INFO|configuration_utils.py:659] 2022-05-18 16:05:55,067 >> loading configuration file https://huggingface.co/Jean-Baptiste/camembert-ner/resolve/main/config.json from cache at /home/bertrand/.cache/huggingface/transformers/0ca0fa98897ddf36d30f9a4f597bc247f48b49acee6ada696ef37f71ad0c7183.72890737d36e24d44eee8889cd355932b6b45361a99f9a231076186f3562e80b\n",
      "[INFO|configuration_utils.py:708] 2022-05-18 16:05:55,069 >> Model config CamembertConfig {\n",
      "  \"_name_or_path\": \"Jean-Baptiste/camembert-ner\",\n",
      "  \"architectures\": [\n",
      "    \"CamembertForTokenClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 5,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 6,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"O\",\n",
      "    \"1\": \"I-LOC\",\n",
      "    \"2\": \"I-PER\",\n",
      "    \"3\": \"I-MISC\",\n",
      "    \"4\": \"I-ORG\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"I-LOC\": 1,\n",
      "    \"I-MISC\": 3,\n",
      "    \"I-ORG\": 4,\n",
      "    \"I-PER\": 2,\n",
      "    \"O\": 0\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"camembert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.19.2\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32005\n",
      "}\n",
      "\n",
      "[INFO|hub.py:583] 2022-05-18 16:05:57,046 >> https://huggingface.co/Jean-Baptiste/camembert-ner/resolve/main/pytorch_model.bin not found in cache or force_download set to True, downloading to /home/bertrand/.cache/huggingface/transformers/tmpv0dsj_45\n",
      "Downloading: 100%|███████████████████████████| 420M/420M [00:04<00:00, 97.5MB/s]\n",
      "[INFO|hub.py:587] 2022-05-18 16:06:01,638 >> storing https://huggingface.co/Jean-Baptiste/camembert-ner/resolve/main/pytorch_model.bin in cache at /home/bertrand/.cache/huggingface/transformers/a0f287c684a81b3f5603d8c73a8303a2a554446a51e28b08e5715f301f4012e1.9ea323d73321b5d2aea778b0154b8beb9d4d48ac674ec068ec5dbb931efcd859\n",
      "[INFO|hub.py:595] 2022-05-18 16:06:01,638 >> creating metadata file for /home/bertrand/.cache/huggingface/transformers/a0f287c684a81b3f5603d8c73a8303a2a554446a51e28b08e5715f301f4012e1.9ea323d73321b5d2aea778b0154b8beb9d4d48ac674ec068ec5dbb931efcd859\n",
      "[INFO|modeling_utils.py:1953] 2022-05-18 16:06:01,638 >> loading weights file https://huggingface.co/Jean-Baptiste/camembert-ner/resolve/main/pytorch_model.bin from cache at /home/bertrand/.cache/huggingface/transformers/a0f287c684a81b3f5603d8c73a8303a2a554446a51e28b08e5715f301f4012e1.9ea323d73321b5d2aea778b0154b8beb9d4d48ac674ec068ec5dbb931efcd859\n",
      "[WARNING|modeling_utils.py:2254] 2022-05-18 16:06:02,820 >> Some weights of the model checkpoint at Jean-Baptiste/camembert-ner were not used when initializing CamembertForMaskedLM: ['classifier.bias', 'classifier.weight']\n",
      "- This IS expected if you are initializing CamembertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing CamembertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "[WARNING|modeling_utils.py:2265] 2022-05-18 16:06:02,821 >> Some weights of CamembertForMaskedLM were not initialized from the model checkpoint at Jean-Baptiste/camembert-ner and are newly initialized: ['lm_head.dense.bias', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Running tokenizer on dataset line_by_line:   0%|        | 0/803 [00:00<?, ?ba/s]05/18/2022 16:06:03 - INFO - datasets.arrow_dataset - Caching processed dataset at /home/bertrand/.cache/huggingface/datasets/text/default-df1722206e26b064/0.0.0/4b86d314f7236db91f0a0f5cda32d4375445e64c5eda2692655dd99c2dac68e8/cache-4dbd4912efad0a67.arrow\n",
      "Running tokenizer on dataset line_by_line:  86%|▊| 691/803 [00:15<00:02, 47.18ba"
     ]
    }
   ],
   "source": [
    "!python pretrain_camembert.py --model_name_or_path \"Jean-Baptiste/camembert-ner\" --train_file \"/tmp/pretraining_data.txt\" --do_train --do_eval --line_by_line --output_dir \"${config.BASEDIR}/10-camembert_pretrained_model\" --save_total_limit 1 --load_best_model_at_end True --evaluation_strategy \"steps\" --save_strategy \"steps\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('ner')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "c57d6dc83202ed16477ed01fbeb8d45268fb6711c5da666dad291c245339c394"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
