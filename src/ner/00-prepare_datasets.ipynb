{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06fb22ae-ac08-4170-932f-0bdaeea1e536",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 00 - Datasets generation\n",
    "\n",
    "This notebook expects the gold datasets to be available in CSV in paper-ner-bench-das22/dataset.\n",
    "Set the environment variable `DATASET_DIR` to change this path.\n",
    "\n",
    "Outputs:\n",
    "- In `./experiment_1`: train, dev & test datasets for each size of training sets for experiment 1\n",
    "- In `./experiment_2`: train, dev & test datasets for clean & noisy OCR data (Pero-OCR, Tesseract) for experiment 2 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d3ab2a8-d126-4a36-87c1-5bd934a2f5c4",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 01. Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16874c6b-e422-4e07-b31c-856841a71300",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# GLOBAL CONSTANTS\n",
    "import config\n",
    "\n",
    "config.SPLIT_SEED = 42 # Random seed used in train/dev/test. Do not change it if you want to recreate the paper results.\n",
    "config.DEBUG = True # Enable debug features ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b97df95d-88c5-4978-a452-fdcfbde37a94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(PosixPath('/home/bertrand/dev/paper-ner-bench-das22/dataset'),\n",
       " PosixPath('/home/bertrand/dev/paper-ner-bench-das22/src/ner'))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# INPUT / OUTPUT DIRECTORIES\n",
    "WORK_DIR = Path(os.path.dirname(os.path.realpath(\"__file__\")))\n",
    "DATASET_DIR_DEFAULT = (WORK_DIR / \"../../dataset\").resolve()\n",
    "DATASET_DIR = Path(os.getenv(\"DATASET_DIR\", DATASET_DIR_DEFAULT))\n",
    "\n",
    "assert DATASET_DIR.exists()\n",
    "DATASET_DIR, WORK_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6183eae7-b77e-4d3b-b7a3-a734751ab18e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['<PER>Dufan et Clémendot</PER>, <ACT>pharmaciens</ACT>, <LOC>r. de la\\u2029Chaussée-d&apos;Antin</LOC>, <CARDINAL>34</CARDINAL>. <TITRE>(Elig.)</TITRE> 449',\n",
       "        ' \"Bottin1_1820\"'],\n",
       "       ['<PER>Dufant (Victor)</PER>, <ACT>libraire</ACT>, <LOC>r. du Gros-Che-\\u2029net</LOC>, <CARDINAL>2</CARDINAL>. 392',\n",
       "        ' \"Bottin1_1820\"'],\n",
       "       ['<PER>Dufay</PER>, <ACT>essayeur du commerce</ACT>, <LOC>place Dau-\\u2029phine</LOC>, <CARDINAL>5</CARDINAL>.         355',\n",
       "        ' \"Bottin1_1820\"'],\n",
       "       ...,\n",
       "       ['<PER>Lamare</PER>, <ACT>notaire</ACT>, <LOC>rue du faubourg honoré</LOC>.',\n",
       "        ' \"notables_communaux_seine_1801\"'],\n",
       "       ['<PER>Lamarre</PER> , <ACT>carrier</ACT>, <LOC>rue mouffetard</LOC>.',\n",
       "        ' \"notables_communaux_seine_1801\"'],\n",
       "       ['<PER>Lamarre</PER>, <ACT>clerc de notaire</ACT>, <LOC>rue égalité</LOC>.',\n",
       "        ' \"notables_communaux_seine_1801\"']], dtype='<U855')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "# Load the Reference, pero-OCR and Tesseract gold datasets\n",
    "GOLD_REF = DATASET_DIR / \"supervised/10-ref-ocr-ner-json/gold.csv\"\n",
    "GOLD_PERO = DATASET_DIR / \"\" #TODO \n",
    "GOLD_TESS = DATASET_DIR / \"\" #TODO\n",
    "\n",
    "with open(GOLD_REF, encoding=\"utf-8\") as gf:\n",
    "    gold_reference = np.array([(_[0], _[1]) for _ in csv.reader(gf)])\n",
    "\n",
    "assert len(gold_reference)\n",
    "gold_reference\n",
    "\n",
    "#TODO: PERO + TESS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71010115-8bac-43d9-9638-15f56f029493",
   "metadata": {},
   "source": [
    "# 02. Experiment #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "343557ea-5ea3-4df0-86c3-efe69112c8d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/bertrand/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[6373, 3186, 1593, 796, 398, 199, 99, 49]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dataset_util import train_dev_test_split, unwrap # Local imports\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# CONSTANTS\n",
    "MIN_TRAINSET_SIZE = 30\n",
    "\n",
    " # Split 72/8/20% w. stratified sampling on directories names\n",
    "train, dev, test = train_dev_test_split(gold_reference)\n",
    "\n",
    "# Iteratively split the trainset in half to create smaller trainsets\n",
    "exp1_trainsets = [train]\n",
    "t_len = len(train)\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        current = exp1_trainsets[-1]\n",
    "        _, groups = unwrap(current)\n",
    "        smaller, rest = train_test_split(\n",
    "            current,\n",
    "            train_size=0.5,\n",
    "            shuffle=True,\n",
    "            random_state=config.SPLIT_SEED,\n",
    "            stratify=groups,\n",
    "        )\n",
    "        t_len = len(rest)\n",
    "        if t_len < MIN_TRAINSET_SIZE:\n",
    "            break\n",
    "        exp1_trainsets.append(smaller)\n",
    "\n",
    "    except ValueError:\n",
    "        # Stop now if we encounter the error \"The least populated class in y has only 1 member\".\n",
    "        break\n",
    "\n",
    "[len(s) for s in exp1_trainsets] # Should be \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9f4fd33-72da-4eb8-bec2-c90aa3798c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity checks\n",
    "\n",
    "# Dev set should contain 709 examples\n",
    "assert len(dev) == 709\n",
    "\n",
    "# Test set should contain 1690 examples\n",
    "assert len(test) == 1690\n",
    "\n",
    "# Lenghts of exp1_trainsets should be fixed\n",
    "assert sorted([len(s) for s in exp1_trainsets] ) == sorted([6373, 3186, 1593, 796, 398, 199, 99, 49])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd88d23-c062-4772-b53f-610927523397",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1e79e483c924bb19c758021397502fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0070492287b406d9a280f1bb7d81d9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c27828ce875042dd9ea7b6b0a7271654",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9365937c152c47239eb3fff83951b228",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76570808c1f9444fb073af78b3540c97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f02bb139083040bfa15afa170790349d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09f556de7e1d419f8fa6dab02b23b4e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93fc87d3bb6f45d1a87425c7a41d0308",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d64d0f1967c46f78a80ca8483893ca7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84211ec9f117413f85431daceb49d39a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c7a254568da403c9898028b28a925e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fc6645eb80f4290b36d572f0df008f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "267d1a0f6205471280a56fd81a93cf4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a470c8fdb23242dc89f8b06ab76ffb03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Save on disk\n",
    "from dataset_util import save_dataset # Local import\n",
    "\n",
    "output_directory = WORK_DIR / \"20-experiment_1\"\n",
    "output_directory.mkdir(exist_ok=True) # Create if necessary\n",
    "   \n",
    "for train in exp1_trainsets:\n",
    "    datasets = [train, dev, test]\n",
    "    save_dataset(output_directory, datasets, [\"train\",\"dev\",\"test\"], suffix=len(train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e623237-eb40-4bef-80d2-7a21a334023f",
   "metadata": {},
   "source": [
    "# 03. Experiment #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797dd5c1-65c6-4b41-abcc-7e3f210948ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset_util import train_dev_test_split # Local imports\n",
    "\n",
    "# Reference gold (manually annotated & corrected examples): Split 72/8/20% w. stratified sampling on directories names\n",
    "train_ref, dev_ref, test_ref = train_dev_test_split(gold_reference)\n",
    "\n",
    "# Pero-OCR gold: split 72/8/20% w. stratified sampling on directories names\n",
    "train_pero, dev_pero, test_pero = train_dev_test_split(gold_reference)\n",
    "\n",
    "# Tesseract gold: split 72/8/20% w. stratified sampling on directories names\n",
    "train_tess, dev_tess, test_tess = train_dev_test_split(gold_reference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16dfa485-5b32-40c6-9b60-3f7242b53a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity checks: all train (resp. dev, test) sets must be the exact same size.\n",
    "\n",
    "assert len(train_ref) == len(train_pero) and len(train_ref) == len(train_tess)\n",
    "\n",
    "assert len(dev_ref) == len(dev_pero) and len(dev_ref) == len(dev_tess)\n",
    "\n",
    "assert len(test_ref) == len(test_pero) and len(test_ref) == len(test_tess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a341959-728c-4bd0-9c33-c067c4b69bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save on disk\n",
    "from dataset_util import save_dataset # Local import\n",
    "\n",
    "output_directory = WORK_DIR / \"experiment_2\"\n",
    "output_directory.mkdir(exist_ok=True) # Create if necessary\n",
    "\n",
    "names = [\"train\", \"dev\", \"test\"]\n",
    "save_dataset(output_directory, [train_ref, dev_ref, test_ref], names, suffix=\"ref\")\n",
    "save_dataset(output_directory, [train_pero, dev_pero, test_pero], names, suffix=\"pero\")\n",
    "save_dataset(output_directory, [train_tess, dev_tess, test_tess], names, suffix=\"tess\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
