{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8189029c-0b96-45a0-8d89-6c49ffdda9b4",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 00 - Datasets generation\n",
    "\n",
    "Prepares all train, dev and test sets for Spacy and the tranformers models for both NER experiments (section 5 and 6).\n",
    "This notebook should be executed first and foremost.\n",
    "\n",
    "The sets will be saved ont the disk:\n",
    "- In `01-experiment_1_prepared_datasets`: train, dev & test datasets for each size of training sets for experiment 1\n",
    "- In `02-experiment_2_prepared_datasets`: train, dev & test datasets for clean & noisy OCR data (Pero-OCR, Tesseract) for experiment 2 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da77ed69-9fa6-4462-9b1b-00ecb3f17392",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Initialisation\n",
    "The initialisation step:\n",
    "- sets the random seed SPLIT_SEED to use in all training set generation to ensure repeatable results\n",
    "- creates logger named nerlogger\n",
    "- defines the paths to the directories used by the NER notebooks\n",
    "- imports all the modules used in this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "479d255e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18/05/2022 02:39:22 ; INFO ; ======= CONFIGURATION =======\n",
      "18/05/2022 02:39:22 ; INFO ; BASEDIR: /home/bertrand/paper-ner-bench-das22\n",
      "18/05/2022 02:39:22 ; INFO ; Input datasets will be loaded from DATASETDIR /home/bertrand/paper-ner-bench-das22/dataset\n",
      "18/05/2022 02:39:22 ; INFO ; Training data and models will be saved to NERDIR /home/bertrand/paper-ner-bench-das22/src/ner\n",
      "18/05/2022 02:39:22 ; INFO ; Debug mode is ON\n",
      "18/05/2022 02:39:22 ; INFO ; Random seed: 42\n",
      "18/05/2022 02:39:22 ; INFO ; Enable reproducibility checks: True\n",
      "18/05/2022 02:39:22 ; INFO ; ============================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: DEBUG=1\n",
      "env: AS_IN_THE_PAPER=True\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Loads the configuration \"\"\"\n",
    "\n",
    "# Set to 1/true/ to set the logging level of nerlogger to DEBUG \n",
    "# and save the the spacy datasets as TXT along with the .spacy file\n",
    "#  for easier debug of the training set generation.\n",
    "%env DEBUG=1\n",
    "\n",
    "# If True, activates a set of assertions in the notebooks to ensure\n",
    "# that the scripts runs with the parameters used in the paper.\n",
    "%env AS_IN_THE_PAPER = True\n",
    "\n",
    "import util.config as config\n",
    "\n",
    "config.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ad26425",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bertrand/anaconda3/envs/ner/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[nltk_data] Downloading package punkt to /home/bertrand/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Import all modules at once \"\"\"\n",
    "\n",
    "# General imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "# NER imports\n",
    "from util.dataset_util import train_dev_test_split, unwrap, save_dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from util.as_in_the_paper import assert_expected\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71010115-8bac-43d9-9638-15f56f029493",
   "metadata": {},
   "source": [
    "# 01. Experiment #1\n",
    "\n",
    "Generates the training, development and test sets for the Spacy and transformers models as described in the subsection #5 \"Training and evaluation protocol\" of the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "de597797-0541-404e-b721-8667077eb7f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ner_xml</th>\n",
       "      <th>book</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;PER&gt;Dufan et Clémendot&lt;/PER&gt;, &lt;ACT&gt;pharmacien...</td>\n",
       "      <td>Bottin1_1820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;PER&gt;Dufant (Victor)&lt;/PER&gt;, &lt;ACT&gt;libraire&lt;/ACT...</td>\n",
       "      <td>Bottin1_1820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;PER&gt;Dufay&lt;/PER&gt;, &lt;ACT&gt;essayeur du commerce&lt;/A...</td>\n",
       "      <td>Bottin1_1820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;PER&gt;Dulay&lt;/PER&gt;, &lt;ACT&gt;chandronnier&lt;/ACT&gt;, &lt;LO...</td>\n",
       "      <td>Bottin1_1820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;PER&gt;Dufay (V.e)&lt;/PER&gt;, &lt;ACT&gt;grenetière&lt;/ACT&gt;,...</td>\n",
       "      <td>Bottin1_1820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8767</th>\n",
       "      <td>&lt;PER&gt;Lamarche&lt;/PER&gt;, &lt;ACT&gt;géographe&lt;/ACT&gt; , &lt;L...</td>\n",
       "      <td>Notables_communaux_seine_1801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8768</th>\n",
       "      <td>&lt;PER&gt;Lamarck&lt;/PER&gt;, &lt;ACT&gt;membre de l&amp;apos;inst...</td>\n",
       "      <td>Notables_communaux_seine_1801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8769</th>\n",
       "      <td>&lt;PER&gt;Lamare&lt;/PER&gt;, &lt;ACT&gt;notaire&lt;/ACT&gt;, &lt;LOC&gt;ru...</td>\n",
       "      <td>Notables_communaux_seine_1801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8770</th>\n",
       "      <td>&lt;PER&gt;Lamarre&lt;/PER&gt; , &lt;ACT&gt;carrier&lt;/ACT&gt;, &lt;LOC&gt;...</td>\n",
       "      <td>Notables_communaux_seine_1801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8771</th>\n",
       "      <td>&lt;PER&gt;Lamarre&lt;/PER&gt;, &lt;ACT&gt;clerc de notaire&lt;/ACT...</td>\n",
       "      <td>Notables_communaux_seine_1801</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8772 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                ner_xml  \\\n",
       "0     <PER>Dufan et Clémendot</PER>, <ACT>pharmacien...   \n",
       "1     <PER>Dufant (Victor)</PER>, <ACT>libraire</ACT...   \n",
       "2     <PER>Dufay</PER>, <ACT>essayeur du commerce</A...   \n",
       "3     <PER>Dulay</PER>, <ACT>chandronnier</ACT>, <LO...   \n",
       "4     <PER>Dufay (V.e)</PER>, <ACT>grenetière</ACT>,...   \n",
       "...                                                 ...   \n",
       "8767  <PER>Lamarche</PER>, <ACT>géographe</ACT> , <L...   \n",
       "8768  <PER>Lamarck</PER>, <ACT>membre de l&apos;inst...   \n",
       "8769  <PER>Lamare</PER>, <ACT>notaire</ACT>, <LOC>ru...   \n",
       "8770  <PER>Lamarre</PER> , <ACT>carrier</ACT>, <LOC>...   \n",
       "8771  <PER>Lamarre</PER>, <ACT>clerc de notaire</ACT...   \n",
       "\n",
       "                               book  \n",
       "0                      Bottin1_1820  \n",
       "1                      Bottin1_1820  \n",
       "2                      Bottin1_1820  \n",
       "3                      Bottin1_1820  \n",
       "4                      Bottin1_1820  \n",
       "...                             ...  \n",
       "8767  Notables_communaux_seine_1801  \n",
       "8768  Notables_communaux_seine_1801  \n",
       "8769  Notables_communaux_seine_1801  \n",
       "8770  Notables_communaux_seine_1801  \n",
       "8771  Notables_communaux_seine_1801  \n",
       "\n",
       "[8772 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Loads the input dataset from DATASETDIR. \"\"\"\n",
    "\n",
    "GOLD_REFERENCE_PATH = config.DATASETDIR / \"supervised/10-ref-ocr-ner-json/gold.csv\"\n",
    "\n",
    "assert GOLD_REFERENCE_PATH.exists()\n",
    "\n",
    "gold_reference = pd.read_csv(GOLD_REFERENCE_PATH, \n",
    "                             header=None,\n",
    "                             names=[\"ner_xml\", \"book\"],\n",
    "                             skipinitialspace='True')\n",
    "\n",
    "assert_expected(len(gold_reference), 8772)\n",
    "\n",
    "gold_reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee5bdd42-8847-48e5-833f-8cbb8106e172",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18/05/2022 02:40:48 ; DEBUG ; Experiment #1 trainsets sizes: [6373, 3186, 1593, 796, 398, 199, 99, 49]\n",
      "18/05/2022 02:40:48 ; DEBUG ; Experiment #1 dev set size: 709\n",
      "18/05/2022 02:40:48 ; DEBUG ; Experiment #1 test set size: 1690\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Actually generates the sets. \"\"\"\n",
    "\n",
    "# Do not create training sets smaller than this.\n",
    "# You can adjust this value to your convenance but the training processes might\n",
    "# complain.\n",
    "# Do not change it if you want to reproduce the results from the article.\n",
    "MIN_TRAINSET_SIZE = 30\n",
    "\n",
    "# Split 72/8/20% w. stratified sampling on directories names\n",
    "train, dev, test = train_dev_test_split(gold_reference.to_numpy())\n",
    "\n",
    "# Iteratively split the trainset in half to create smaller trainsets\n",
    "exp1_trainsets = [train]\n",
    "t_len = len(train)\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        current = exp1_trainsets[-1]\n",
    "        _, groups = unwrap(current)\n",
    "        smaller, rest = train_test_split(\n",
    "            current,\n",
    "            train_size=0.5,\n",
    "            shuffle=True,\n",
    "            random_state=config.SPLIT_SEED,\n",
    "            stratify=groups,\n",
    "        )\n",
    "        t_len = len(rest)\n",
    "        if t_len < MIN_TRAINSET_SIZE:\n",
    "            break\n",
    "        exp1_trainsets.append(smaller)\n",
    "\n",
    "    except ValueError:\n",
    "        # Stop now if we encounter the error \"The least populated class in y has only 1 member\".\n",
    "        break\n",
    "\n",
    "\n",
    "trainset_sizes = [len(s) for s in exp1_trainsets]\n",
    "\n",
    "config.logger.debug(f\"Experiment #1 trainsets sizes: {trainset_sizes}\")\n",
    "config.logger.debug(f\"Experiment #1 dev set size: {len(dev)}\")\n",
    "config.logger.debug(f\"Experiment #1 test set size: {len(test)}\")\n",
    "\n",
    "# \"AS IN PAPER\" checks. Apply only if config.AS_IN_THE_PAPER is true\n",
    "# - number of samples in the full trainset\n",
    "assert_expected(6373, len(train))\n",
    "\n",
    "# - number of samples in the subsets of the trainset set\n",
    "actual = \"[6373, 3186, 1593, 796, 398, 199, 99, 49]\"\n",
    "expected = str(trainset_sizes)\n",
    "assert_expected(actual, expected)\n",
    "\n",
    "# - number of samples in the dev set\n",
    "assert_expected(709, len(dev))\n",
    "\n",
    "# - number of samples in the test set\n",
    "assert_expected(1690, len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bcd88d23-c062-4772-b53f-610927523397",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18/05/2022 02:40:56 ; INFO ; Saving dataset with training set of size 6373 to /home/bertrand/paper-ner-bench-das22/src/ner/01-experiment_1_prepared_datasets\n",
      "100%|██████████| 7/7 [00:00<00:00, 25.82ba/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 30.17ba/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 27.81ba/s]\n",
      "18/05/2022 02:41:04 ; INFO ; Saving dataset with training set of size 3186 to /home/bertrand/paper-ner-bench-das22/src/ner/01-experiment_1_prepared_datasets\n",
      "100%|██████████| 4/4 [00:00<00:00, 28.88ba/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 31.75ba/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 26.41ba/s]\n",
      "18/05/2022 02:41:08 ; INFO ; Saving dataset with training set of size 1593 to /home/bertrand/paper-ner-bench-das22/src/ner/01-experiment_1_prepared_datasets\n",
      "100%|██████████| 2/2 [00:00<00:00, 29.69ba/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 33.01ba/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 26.94ba/s]\n",
      "18/05/2022 02:41:11 ; INFO ; Saving dataset with training set of size 796 to /home/bertrand/paper-ner-bench-das22/src/ner/01-experiment_1_prepared_datasets\n",
      "100%|██████████| 1/1 [00:00<00:00, 28.83ba/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 32.01ba/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 27.40ba/s]\n",
      "18/05/2022 02:41:14 ; INFO ; Saving dataset with training set of size 398 to /home/bertrand/paper-ner-bench-das22/src/ner/01-experiment_1_prepared_datasets\n",
      "100%|██████████| 1/1 [00:00<00:00,  8.82ba/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 29.41ba/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 27.51ba/s]\n",
      "18/05/2022 02:41:16 ; INFO ; Saving dataset with training set of size 199 to /home/bertrand/paper-ner-bench-das22/src/ner/01-experiment_1_prepared_datasets\n",
      "100%|██████████| 1/1 [00:00<00:00, 92.49ba/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 29.79ba/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 28.01ba/s]\n",
      "18/05/2022 02:41:18 ; INFO ; Saving dataset with training set of size 99 to /home/bertrand/paper-ner-bench-das22/src/ner/01-experiment_1_prepared_datasets\n",
      "100%|██████████| 1/1 [00:00<00:00, 173.07ba/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 31.77ba/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 28.19ba/s]\n",
      "18/05/2022 02:41:20 ; INFO ; Saving dataset with training set of size 49 to /home/bertrand/paper-ner-bench-das22/src/ner/01-experiment_1_prepared_datasets\n",
      "100%|██████████| 1/1 [00:00<00:00, 257.46ba/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 33.74ba/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 29.22ba/s]\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Save the generated sets on the disk. \"\"\"\n",
    "\n",
    "output_directory = config.NERDIR / \"01-experiment_1_prepared_datasets\"\n",
    "\n",
    "# Create the output directory if necessary\n",
    "output_directory.mkdir(exist_ok=True, parents=True)\n",
    "   \n",
    "for train in exp1_trainsets:\n",
    "    datasets = [train, dev, test]\n",
    "    names    = [\"train\",\"dev\",\"test\"]\n",
    "    config.logger.info(f\"Saving dataset with training set of size {len(train)} to {output_directory}\")\n",
    "    save_dataset(output_directory, datasets, names, suffix=len(train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e623237-eb40-4bef-80d2-7a21a334023f",
   "metadata": {},
   "source": [
    "# 02. Experiment #2\n",
    "\n",
    "Generates the training, development and test sets for the Spacy and transformers models as described in the subsection #6 \"Training and evaluation protocol\" of the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7a74252e-1857-4aff-a2bc-a9c89be16980",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ner_xml_ref</th>\n",
       "      <th>ner_xml_pero</th>\n",
       "      <th>ner_xml_tess</th>\n",
       "      <th>book</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;PER&gt;Dufant (Victor)&lt;/PER&gt;, &lt;ACT&gt;libraire&lt;/ACT...</td>\n",
       "      <td>☞  T &lt;PER&gt;Dufant (Victor)&lt;/PER&gt;, &lt;ACT&gt;libraire...</td>\n",
       "      <td>&lt;PER&gt;Dofaut (Victor)&lt;/PER&gt;, &lt;ACT&gt;Sbraire&lt;/ACT&gt;...</td>\n",
       "      <td>Bottin1_1820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;PER&gt;Dufay&lt;/PER&gt;, &lt;ACT&gt;essayeur du commerce&lt;/A...</td>\n",
       "      <td>&lt;PER&gt;Dutay&lt;/PER&gt;, &lt;ACT&gt;essayeur du commerce&lt;/A...</td>\n",
       "      <td>&lt;PER&gt;Dufay&lt;/PER&gt;, &lt;ACT&gt;essayeur du commerce&lt;/A...</td>\n",
       "      <td>Bottin1_1820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;PER&gt;Dulay&lt;/PER&gt;, &lt;ACT&gt;chandronnier&lt;/ACT&gt;, &lt;LO...</td>\n",
       "      <td>&lt;PER&gt;Dulay&lt;/PER&gt;, &lt;ACT&gt;chandronnier&lt;/ACT&gt;, &lt;LO...</td>\n",
       "      <td>&lt;PER&gt;Dufay&lt;/PER&gt;, &lt;ACT&gt;chandronnier&lt;/ACT&gt;, &lt;LO...</td>\n",
       "      <td>Bottin1_1820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;PER&gt;Dufay (V.e)&lt;/PER&gt;, &lt;ACT&gt;grenetière&lt;/ACT&gt;,...</td>\n",
       "      <td>&lt;PER&gt;Dufay (V.e)&lt;/PER&gt;, &lt;ACT&gt;grenetière&lt;/ACT&gt;,...</td>\n",
       "      <td>&amp;quot;&lt;PER&gt;Dufay (V.e)&lt;/PER&gt;, &lt;ACT&gt;grenetière&lt;...</td>\n",
       "      <td>Bottin1_1820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;PER&gt;Dufeu&lt;/PER&gt;, &lt;ACT&gt;charcutier&lt;/ACT&gt;, &lt;LOC&gt;...</td>\n",
       "      <td>Y ☞ &lt;PER&gt;Dnten&lt;/PER&gt;,&lt;ACT&gt;charentier&lt;/ACT&gt;, &lt;L...</td>\n",
       "      <td>&lt;PER&gt;Dufen&lt;/PER&gt; . &lt;ACT&gt;chareutier&lt;/ACT&gt;, &lt;LOC...</td>\n",
       "      <td>Bottin1_1820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8336</th>\n",
       "      <td>&lt;PER&gt;Lamarche&lt;/PER&gt;, &lt;ACT&gt;géographe&lt;/ACT&gt; , &lt;L...</td>\n",
       "      <td>&lt;PER&gt;Lamarche&lt;/PER&gt;, &lt;ACT&gt;geographe&lt;/ACT&gt; , &lt;L...</td>\n",
       "      <td>&lt;PER&gt;Lamarche&lt;/PER&gt;, &lt;ACT&gt;geographe&lt;/ACT&gt; , &lt;L...</td>\n",
       "      <td>Notables_communaux_seine_1801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8337</th>\n",
       "      <td>&lt;PER&gt;Lamarck&lt;/PER&gt;, &lt;ACT&gt;membre de l&amp;apos;inst...</td>\n",
       "      <td>&lt;PER&gt;Lamarck&lt;/PER&gt;, &lt;ACT&gt;membre de l&amp;apos;inst...</td>\n",
       "      <td>&lt;PER&gt;Lamarck&lt;/PER&gt;, &lt;ACT&gt;membre de l&amp;apos;inst...</td>\n",
       "      <td>Notables_communaux_seine_1801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8338</th>\n",
       "      <td>&lt;PER&gt;Lamare&lt;/PER&gt;, &lt;ACT&gt;notaire&lt;/ACT&gt;, &lt;LOC&gt;ru...</td>\n",
       "      <td>&lt;PER&gt;Lamare&lt;/PER&gt; , &lt;ACT&gt;notaire&lt;/ACT&gt;, &lt;LOC&gt;r...</td>\n",
       "      <td>&lt;PER&gt;Lamare&lt;/PER&gt; , &lt;ACT&gt;notaire&lt;/ACT&gt;, &lt;LOC&gt;r...</td>\n",
       "      <td>Notables_communaux_seine_1801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8339</th>\n",
       "      <td>&lt;PER&gt;Lamarre&lt;/PER&gt; , &lt;ACT&gt;carrier&lt;/ACT&gt;, &lt;LOC&gt;...</td>\n",
       "      <td>&lt;PER&gt;Lamarre&lt;/PER&gt;, &lt;ACT&gt;carrier&lt;/ACT&gt;, &lt;LOC&gt;r...</td>\n",
       "      <td>&lt;PER&gt;Lamarre&lt;/PER&gt; , &lt;ACT&gt;Carrier&lt;/ACT&gt;, &lt;LOC&gt;...</td>\n",
       "      <td>Notables_communaux_seine_1801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8340</th>\n",
       "      <td>&lt;PER&gt;Lamarre&lt;/PER&gt;, &lt;ACT&gt;clerc de notaire&lt;/ACT...</td>\n",
       "      <td>&lt;PER&gt;Lamarre&lt;/PER&gt;, &lt;ACT&gt;clerc de notaire&lt;/ACT...</td>\n",
       "      <td>&lt;PER&gt;Lamarre&lt;/PER&gt;, &lt;ACT&gt;clerc de notaire&lt;/ACT...</td>\n",
       "      <td>Notables_communaux_seine_1801</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8341 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            ner_xml_ref  \\\n",
       "0     <PER>Dufant (Victor)</PER>, <ACT>libraire</ACT...   \n",
       "1     <PER>Dufay</PER>, <ACT>essayeur du commerce</A...   \n",
       "2     <PER>Dulay</PER>, <ACT>chandronnier</ACT>, <LO...   \n",
       "3     <PER>Dufay (V.e)</PER>, <ACT>grenetière</ACT>,...   \n",
       "4     <PER>Dufeu</PER>, <ACT>charcutier</ACT>, <LOC>...   \n",
       "...                                                 ...   \n",
       "8336  <PER>Lamarche</PER>, <ACT>géographe</ACT> , <L...   \n",
       "8337  <PER>Lamarck</PER>, <ACT>membre de l&apos;inst...   \n",
       "8338  <PER>Lamare</PER>, <ACT>notaire</ACT>, <LOC>ru...   \n",
       "8339  <PER>Lamarre</PER> , <ACT>carrier</ACT>, <LOC>...   \n",
       "8340  <PER>Lamarre</PER>, <ACT>clerc de notaire</ACT...   \n",
       "\n",
       "                                           ner_xml_pero  \\\n",
       "0     ☞\n",
       "\n",
       "T\n",
       "<PER>Dufant (Victor)</PER>, <ACT>libraire...   \n",
       "1     <PER>Dutay</PER>, <ACT>essayeur du commerce</A...   \n",
       "2     <PER>Dulay</PER>, <ACT>chandronnier</ACT>, <LO...   \n",
       "3     <PER>Dufay (V.e)</PER>, <ACT>grenetière</ACT>,...   \n",
       "4     Y\n",
       "☞\n",
       "<PER>Dnten</PER>,<ACT>charentier</ACT>, <L...   \n",
       "...                                                 ...   \n",
       "8336  <PER>Lamarche</PER>, <ACT>geographe</ACT> , <L...   \n",
       "8337  <PER>Lamarck</PER>, <ACT>membre de l&apos;inst...   \n",
       "8338  <PER>Lamare</PER> , <ACT>notaire</ACT>, <LOC>r...   \n",
       "8339  <PER>Lamarre</PER>, <ACT>carrier</ACT>, <LOC>r...   \n",
       "8340  <PER>Lamarre</PER>, <ACT>clerc de notaire</ACT...   \n",
       "\n",
       "                                           ner_xml_tess  \\\n",
       "0     <PER>Dofaut (Victor)</PER>, <ACT>Sbraire</ACT>...   \n",
       "1     <PER>Dufay</PER>, <ACT>essayeur du commerce</A...   \n",
       "2     <PER>Dufay</PER>, <ACT>chandronnier</ACT>, <LO...   \n",
       "3     &quot;<PER>Dufay (V.e)</PER>, <ACT>grenetière<...   \n",
       "4     <PER>Dufen</PER> . <ACT>chareutier</ACT>, <LOC...   \n",
       "...                                                 ...   \n",
       "8336  <PER>Lamarche</PER>, <ACT>geographe</ACT> , <L...   \n",
       "8337  <PER>Lamarck</PER>, <ACT>membre de l&apos;inst...   \n",
       "8338  <PER>Lamare</PER> , <ACT>notaire</ACT>, <LOC>r...   \n",
       "8339  <PER>Lamarre</PER> , <ACT>Carrier</ACT>, <LOC>...   \n",
       "8340  <PER>Lamarre</PER>, <ACT>clerc de notaire</ACT...   \n",
       "\n",
       "                               book  \n",
       "0                      Bottin1_1820  \n",
       "1                      Bottin1_1820  \n",
       "2                      Bottin1_1820  \n",
       "3                      Bottin1_1820  \n",
       "4                      Bottin1_1820  \n",
       "...                             ...  \n",
       "8336  Notables_communaux_seine_1801  \n",
       "8337  Notables_communaux_seine_1801  \n",
       "8338  Notables_communaux_seine_1801  \n",
       "8339  Notables_communaux_seine_1801  \n",
       "8340  Notables_communaux_seine_1801  \n",
       "\n",
       "[8341 rows x 4 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Loads the gold referernce dataset from DATASETDIR. \"\"\"\n",
    "\n",
    "GOLD_REFERENCE_PATH = config.DATASETDIR / \"supervised/40-ner_aligned_valid_subset/gold.csv\"\n",
    "assert GOLD_REFERENCE_PATH.exists()\n",
    "\n",
    "gold_reference = pd.read_csv(GOLD_REFERENCE_PATH, skipinitialspace='True')\n",
    "\n",
    "assert_expected(len(gold_reference), 8341)\n",
    "\n",
    "gold_reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a6f4c8c2-2982-45e0-8fac-132133e58ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Creates the training sets. \"\"\"\n",
    "\n",
    "# Reference gold (manually annotated & corrected examples): Split 72/8/20% w. stratified sampling on directories names\n",
    "ref = gold_reference[[\"ner_xml_ref\",\"book\"]]\n",
    "train_ref, dev_ref, test_ref = train_dev_test_split(ref.to_numpy())\n",
    "\n",
    "assert_expected(6004, len(train_ref))\n",
    "assert_expected(668, len(dev_ref))\n",
    "assert_expected(1669, len(test_ref))\n",
    "\n",
    "# Pero-OCR gold: split 72/8/20% w. stratified sampling on directories names\n",
    "pero = gold_reference[[\"ner_xml_pero\",\"book\"]]\n",
    "train_pero, dev_pero, test_pero = train_dev_test_split(pero.to_numpy())\n",
    "\n",
    "assert_expected(6004, len(train_pero))\n",
    "assert_expected(668, len(dev_pero))\n",
    "assert_expected(1669, len(test_pero))\n",
    "\n",
    "# Tesseract gold: split 72/8/20% w. stratified sampling on directories names\n",
    "tess = gold_reference[[\"ner_xml_tess\",\"book\"]]\n",
    "train_tess, dev_tess, test_tess = train_dev_test_split(tess.to_numpy())\n",
    "\n",
    "assert_expected(6004, len(train_tess))\n",
    "assert_expected(668, len(dev_tess))\n",
    "assert_expected(1669, len(test_tess))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7a341959-728c-4bd0-9c33-c067c4b69bdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00, 27.23ba/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 34.59ba/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 27.89ba/s]\n",
      "100%|██████████| 7/7 [00:00<00:00, 28.32ba/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 35.79ba/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 29.23ba/s]\n",
      "100%|██████████| 7/7 [00:00<00:00, 27.35ba/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 32.77ba/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 27.27ba/s]\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Save the generated sets on the disk. \"\"\"\n",
    "\n",
    "output_directory = config.NERDIR / \"02-experiment_2_prepared_datasets\"\n",
    "\n",
    "# Create the output directory if necessary\n",
    "output_directory.mkdir(exist_ok=True, parents=True)\n",
    "   \n",
    "names = [\"train\", \"dev\", \"test\"]\n",
    "save_dataset(output_directory, [train_ref, dev_ref, test_ref], names, suffix=\"ref\")\n",
    "save_dataset(output_directory, [train_pero, dev_pero, test_pero], names, suffix=\"pero\")\n",
    "save_dataset(output_directory, [train_tess, dev_tess, test_tess], names, suffix=\"tess\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('ner')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "c57d6dc83202ed16477ed01fbeb8d45268fb6711c5da666dad291c245339c394"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
