{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import isri_tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üëâ √©tag√®rxxesêå∞x\n",
      "exxtag.¬µbleble\n"
     ]
    }
   ],
   "source": [
    "a = \"üëâ √©tag√®resêå∞\"\n",
    "b = \"etag.¬µbleble\"\n",
    "\n",
    "A, B = isri_tools.align(a, b, 'x')\n",
    "print(A)\n",
    "print(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 10, 11, 12]\n",
      "[0, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13]\n"
     ]
    }
   ],
   "source": [
    "A, B = isri_tools.get_align_map(a, b)\n",
    "print(A)\n",
    "print(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import regex\n",
    "import numpy as np\n",
    "from warnings import warn\n",
    "\n",
    "tag_list = [\"PER\", \"LOC\", \"ACT\", \"CARD\", \"FT\", \"TITRE\"]\n",
    "\n",
    "def normalize(txt: str):\n",
    "    return txt\n",
    "\n",
    "\n",
    "def add_tags_prediction(ner_xml: str, text_ocr: str):\n",
    "     # Sanity check\n",
    "    cbegin = { tag : ner_xml.count(f\"<{tag}>\") for tag in tag_list }\n",
    "    cend = { tag : ner_xml.count(f\"</{tag}>\") for tag in tag_list }\n",
    "    if cbegin != cend:\n",
    "        warn(f\"The string '{ner_xml}' has unbalanced tags.\")\n",
    "        print(\"Opening:\", cbegin)\n",
    "        print(\"Closing:\", cend)\n",
    "\n",
    "    ## 1. Chunking\n",
    "    chunks = regex.split(\"(</?\\L<tag>>)\", ner_xml, tag=tag_list)\n",
    "    print(\"chunks:\", chunks)\n",
    "    A_chunks = chunks[0::2]\n",
    "    A_tags = [] if len(chunks) < 2 else chunks[1::2]\n",
    "\n",
    "    # 2.1 Normalize\n",
    "    A_chunks = list(map(normalize, A_chunks))\n",
    "    a = \"\".join(A_chunks)\n",
    "    b = normalize(text_ocr)\n",
    "\n",
    "    # 2.2 Single char \"normalizations\"\n",
    "    # tolerance to OCR single char substitutions (case insensitive, no accents, etc.)\n",
    "    # which DO NOT CHANGE THE MATCHING\n",
    "    case_insensitive = True\n",
    "    ai = a\n",
    "    bi = b\n",
    "    if case_insensitive:\n",
    "        ai = a.lower()\n",
    "        bi = b.lower()\n",
    "\n",
    "    # 3. Align\n",
    "    A, B = isri_tools.align(ai, bi, ' ')\n",
    "    print(A)\n",
    "    print(B)\n",
    "    A, B = isri_tools.get_align_map(ai, bi)\n",
    "\n",
    "    # 4. \n",
    "    pos_tags = np.cumsum([len(x) for x in A_chunks[:-1]])\n",
    "\n",
    "    # 5. Reprojet b on the alignment string\n",
    "    n = max(np.max(A), np.max(B)) + 1\n",
    "    chr_list = [ '' for i in range(n + 1)]\n",
    "    for k, c in zip(B, b):\n",
    "        chr_list[k] = c\n",
    "\n",
    "\n",
    "    # 6. Add tags on the alignment string\n",
    "    for p, tag in zip(reversed(pos_tags), reversed(A_tags)):\n",
    "        if tag.startswith(\"</\"):\n",
    "            print(p, a[p-1], chr_list[A[p-1] + 1])\n",
    "            chr_list.insert(A[p-1]+1, tag)\n",
    "        else:\n",
    "            print(p, a[p], chr_list[A[p]])\n",
    "            chr_list.insert(A[p], tag)\n",
    "\n",
    "    return \"\".join(chr_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunks: ['', '<PER>', 'Anthony', '</PER>', ', fab. du ', '<ACT>', 'p√™che', '</ACT>', ', ', '<LOC>', 'Ch√¢telet', '</LOC>', '']\n",
      "    anthony, fab. du p√™che,     ch√¢telet                       \n",
      "mme antoine, fab  la pecheur du chatelet et du faub. st antoine\n",
      "32 t  \n",
      "24 C c\n",
      "22 e u\n",
      "17 p p\n",
      "7 y ,\n",
      "0 A A\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Mme <PER>Antoine</PER>, fab la <ACT>peche</ACT>ur du <LOC>chatelet</LOC> et du Faub. St Antoine'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = \"<PER>Anthony</PER>, fab. du <ACT>p√™che</ACT>, <LOC>Ch√¢telet</LOC>\"\n",
    "B = \"Mme Antoine, fab la pecheur du chatelet et du Faub. St Antoine\"\n",
    "add_tags_prediction(A, B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunks: ['Mme ', '<PER>', 'Anthony', '</PER>', ', fab. du ', '<ACT>', 'p√™che', '</ACT>', ', ', '<LOC>', 'Ch√¢telet', '</LOC>', '']\n",
      "mme anthony, fab. du p√™che,     ch√¢telet                       \n",
      "mme antoine, fab  la pecheur du chatelet et du faub. st antoine\n",
      "36 t  \n",
      "28 C c\n",
      "26 e u\n",
      "21 p p\n",
      "11 y ,\n",
      "4 A A\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Mme <PER>Antoine</PER>, fab la <ACT>peche</ACT>ur du <LOC>chatelet</LOC> et du Faub. St Antoine'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = \"Mme <PER>Anthony</PER>, fab. du <ACT>p√™che</ACT>, <LOC>Ch√¢telet</LOC>\"\n",
    "B = \"Mme Antoine, fab la pecheur du chatelet et du Faub. St Antoine\"\n",
    "add_tags_prediction(A, B)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
