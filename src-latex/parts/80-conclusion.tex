% !TeX root = ../main-paper.tex
\section{Conclusion}

In this article, we assessed the performance of three modern OCR systems on real historical data. Although Pero-OCR clearly outperforms its competitors, the qualitative analysis of its errors shows that it fails on different entries. This calls for leveraging both Pero-OCR and Tesseract in a complementary way to get the best out of both systems. Moreover, we evaluated the needs of two deep-learning-based NER approaches in terms of training data amount and text quality for pretraining. We showed that BERT-based NER can benefit from pretraining and fine-tuning on a noisy OCRed corpus to improve its performance on a noisy OCRed test dataset. To perform a NER task on OCRised texts, it seems therefore worthwhile to train the NER model on a corpus OCRised with the same system and not corrected. However, the results are not as good as for clean text: it is therefore interesting to investigate how to improve the OCR results or to correct the text in a postprocessing step. Furthermore, it seems that the models quickly achieve good performance with very few training examples. Leveraging a model fine-tuned on a few examples to automatically produce much larger training sets could reveal a solution to lower the annotation burden. Besides, as directory entries always have the same structure - at least within a given list - we could take advantage of NER results and some simple rules to identify entries within pages instead of relying on the page layout.

Interesting points to discuss:
\begin{itemize}
    \item can we train on noisy data? (without manual OCR correction?) => future work? cf Pero OCR training procedure?
    \item do we need better OCR systems or better post-correction techniques (if NER is reliable enough)?
    \item Construction of the lexicon and associated cost \nathalie{là je ne comprends pas}
\end{itemize}

Ideas for future work:
\begin{itemize}
    \item Evaluate this: fine-tune Spacy NER on a few samples to generated a bootstrap dataset, feed it to BERT (cleaned or raw) to create an good model with minimal efforts ? \nathalie{les résultats de la table 2 ne plaident pas vraiment pour ça: même sur les très petits corpus, spacy est tours derrière...}
    \item Use ML to infer regexes ?
    \item As directories entries are always structured the same way (in a given list at least): use NER to identify entries within pages to save the burden of having to rely on the page layout ?
\end{itemize}